{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación del Entorno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aplicacion de modelo\n",
    "\n",
    "# limpio la memoria\n",
    "rm(list = ls()) # remove all objects\n",
    "gc() # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Librerías necesarias\n",
    "require(\"data.table\")\n",
    "require(\"rpart\")\n",
    "require(\"ggplot2\")\n",
    "require(\"ranger\")\n",
    "require(\"randomForest\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Importación del archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui se debe poner la carpeta de la materia de SU computadora local\n",
    "setwd(\"C:/Users/German/Desktop/dmeyf2023/German/Clase 1\") # Establezco el Working Directory\n",
    "\n",
    "# cargo el dataset\n",
    "dataset <- fread(\"competencia_01_alternativo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Poner sus semillas\n",
    "semillas <- c(279511, 279523, 279541, 279551, 279571)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Nos quedamos solo con el 202103\n",
    "dataset <- dataset[foto_mes == 202103]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Clase como factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Importante que la clase sea factor\n",
    "dataset[, clase_binaria1 := factor(ifelse(clase_ternaria == \"BAJA+2\", \"evento\", \"noevento\"))]\n",
    "dataset$clase_ternaria <- NULL\n",
    "in_training <- caret::createDataPartition(dataset$clase_binaria1,\n",
    "                     p = 0.70, list = FALSE)\n",
    "\n",
    "dtrain  <-  dataset[in_training, ]\n",
    "dtest   <-  dataset[-in_training, ]\n",
    "\n",
    "# ranger no soporta, como lo hacen otras librerías, los missing values\n",
    "dtrain <-  na.roughfix(dtrain)\n",
    "dtest <-  na.roughfix(dtest)\n",
    "\n",
    "# Cantidad de variables que abren por cada hoja\n",
    "n_variables <- round(sqrt(dim(dtrain)[2] - 1))\n",
    "\n",
    "t0 <- Sys.time()\n",
    "modelo_rf_1 <- ranger(clase_binaria1 ~ ., data = dtrain,\n",
    "                  probability = TRUE,\n",
    "                  num.trees = 100,\n",
    "                  min.node.size=10,  # <---------\n",
    "                  mtry = n_variables,\n",
    "                  splitrule = \"gini\",\n",
    "                  sample.fraction = 0.66,\n",
    "                  importance = \"impurity\",\n",
    "                  verbose = TRUE)\n",
    "t1 <- Sys.time()\n",
    "as.numeric(t1 - t0, units = \"secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Midiendo el primero RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pred_train <- predict(modelo_rf_1, dtrain)\n",
    "pred_test <- predict(modelo_rf_1, dtest)\n",
    "\n",
    "# Ganancia en dtrain\n",
    "print(sum((pred_train$predictions[, \"evento\"] >= 0.025) * ifelse(\n",
    "                    dtrain$clase_binaria1 == \"evento\", \n",
    "                    273000, -7000) / 0.7))\n",
    "# Ganancia en dtest\n",
    "print(sum((pred_test$predictions[, \"evento\"] >= 0.025) * ifelse(\n",
    "                    dtest$clase_binaria1 == \"evento\",\n",
    "                    273000, -7000) / 0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preguntas\n",
    "- ¿Qué paso en `train`?\n",
    "- ¿Se veía esa diferencia en los árboles?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Importancia de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "importancia <- as.data.table(modelo_rf_1$variable.importance,\n",
    "                    keep.rownames = TRUE)\n",
    "colnames(importancia) <- c(\"variable\", \"importancia\")\n",
    "setorder(importancia, -importancia)\n",
    "importancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preguntas\n",
    " - ¿Qué significa que una variable sea más importante que otra?\n",
    " - ¿Qué significa que una variable tenga 0 importancia?\n",
    " - ¿Con el **RF** es suficiente como para descartarlas?\n",
    " - ¿Qué una variable tenga algo de importancia es suficiente como para\n",
    " - entender que da valor?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Un experimento con canaritos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dtrain$canarito <- runif(nrow(dtrain))\n",
    "\n",
    "modelo_rf_2 <- ranger(clase_binaria1 ~ ., data = dtrain,\n",
    "                  probability = TRUE,\n",
    "                  num.trees = 150,\n",
    "                  min.node.size = 10, # <-- probar con valores mas altos\n",
    "                  mtry = n_variables,\n",
    "                  splitrule = \"gini\",\n",
    "                  importance = \"impurity\",\n",
    "                  verbose = TRUE)\n",
    "\n",
    "importancia2 <- as.data.table(modelo_rf_2$variable.importance,\n",
    "                    keep.rownames = TRUE)\n",
    "colnames(importancia2) <- c(\"variable\", \"importancia\")\n",
    "setorder(importancia2, -importancia)\n",
    "importancia2\n",
    "which(importancia2$variable == \"canarito\")\n",
    "\n",
    "## Active learning o a llorar a la iglesia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## ---------------------------\n",
    "## Step 5.1: Hablando de los Extra Trees\n",
    "## ---------------------------\n",
    "\n",
    "modelo_rf_3 <- ranger(clase_binaria1 ~ ., data = dtrain,\n",
    "                  probability = TRUE,\n",
    "                  num.trees = 150,\n",
    "                  min.node.size = 200, # <---------\n",
    "                  mtry = n_variables,\n",
    "                  splitrule = \"extratrees\", # <---------\n",
    "                  num.random.splits = 10, # <---------\n",
    "                  importance = \"impurity\",\n",
    "                  verbose = TRUE)\n",
    "\n",
    "importancia3 <- as.data.table(modelo_rf_3$variable.importance,\n",
    "                    keep.rownames = TRUE)\n",
    "colnames(importancia3) <- c(\"variable\", \"importancia\")\n",
    "setorder(importancia3, -importancia)\n",
    "importancia3\n",
    "which(importancia3$variable == \"canarito\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Boosting, la navaja suiza de los modelos - Conceptos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    " Estos se construyen de forma serial.\n",
    "- Primero se parte de un modelo (que puede ser un valor constante) y se  complementa con un modelo que busca mejorar al anterior.\n",
    "\n",
    "Hay dos algoritmos muy conocidos de este tipo:\n",
    "\n",
    "- **Adaboost**: Que cada nuevo modelo va mejorando a los anteriores poniendo un peso mayor en los casos donde la clasificación es incorrecta\n",
    "\n",
    "- **Gradient Boosting**: Que cada nuevo modelo va mejorando los anteriores, tratando de corregir los residuos, buscando estos últimos con el gradiente de una función de perdida.\n",
    "\n",
    "Este último se empezó a hacer muy popular por la excelente pieza de tecnología que es su implementación **xgboost**, superado luego por el LightGBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Cargamos todo para tener un código limpio\n",
    "dataset <- fread(\".competencia_01_alternativo.csv\")\n",
    "\n",
    "# Nos quedamos solo con el 202103\n",
    "dataset <- dataset[foto_mes == 202103]\n",
    "\n",
    "clase_binaria <- ifelse(dataset$clase_ternaria == \"BAJA+2\", 1, 0)\n",
    "dataset$clase_ternaria <- NULL\n",
    "\n",
    "dtrain  <- lgb.Dataset(data = data.matrix(dataset), label = clase_binaria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(semillas[1])\n",
    "# LightGBM, al igual que XGB traen su implementación del CV\n",
    "# Los parámetros los iremos viendo en profundidad la siguiente clase.\n",
    "model_lgbm_cv <- lgb.cv(data = dtrain,\n",
    "         eval = \"auc\",\n",
    "         stratified = TRUE,\n",
    "         nfold = 5,\n",
    "         feature_pre_filter=FALSE,\n",
    "         param = list(objective = \"binary\",\n",
    "                       max_bin = 15,\n",
    "                       min_data_in_leaf = 300,\n",
    "                       learning_rate = 0.05\n",
    "                       )\n",
    "      )\n",
    "\n",
    "# Mejor iteración\n",
    "model_lgbm_cv$best_iter\n",
    "\n",
    "# Una vez que elegimos los parámetros tenemos que entrenar con todos.\n",
    "model_lgm <- lightgbm(data = dtrain,\n",
    "            nrounds = model_lgbm_cv$best_iter,\n",
    "            params = list(objective = \"binary\",\n",
    "                            max_bin = 15,\n",
    "                            min_data_in_leaf = 4000,\n",
    "                            learning_rate = 0.05),\n",
    "             verbose = -1)\n",
    "\n",
    "# También tiene su importancia de variables\n",
    "lgb.importance(model_lgm, percentage = TRUE)\n",
    "\n",
    "## Bienvenido al mundo de los ensambles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
