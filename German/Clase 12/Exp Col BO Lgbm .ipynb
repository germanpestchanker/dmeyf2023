{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de Librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este script esta pensado para correr en Google Cloud\n",
    "- 8 vCPU\n",
    "- 128 GB memoria RAM\n",
    "\n",
    "- se entrena con clase_binaria2  POS =  { BAJA+1, BAJA+2 }\n",
    "- Optimizacion Bayesiana de hiperparametros de  lightgbm,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Borrar al terminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# limpio la memoria\n",
    "rm(list = ls()) # remove all objects\n",
    "gc() # garbage collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "require(\"data.table\")\n",
    "require(\"rlist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Paso previo de transformar caracteres especiales\n",
    "# Carga el dataset desde el archivo CSV comprimido\n",
    "df <- read.csv(\"/home/germanpestchanker/buckets/b1/datasets/competencia_03_infla_ajustado_lags.csv.gz\")\n",
    "\n",
    "# Limpiar los nombres de las columnas\n",
    "colnames(df) <- gsub(\"[^A-Za-z0-9_]\", \"_\", colnames(df))\n",
    "\n",
    "write.csv(df, file = \"/home/germanpestchanker/buckets/b1/datasets/competencia_03_infla_ajustado_lags.csv.gz\", row.names = FALSE, quote = FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semilla 1, base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 631888</td><td>33.8</td><td>1412175</td><td>75.5</td><td> 984966</td><td>52.7</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>1170380</td><td> 9.0</td><td>8388608</td><td>64.0</td><td>1815603</td><td>13.9</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  631888 & 33.8 & 1412175 & 75.5 &  984966 & 52.7\\\\\n",
       "\tVcells & 1170380 &  9.0 & 8388608 & 64.0 & 1815603 & 13.9\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |  631888 | 33.8 | 1412175 | 75.5 |  984966 | 52.7 |\n",
       "| Vcells | 1170380 |  9.0 | 8388608 | 64.0 | 1815603 | 13.9 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
       "Ncells  631888 33.8 1412175    75.5  984966  52.7\n",
       "Vcells 1170380  9.0 8388608    64.0 1815603  13.9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "rm(list = ls()) # remove all objects\n",
    "gc() # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: data.table\n",
      "\n",
      "Loading required package: rlist\n",
      "\n",
      "Loading required package: lightgbm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "require(\"data.table\")\n",
    "require(\"rlist\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: DiceKriging\n",
      "\n",
      "Loading required package: mlrMBO\n",
      "\n",
      "Loading required package: mlr\n",
      "\n",
      "Loading required package: ParamHelpers\n",
      "\n",
      "Warning message: 'mlr' is in 'maintenance-only' mode since July 2019.\n",
      "Future development will only happen in 'mlr3'\n",
      "(<https://mlr3.mlr-org.com>). Due to the focus on 'mlr3' there might be\n",
      "uncaught bugs meanwhile in {mlr} - please consider switching.\n",
      "\n",
      "Loading required package: smoof\n",
      "\n",
      "Loading required package: checkmate\n",
      "\n",
      "\n",
      "Attaching package: ‘checkmate’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:DiceKriging’:\n",
      "\n",
      "    checkNames\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# paquetes necesarios para la Bayesian Optimization\n",
    "require(\"DiceKriging\")\n",
    "require(\"mlrMBO\")\n",
    "\n",
    "# para que se detenga ante el primer error\n",
    "# y muestre el stack de funciones invocadas\n",
    "options(error = function() {\n",
    "  traceback(20)\n",
    "  options(error = NULL)\n",
    "  stop(\"exiting after script error\")\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los parametros de la corrida, en una lista, la variable global  PARAM\n",
    "#  muy pronto esto se leera desde un archivo formato .yaml\n",
    "PARAM <- list()\n",
    "\n",
    "PARAM$experimento <- \"HT8230 (Clase 12, Base Sem1)\"\n",
    "\n",
    "PARAM$input$dataset <- \"datasets/competencia_03_base_lags.csv.gz\"\n",
    "\n",
    "# los meses en los que vamos a entrenar\n",
    "#  mucha magia emerger de esta eleccion\n",
    "PARAM$input$testing <- c(202107) # Último mes, lo más cercano al 202109 de kaggle\n",
    "PARAM$input$validation <- c(202106)\n",
    "PARAM$input$training <- c(202105, 202104, 202103, 202102, 202101,202012) # 6 meses de entrenamiento\t\n",
    "\n",
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "PARAM$trainingstrategy$undersampling <- 1.0\n",
    "PARAM$trainingstrategy$semilla_azar <- c(279511, 279523, 279541, 279551, 279571)  # Aqui poner su  primer  semilla/ pongo todas mis semillas\n",
    "\n",
    "PARAM$hyperparametertuning$POS_ganancia <- 273000\n",
    "PARAM$hyperparametertuning$NEG_ganancia <- -7000\n",
    "\n",
    "# Aqui va semilla\n",
    "PARAM$lgb_semilla <- 279511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Hiperparametros FIJOS de  lightgbm\n",
    "PARAM$lgb_basicos <- list(\n",
    "  boosting = \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
    "  objective = \"binary\",\n",
    "  metric = \"custom\",\n",
    "  first_metric_only = TRUE,\n",
    "  boost_from_average = TRUE,\n",
    "  feature_pre_filter = FALSE,\n",
    "  force_row_wise = TRUE, # para reducir warnings\n",
    "  verbosity = -100,\n",
    "  max_depth = -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split = 0.0, # min_gain_to_split >= 0.0\n",
    "  min_sum_hessian_in_leaf = 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1 = 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2 = 0.0, # lambda_l2 >= 0.0\n",
    "  max_bin = 31L, # lo debo dejar fijo, no participa de la BO\n",
    "  num_iterations = 9999, # un numero muy grande, lo limita early_stopping_rounds\n",
    "\n",
    "  bagging_fraction = 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction = 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction = 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance = FALSE, #\n",
    "  scale_pos_weight = 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate = 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop = 50, # <=0 means no limit\n",
    "  skip_drop = 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  extra_trees = TRUE, # Magic Sauce\n",
    "\n",
    "  seed = PARAM$lgb_semilla\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui se cargan los hiperparametros que se optimizan\n",
    "#  en la Bayesian Optimization\n",
    "PARAM$bo_lgb <- makeParamSet(\n",
    "  makeNumericParam(\"learning_rate\", lower = 0.02, upper = 0.3),\n",
    "  makeNumericParam(\"feature_fraction\", lower = 0.01, upper = 1.0),\n",
    "  makeIntegerParam(\"num_leaves\", lower = 8L, upper = 1024L),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower = 100L, upper = 50000L)\n",
    ")\n",
    "\n",
    "# si usted es ambicioso, y tiene paciencia, podria subir este valor a 100\n",
    "PARAM$bo_iteraciones <- 50 # iteraciones de la Optimizacion Bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# graba a un archivo los componentes de lista\n",
    "# para el primer registro, escribe antes los titulos\n",
    "\n",
    "loguear <- function(\n",
    "    reg, arch = NA, folder = \"./exp/\",\n",
    "    ext = \".txt\", verbose = TRUE) {\n",
    "  archivo <- arch\n",
    "  if (is.na(arch)) archivo <- paste0(folder, substitute(reg), ext)\n",
    "\n",
    "  if (!file.exists(archivo)) # Escribo los titulos\n",
    "    {\n",
    "      linea <- paste0(\n",
    "        \"fecha\\t\",\n",
    "        paste(list.names(reg), collapse = \"\\t\"), \"\\n\"\n",
    "      )\n",
    "\n",
    "      cat(linea, file = archivo)\n",
    "    }\n",
    "\n",
    "  linea <- paste0(\n",
    "    format(Sys.time(), \"%Y%m%d %H%M%S\"), \"\\t\", # la fecha y hora\n",
    "    gsub(\", \", \"\\t\", toString(reg)), \"\\n\"\n",
    "  )\n",
    "\n",
    "  cat(linea, file = archivo, append = TRUE) # grabo al archivo\n",
    "\n",
    "  if (verbose) cat(linea) # imprimo por pantalla\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "GLOBAL_arbol <- 0L\n",
    "GLOBAL_gan_max <- -Inf\n",
    "vcant_optima <- c()\n",
    "\n",
    "fganancia_lgbm_meseta <- function(probs, datos) {\n",
    "  vlabels <- get_field(datos, \"label\")\n",
    "  vpesos <- get_field(datos, \"weight\")\n",
    "\n",
    "\n",
    "  GLOBAL_arbol <<- GLOBAL_arbol + 1\n",
    "  tbl <- as.data.table(list(\n",
    "    \"prob\" = probs,\n",
    "    \"gan\" = ifelse(vlabels == 1 & vpesos > 1,\n",
    "      PARAM$hyperparametertuning$POS_ganancia,\n",
    "      PARAM$hyperparametertuning$NEG_ganancia  )\n",
    "  ))\n",
    "\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, posicion := .I]\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "\n",
    "  tbl[, gan_suavizada :=\n",
    "    frollmean(\n",
    "      x = gan_acum, n = 2001, align = \"center\",\n",
    "      na.rm = TRUE, hasNA = TRUE\n",
    "    )]\n",
    "\n",
    "  gan <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "\n",
    "  pos <- which.max(tbl[, gan_suavizada])\n",
    "  vcant_optima <<- c(vcant_optima, pos)\n",
    "\n",
    "  if (GLOBAL_arbol %% 10 == 0) {\n",
    "    if (gan > GLOBAL_gan_max) GLOBAL_gan_max <<- gan\n",
    "\n",
    "    cat(\"\\r\")\n",
    "    cat(\n",
    "      \"Validate \", GLOBAL_iteracion, \" \", \" \",\n",
    "      GLOBAL_arbol, \"  \", gan, \"   \", GLOBAL_gan_max, \"   \"\n",
    "    )\n",
    "  }\n",
    "\n",
    "\n",
    "  return(list(\n",
    "    \"name\" = \"ganancia\",\n",
    "    \"value\" = gan,\n",
    "    \"higher_better\" = TRUE\n",
    "  ))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "\n",
    "EstimarGanancia_lightgbm <- function(x) {\n",
    "  gc()\n",
    "  GLOBAL_iteracion <<- GLOBAL_iteracion + 1L\n",
    "\n",
    "  # hago la union de los parametros basicos y los moviles que vienen en x\n",
    "  param_completo <- c(PARAM$lgb_basicos, x)\n",
    "\n",
    "  param_completo$early_stopping_rounds <-\n",
    "    as.integer(400 + 4 / param_completo$learning_rate)\n",
    "\n",
    "  GLOBAL_arbol <<- 0L\n",
    "  GLOBAL_gan_max <<- -Inf\n",
    "  vcant_optima <<- c()\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  modelo_train <- lgb.train(\n",
    "    data = dtrain,\n",
    "    valids = list(valid = dvalidate),\n",
    "    eval = fganancia_lgbm_meseta,\n",
    "    param = param_completo,\n",
    "    verbose = -100\n",
    "  )\n",
    "\n",
    "  cat(\"\\n\")\n",
    "\n",
    "  cant_corte <- vcant_optima[modelo_train$best_iter]\n",
    "\n",
    "  # aplico el modelo a testing y calculo la ganancia\n",
    "  prediccion <- predict(\n",
    "    modelo_train,\n",
    "    data.matrix(dataset_test[, campos_buenos, with = FALSE])\n",
    "  )\n",
    "\n",
    "  tbl <- copy(dataset_test[, list(\"gan\" = ifelse(clase_ternaria == \"BAJA+2\",\n",
    "    PARAM$hyperparametertuning$POS_ganancia, \n",
    "    PARAM$hyperparametertuning$NEG_ganancia))])\n",
    "\n",
    "  tbl[, prob := prediccion]\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "  tbl[, gan_suavizada := frollmean(\n",
    "    x = gan_acum, n = 2001,\n",
    "    align = \"center\", na.rm = TRUE, hasNA = TRUE\n",
    "  )]\n",
    "\n",
    "\n",
    "  ganancia_test <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "  cantidad_test_normalizada <- which.max(tbl[, gan_suavizada])\n",
    "\n",
    "  rm(tbl)\n",
    "  gc()\n",
    "\n",
    "  ganancia_test_normalizada <- ganancia_test\n",
    "\n",
    "\n",
    "  # voy grabando las mejores column importance\n",
    "  if (ganancia_test_normalizada > GLOBAL_gananciamax) {\n",
    "    GLOBAL_gananciamax <<- ganancia_test_normalizada\n",
    "    tb_importancia <- as.data.table(lgb.importance(modelo_train))\n",
    "\n",
    "    fwrite(tb_importancia,\n",
    "      file = paste0(\"impo_\", sprintf(\"%03d\", GLOBAL_iteracion), \".txt\"),\n",
    "      sep = \"\\t\"\n",
    "    )\n",
    "\n",
    "    rm(tb_importancia)\n",
    "  }\n",
    "\n",
    "\n",
    "  # logueo final\n",
    "  ds <- list(\"cols\" = ncol(dtrain), \"rows\" = nrow(dtrain))\n",
    "  xx <- c(ds, copy(param_completo))\n",
    "\n",
    "  xx$early_stopping_rounds <- NULL\n",
    "  xx$num_iterations <- modelo_train$best_iter\n",
    "  xx$estimulos <- cantidad_test_normalizada\n",
    "  xx$ganancia <- ganancia_test_normalizada\n",
    "  xx$iteracion_bayesiana <- GLOBAL_iteracion\n",
    "\n",
    "  loguear(xx, arch = \"BO_log.txt\")\n",
    "\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  return(ganancia_test_normalizada)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aquí empieza el programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui empieza el programa\n",
    "\n",
    "# Aqui se debe poner la carpeta de la computadora local\n",
    "setwd(\"~/buckets/b1/\") # Establezco el Working Directory\n",
    "\n",
    "# cargo el dataset donde voy a entrenar el modelo\n",
    "dataset <- fread(PARAM$input$dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# creo la carpeta donde va el experimento\n",
    "dir.create(\"./exp/\", showWarnings = FALSE)\n",
    "dir.create(paste0(\"./exp/\", PARAM$experimento, \"/\"), showWarnings = FALSE)\n",
    "\n",
    "# Establezco el Working Directory DEL EXPERIMENTO\n",
    "setwd(paste0(\"./exp/\", PARAM$experimento, \"/\"))\n",
    "\n",
    "# en estos archivos quedan los resultados\n",
    "kbayesiana <- paste0(PARAM$experimento, \".RDATA\")\n",
    "klog <- paste0(PARAM$experimento, \".txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Catastrophe Analysis  -------------------------------------------------------\n",
    "# deben ir cosas de este estilo\n",
    "#   dataset[foto_mes == 202006, active_quarter := NA]\n",
    "\n",
    "# Data Drifting\n",
    "# por ahora, no hago nada\n",
    "\n",
    "\n",
    "# Feature Engineering Historico  ----------------------------------------------\n",
    "#   aqui deben calcularse los  lags y  lag_delta\n",
    "#   Sin lags no hay paraiso !  corta la bocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ahora SI comienza la optimizacion Bayesiana\n",
    "\n",
    "GLOBAL_iteracion <- 0 # inicializo la variable global\n",
    "GLOBAL_gananciamax <- -1 # inicializo la variable global\n",
    "\n",
    "# si ya existe el archivo log, traigo hasta donde llegue\n",
    "if (file.exists(klog)) {\n",
    "  tabla_log <- fread(klog)\n",
    "  GLOBAL_iteracion <- nrow(tabla_log)\n",
    "  GLOBAL_gananciamax <- tabla_log[, max(ganancia)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 4893028 × 602</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>numero_de_cliente</th><th scope=col>foto_mes</th><th scope=col>active_quarter</th><th scope=col>cliente_vip</th><th scope=col>internet</th><th scope=col>cliente_edad</th><th scope=col>cliente_antiguedad</th><th scope=col>mrentabilidad</th><th scope=col>mrentabilidad_annual</th><th scope=col>mcomisiones</th><th scope=col>⋯</th><th scope=col>lag_6_Visa_mconsumototal</th><th scope=col>lag_1_Visa_cconsumos</th><th scope=col>lag_3_Visa_cconsumos</th><th scope=col>lag_6_Visa_cconsumos</th><th scope=col>lag_1_Visa_cadelantosefectivo</th><th scope=col>lag_3_Visa_cadelantosefectivo</th><th scope=col>lag_6_Visa_cadelantosefectivo</th><th scope=col>lag_1_Visa_mpagominimo</th><th scope=col>lag_3_Visa_mpagominimo</th><th scope=col>lag_6_Visa_mpagominimo</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>29234246</td><td>202003</td><td>1</td><td>0</td><td>0</td><td>61</td><td>280</td><td> 497.55</td><td>10740.15</td><td>   9.85</td><td>⋯</td><td>      NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>     NA</td><td>     NA</td><td>     NA</td></tr>\n",
       "\t<tr><td>29234246</td><td>202004</td><td>1</td><td>0</td><td>1</td><td>61</td><td>281</td><td>1148.00</td><td>11473.76</td><td>   9.85</td><td>⋯</td><td>      NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>   0.00</td><td>     NA</td><td>     NA</td></tr>\n",
       "\t<tr><td>29234246</td><td>202005</td><td>1</td><td>0</td><td>1</td><td>61</td><td>282</td><td>1716.07</td><td>12906.70</td><td>  17.09</td><td>⋯</td><td>      NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>   0.00</td><td>     NA</td><td>     NA</td></tr>\n",
       "\t<tr><td>29234246</td><td>202006</td><td>0</td><td>0</td><td>0</td><td>61</td><td>283</td><td>   0.00</td><td>    0.00</td><td>   0.00</td><td>⋯</td><td>      NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>   0.00</td><td>   0.00</td><td>     NA</td></tr>\n",
       "\t<tr><td>29234246</td><td>202007</td><td>1</td><td>0</td><td>1</td><td>61</td><td>284</td><td>1843.89</td><td>13487.06</td><td>  13.98</td><td>⋯</td><td>      NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>   0.00</td><td>   0.00</td><td>     NA</td></tr>\n",
       "\t<tr><td>29234246</td><td>202008</td><td>1</td><td>0</td><td>1</td><td>62</td><td>285</td><td>1479.17</td><td>13404.26</td><td>  13.85</td><td>⋯</td><td>      NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>   0.00</td><td>   0.00</td><td>     NA</td></tr>\n",
       "\t<tr><td>29234246</td><td>202009</td><td>1</td><td>0</td><td>1</td><td>62</td><td>286</td><td>2121.81</td><td>14320.19</td><td>  17.29</td><td>⋯</td><td>      NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>   0.00</td><td>   0.00</td><td>   0.00</td></tr>\n",
       "\t<tr><td>29234246</td><td>202010</td><td>1</td><td>0</td><td>0</td><td>62</td><td>287</td><td>4303.36</td><td>17865.74</td><td>2367.26</td><td>⋯</td><td>      NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>   0.00</td><td>   0.00</td><td>   0.00</td></tr>\n",
       "\t<tr><td>29234246</td><td>202011</td><td>1</td><td>0</td><td>0</td><td>62</td><td>288</td><td>3702.42</td><td>21318.99</td><td>2367.27</td><td>⋯</td><td>      NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>   0.00</td><td>   0.00</td><td>   0.00</td></tr>\n",
       "\t<tr><td>29234246</td><td>202012</td><td>1</td><td>0</td><td>0</td><td>62</td><td>289</td><td>4394.43</td><td>25032.74</td><td>2382.39</td><td>⋯</td><td>      NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>   0.00</td><td>   0.00</td><td>   0.00</td></tr>\n",
       "\t<tr><td>29234246</td><td>202101</td><td>1</td><td>0</td><td>0</td><td>62</td><td>290</td><td>4519.04</td><td>28757.53</td><td>2372.25</td><td>⋯</td><td>      NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>   0.00</td><td>   0.00</td><td>   0.00</td></tr>\n",
       "\t<tr><td>29234246</td><td>202102</td><td>1</td><td>0</td><td>0</td><td>62</td><td>291</td><td>1515.44</td><td>28934.66</td><td>  22.09</td><td>⋯</td><td>      NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>   0.00</td><td>   0.00</td><td>   0.00</td></tr>\n",
       "\t<tr><td>29235399</td><td>201901</td><td>1</td><td>0</td><td>1</td><td>59</td><td>174</td><td>1794.53</td><td> 7842.29</td><td> 295.73</td><td>⋯</td><td>      NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>     NA</td><td>     NA</td><td>     NA</td></tr>\n",
       "\t<tr><td>29235399</td><td>201902</td><td>1</td><td>0</td><td>1</td><td>59</td><td>175</td><td> 765.73</td><td> 8205.41</td><td> 204.86</td><td>⋯</td><td>      NA</td><td> 1</td><td>NA</td><td>NA</td><td> 0</td><td>NA</td><td>NA</td><td> 692.07</td><td>     NA</td><td>     NA</td></tr>\n",
       "\t<tr><td>29235399</td><td>201903</td><td>1</td><td>0</td><td>1</td><td>59</td><td>176</td><td> 927.83</td><td> 8670.28</td><td> 177.54</td><td>⋯</td><td>      NA</td><td> 4</td><td>NA</td><td>NA</td><td> 0</td><td>NA</td><td>NA</td><td> 797.64</td><td>     NA</td><td>     NA</td></tr>\n",
       "\t<tr><td>29235399</td><td>201904</td><td>1</td><td>0</td><td>1</td><td>59</td><td>177</td><td>2951.32</td><td>11260.80</td><td>1337.02</td><td>⋯</td><td>      NA</td><td> 3</td><td> 1</td><td>NA</td><td> 0</td><td> 0</td><td>NA</td><td> 527.85</td><td> 692.07</td><td>     NA</td></tr>\n",
       "\t<tr><td>29235399</td><td>201905</td><td>1</td><td>0</td><td>1</td><td>59</td><td>178</td><td>   0.00</td><td>    0.00</td><td>   0.00</td><td>⋯</td><td>      NA</td><td> 5</td><td> 4</td><td>NA</td><td> 0</td><td> 0</td><td>NA</td><td>1055.70</td><td> 797.64</td><td>     NA</td></tr>\n",
       "\t<tr><td>29235399</td><td>201906</td><td>1</td><td>0</td><td>1</td><td>60</td><td>179</td><td>1239.32</td><td>13242.19</td><td>1085.64</td><td>⋯</td><td>      NA</td><td> 4</td><td> 3</td><td>NA</td><td> 0</td><td> 0</td><td>NA</td><td> 914.94</td><td> 527.85</td><td>     NA</td></tr>\n",
       "\t<tr><td>29235399</td><td>201907</td><td>1</td><td>0</td><td>1</td><td>60</td><td>180</td><td> 641.43</td><td>13460.36</td><td>1763.40</td><td>⋯</td><td>  809.37</td><td> 6</td><td> 5</td><td> 1</td><td> 0</td><td> 0</td><td> 0</td><td> 434.01</td><td>1055.70</td><td> 692.07</td></tr>\n",
       "\t<tr><td>29235399</td><td>201908</td><td>1</td><td>0</td><td>1</td><td>60</td><td>181</td><td> 336.69</td><td>13896.07</td><td>1395.47</td><td>⋯</td><td> 2772.97</td><td>15</td><td> 4</td><td> 4</td><td> 0</td><td> 0</td><td> 0</td><td>2568.87</td><td> 914.94</td><td> 797.64</td></tr>\n",
       "\t<tr><td>29235399</td><td>201909</td><td>1</td><td>0</td><td>1</td><td>60</td><td>182</td><td> 398.97</td><td>13973.28</td><td>1706.33</td><td>⋯</td><td> 2046.88</td><td> 4</td><td> 6</td><td> 3</td><td> 0</td><td> 0</td><td> 0</td><td>2029.29</td><td> 434.01</td><td> 527.85</td></tr>\n",
       "\t<tr><td>29235399</td><td>201910</td><td>1</td><td>0</td><td>1</td><td>60</td><td>183</td><td>   0.00</td><td>    0.00</td><td>   0.00</td><td>⋯</td><td> 6668.90</td><td> 3</td><td>15</td><td> 5</td><td> 0</td><td> 0</td><td> 0</td><td>1888.53</td><td>2568.87</td><td>1055.70</td></tr>\n",
       "\t<tr><td>29235399</td><td>201911</td><td>1</td><td>0</td><td>1</td><td>60</td><td>184</td><td>1804.94</td><td>14722.53</td><td>1442.44</td><td>⋯</td><td> 4532.47</td><td> 3</td><td> 4</td><td> 4</td><td> 0</td><td> 0</td><td> 0</td><td>1571.82</td><td>2029.29</td><td> 914.94</td></tr>\n",
       "\t<tr><td>29235399</td><td>201912</td><td>1</td><td>0</td><td>1</td><td>60</td><td>185</td><td>2993.06</td><td>16134.60</td><td>1321.80</td><td>⋯</td><td> 2421.36</td><td> 3</td><td> 3</td><td> 6</td><td> 0</td><td> 0</td><td> 0</td><td>1724.31</td><td>1888.53</td><td> 434.01</td></tr>\n",
       "\t<tr><td>29235399</td><td>202001</td><td>1</td><td>0</td><td>1</td><td>60</td><td>186</td><td>1902.43</td><td>16242.49</td><td> 390.40</td><td>⋯</td><td>22144.77</td><td> 3</td><td> 3</td><td>15</td><td> 0</td><td> 0</td><td> 0</td><td>1513.17</td><td>1571.82</td><td>2568.87</td></tr>\n",
       "\t<tr><td>29235399</td><td>202002</td><td>1</td><td>0</td><td>1</td><td>60</td><td>187</td><td>2182.74</td><td>17659.50</td><td> 873.31</td><td>⋯</td><td> 2967.51</td><td> 3</td><td> 3</td><td> 4</td><td> 0</td><td> 0</td><td> 0</td><td>1513.17</td><td>1724.31</td><td>2029.29</td></tr>\n",
       "\t<tr><td>29235399</td><td>202003</td><td>1</td><td>0</td><td>1</td><td>60</td><td>188</td><td>1810.86</td><td>18542.53</td><td>1627.78</td><td>⋯</td><td> 2604.06</td><td> 5</td><td> 3</td><td> 3</td><td> 0</td><td> 0</td><td> 0</td><td>2475.03</td><td>1513.17</td><td>1888.53</td></tr>\n",
       "\t<tr><td>29235399</td><td>202004</td><td>1</td><td>0</td><td>1</td><td>60</td><td>189</td><td>1552.37</td><td>17143.58</td><td>1449.13</td><td>⋯</td><td> 2604.06</td><td> 4</td><td> 3</td><td> 3</td><td> 0</td><td> 0</td><td> 0</td><td>2451.57</td><td>1513.17</td><td>1571.82</td></tr>\n",
       "\t<tr><td>29235399</td><td>202005</td><td>1</td><td>0</td><td>1</td><td>60</td><td>190</td><td>1849.97</td><td>17322.94</td><td>1449.32</td><td>⋯</td><td> 2709.63</td><td> 3</td><td> 5</td><td> 3</td><td> 0</td><td> 0</td><td> 0</td><td>2263.89</td><td>2475.03</td><td>1724.31</td></tr>\n",
       "\t<tr><td>29235399</td><td>202006</td><td>0</td><td>0</td><td>0</td><td>60</td><td>191</td><td>   0.00</td><td>    0.00</td><td>   0.00</td><td>⋯</td><td> 2709.63</td><td> 3</td><td> 4</td><td> 3</td><td> 0</td><td> 0</td><td> 0</td><td>2076.21</td><td>2451.57</td><td>1513.17</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋱</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>141405231</td><td>202010</td><td>1</td><td>0</td><td>0</td><td>25</td><td>50</td><td> 740.66</td><td>11520.93</td><td> 308.00</td><td>⋯</td><td> 7226.12</td><td> 6</td><td> 8</td><td> 5</td><td> 0</td><td> 0</td><td> 0</td><td>2815.20</td><td>2615.79</td><td> 445.74</td></tr>\n",
       "\t<tr><td>141405231</td><td>202011</td><td>1</td><td>0</td><td>0</td><td>25</td><td>51</td><td>1325.57</td><td>11930.60</td><td> 443.46</td><td>⋯</td><td>13824.80</td><td>10</td><td> 4</td><td> 6</td><td> 0</td><td> 0</td><td> 0</td><td>3354.78</td><td>2205.24</td><td>2275.62</td></tr>\n",
       "\t<tr><td>141405231</td><td>202012</td><td>1</td><td>0</td><td>0</td><td>25</td><td>52</td><td>2002.89</td><td>12971.81</td><td> 380.15</td><td>⋯</td><td>33331.48</td><td> 9</td><td> 6</td><td>10</td><td> 0</td><td> 0</td><td> 0</td><td>3214.02</td><td>2815.20</td><td>3483.81</td></tr>\n",
       "\t<tr><td>141405231</td><td>202101</td><td>1</td><td>0</td><td>0</td><td>25</td><td>53</td><td>1971.61</td><td>14487.85</td><td> 180.52</td><td>⋯</td><td>14782.72</td><td> 9</td><td>10</td><td> 8</td><td> 0</td><td> 0</td><td> 0</td><td>3659.76</td><td>3354.78</td><td>2615.79</td></tr>\n",
       "\t<tr><td>141405231</td><td>202102</td><td>1</td><td>0</td><td>0</td><td>25</td><td>54</td><td>2001.47</td><td>16252.38</td><td>2012.35</td><td>⋯</td><td> 5537.36</td><td> 7</td><td> 9</td><td> 4</td><td> 0</td><td> 0</td><td> 0</td><td>3237.48</td><td>3214.02</td><td>2205.24</td></tr>\n",
       "\t<tr><td>141405231</td><td>202103</td><td>1</td><td>0</td><td>0</td><td>25</td><td>55</td><td>-288.17</td><td>15031.81</td><td> 492.15</td><td>⋯</td><td>10096.67</td><td> 9</td><td> 9</td><td> 6</td><td> 0</td><td> 0</td><td> 0</td><td>3730.14</td><td>3659.76</td><td>2815.20</td></tr>\n",
       "\t<tr><td>141405231</td><td>202104</td><td>1</td><td>0</td><td>0</td><td>26</td><td>56</td><td> 875.16</td><td>14590.23</td><td> 485.02</td><td>⋯</td><td>20109.13</td><td>12</td><td> 7</td><td>10</td><td> 0</td><td> 0</td><td> 0</td><td>3319.59</td><td>3237.48</td><td>3354.78</td></tr>\n",
       "\t<tr><td>141405231</td><td>202105</td><td>1</td><td>0</td><td>0</td><td>26</td><td>57</td><td>2135.38</td><td>14961.69</td><td> 488.85</td><td>⋯</td><td>12826.76</td><td> 9</td><td> 9</td><td> 9</td><td> 0</td><td> 0</td><td> 0</td><td>3155.37</td><td>3730.14</td><td>3214.02</td></tr>\n",
       "\t<tr><td>141405231</td><td>202106</td><td>1</td><td>0</td><td>0</td><td>26</td><td>58</td><td>-954.82</td><td>12338.14</td><td> 304.40</td><td>⋯</td><td>20146.25</td><td>11</td><td>12</td><td> 9</td><td> 0</td><td> 0</td><td> 0</td><td>3847.44</td><td>3319.59</td><td>3659.76</td></tr>\n",
       "\t<tr><td>141405231</td><td>202107</td><td>1</td><td>0</td><td>0</td><td>26</td><td>59</td><td>-809.87</td><td>10681.31</td><td> 476.43</td><td>⋯</td><td>12794.20</td><td> 8</td><td> 9</td><td> 7</td><td> 0</td><td> 0</td><td> 0</td><td>3507.27</td><td>3155.37</td><td>3237.48</td></tr>\n",
       "\t<tr><td>141405231</td><td>202108</td><td>1</td><td>0</td><td>0</td><td>26</td><td>60</td><td>2172.81</td><td>11958.47</td><td> 456.54</td><td>⋯</td><td>36043.15</td><td>11</td><td>11</td><td> 9</td><td> 0</td><td> 0</td><td> 0</td><td>4105.50</td><td>3847.44</td><td>3730.14</td></tr>\n",
       "\t<tr><td>141405231</td><td>202109</td><td>1</td><td>0</td><td>0</td><td>26</td><td>61</td><td> 943.22</td><td>12115.95</td><td> 324.92</td><td>⋯</td><td>30825.51</td><td> 9</td><td> 8</td><td>12</td><td> 0</td><td> 0</td><td> 0</td><td>3800.52</td><td>3507.27</td><td>3319.59</td></tr>\n",
       "\t<tr><td>141457392</td><td>201901</td><td>1</td><td>0</td><td>1</td><td>23</td><td>29</td><td> 729.69</td><td> 7245.19</td><td> 475.27</td><td>⋯</td><td>      NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>     NA</td><td>     NA</td><td>     NA</td></tr>\n",
       "\t<tr><td>141457392</td><td>201902</td><td>1</td><td>0</td><td>1</td><td>23</td><td>30</td><td> 991.44</td><td> 7881.87</td><td> 479.54</td><td>⋯</td><td>      NA</td><td> 2</td><td>NA</td><td>NA</td><td> 0</td><td>NA</td><td>NA</td><td> 175.95</td><td>     NA</td><td>     NA</td></tr>\n",
       "\t<tr><td>141457392</td><td>201903</td><td>1</td><td>0</td><td>1</td><td>23</td><td>31</td><td> 960.05</td><td> 8674.00</td><td> 439.18</td><td>⋯</td><td>      NA</td><td> 1</td><td>NA</td><td>NA</td><td> 0</td><td>NA</td><td>NA</td><td>  11.73</td><td>     NA</td><td>     NA</td></tr>\n",
       "\t<tr><td>141457392</td><td>201904</td><td>1</td><td>0</td><td>1</td><td>23</td><td>32</td><td>1268.88</td><td> 9457.20</td><td> 425.23</td><td>⋯</td><td>      NA</td><td> 0</td><td> 2</td><td>NA</td><td> 0</td><td> 0</td><td>NA</td><td>   0.00</td><td> 175.95</td><td>     NA</td></tr>\n",
       "\t<tr><td>141457392</td><td>201905</td><td>1</td><td>0</td><td>1</td><td>23</td><td>33</td><td>   0.00</td><td>    0.00</td><td>   0.00</td><td>⋯</td><td>      NA</td><td> 0</td><td> 1</td><td>NA</td><td> 0</td><td> 0</td><td>NA</td><td>  58.65</td><td>  11.73</td><td>     NA</td></tr>\n",
       "\t<tr><td>141457392</td><td>201906</td><td>1</td><td>0</td><td>1</td><td>23</td><td>34</td><td>2075.13</td><td>12656.71</td><td> 458.47</td><td>⋯</td><td>      NA</td><td> 0</td><td> 0</td><td>NA</td><td> 0</td><td> 0</td><td>NA</td><td>  58.65</td><td>   0.00</td><td>     NA</td></tr>\n",
       "\t<tr><td>141457392</td><td>201907</td><td>1</td><td>0</td><td>1</td><td>23</td><td>35</td><td>2447.24</td><td>14809.06</td><td> 497.31</td><td>⋯</td><td> 3988.20</td><td> 1</td><td> 0</td><td> 2</td><td> 0</td><td> 0</td><td> 0</td><td>  58.65</td><td>  58.65</td><td> 175.95</td></tr>\n",
       "\t<tr><td>141457392</td><td>201908</td><td>1</td><td>0</td><td>1</td><td>24</td><td>36</td><td>2530.20</td><td>17082.96</td><td> 556.45</td><td>⋯</td><td>  492.66</td><td> 3</td><td> 0</td><td> 1</td><td> 0</td><td> 0</td><td> 0</td><td> 164.22</td><td>  58.65</td><td>  11.73</td></tr>\n",
       "\t<tr><td>141457392</td><td>201909</td><td>1</td><td>0</td><td>1</td><td>24</td><td>37</td><td>2535.08</td><td>18999.16</td><td>1062.58</td><td>⋯</td><td>    0.00</td><td> 3</td><td> 1</td><td> 0</td><td> 0</td><td> 0</td><td> 0</td><td>   0.00</td><td>  58.65</td><td>   0.00</td></tr>\n",
       "\t<tr><td>141457392</td><td>201910</td><td>1</td><td>0</td><td>1</td><td>24</td><td>38</td><td>   0.00</td><td>    0.00</td><td>   0.00</td><td>⋯</td><td>    0.00</td><td> 0</td><td> 3</td><td> 0</td><td> 0</td><td> 0</td><td> 0</td><td>  46.92</td><td> 164.22</td><td>  58.65</td></tr>\n",
       "\t<tr><td>141457392</td><td>201911</td><td>1</td><td>0</td><td>1</td><td>24</td><td>39</td><td>2649.77</td><td>23222.76</td><td>1053.79</td><td>⋯</td><td>    0.00</td><td> 0</td><td> 3</td><td> 0</td><td> 0</td><td> 0</td><td> 0</td><td> 129.03</td><td>   0.00</td><td>  58.65</td></tr>\n",
       "\t<tr><td>141457392</td><td>201912</td><td>1</td><td>0</td><td>1</td><td>24</td><td>40</td><td>2419.20</td><td>23285.77</td><td>1021.64</td><td>⋯</td><td>   50.08</td><td> 0</td><td> 0</td><td> 1</td><td> 0</td><td> 0</td><td> 0</td><td>   0.00</td><td>  46.92</td><td>  58.65</td></tr>\n",
       "\t<tr><td>141457392</td><td>202001</td><td>1</td><td>0</td><td>1</td><td>24</td><td>41</td><td>2614.01</td><td>25170.09</td><td>1376.69</td><td>⋯</td><td> 2656.35</td><td> 0</td><td> 0</td><td> 3</td><td> 0</td><td> 0</td><td> 0</td><td>   0.00</td><td> 129.03</td><td> 164.22</td></tr>\n",
       "\t<tr><td>141457392</td><td>202002</td><td>1</td><td>0</td><td>1</td><td>24</td><td>42</td><td>1818.39</td><td>25997.04</td><td>1346.34</td><td>⋯</td><td> 9723.30</td><td>NA</td><td> 0</td><td> 3</td><td>NA</td><td> 0</td><td> 0</td><td>   0.00</td><td>   0.00</td><td>   0.00</td></tr>\n",
       "\t<tr><td>141523225</td><td>201910</td><td>1</td><td>0</td><td>1</td><td>34</td><td>38</td><td>   0.00</td><td>    0.00</td><td>   0.00</td><td>⋯</td><td>      NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>     NA</td><td>     NA</td><td>     NA</td></tr>\n",
       "\t<tr><td>141523225</td><td>201911</td><td>1</td><td>0</td><td>1</td><td>34</td><td>39</td><td> 223.93</td><td>10185.90</td><td> 484.08</td><td>⋯</td><td>      NA</td><td> 6</td><td>NA</td><td>NA</td><td> 0</td><td>NA</td><td>NA</td><td> 609.96</td><td>     NA</td><td>     NA</td></tr>\n",
       "\t<tr><td>141523225</td><td>201912</td><td>1</td><td>0</td><td>1</td><td>34</td><td>40</td><td> -21.75</td><td> 9239.60</td><td> 213.47</td><td>⋯</td><td>      NA</td><td> 5</td><td>NA</td><td>NA</td><td> 0</td><td>NA</td><td>NA</td><td>1137.81</td><td>     NA</td><td>     NA</td></tr>\n",
       "\t<tr><td>141523225</td><td>202001</td><td>1</td><td>0</td><td>1</td><td>34</td><td>41</td><td>  46.29</td><td> 8808.30</td><td>2869.85</td><td>⋯</td><td>      NA</td><td> 5</td><td> 6</td><td>NA</td><td> 0</td><td> 0</td><td>NA</td><td>1548.36</td><td> 609.96</td><td>     NA</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 4893028 × 602\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " numero\\_de\\_cliente & foto\\_mes & active\\_quarter & cliente\\_vip & internet & cliente\\_edad & cliente\\_antiguedad & mrentabilidad & mrentabilidad\\_annual & mcomisiones & ⋯ & lag\\_6\\_Visa\\_mconsumototal & lag\\_1\\_Visa\\_cconsumos & lag\\_3\\_Visa\\_cconsumos & lag\\_6\\_Visa\\_cconsumos & lag\\_1\\_Visa\\_cadelantosefectivo & lag\\_3\\_Visa\\_cadelantosefectivo & lag\\_6\\_Visa\\_cadelantosefectivo & lag\\_1\\_Visa\\_mpagominimo & lag\\_3\\_Visa\\_mpagominimo & lag\\_6\\_Visa\\_mpagominimo\\\\\n",
       " <int> & <int> & <int> & <int> & <int> & <int> & <int> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <int> & <int> & <int> & <int> & <int> & <int> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 29234246 & 202003 & 1 & 0 & 0 & 61 & 280 &  497.55 & 10740.15 &    9.85 & ⋯ &       NA & NA & NA & NA & NA & NA & NA &      NA &      NA &      NA\\\\\n",
       "\t 29234246 & 202004 & 1 & 0 & 1 & 61 & 281 & 1148.00 & 11473.76 &    9.85 & ⋯ &       NA & NA & NA & NA & NA & NA & NA &    0.00 &      NA &      NA\\\\\n",
       "\t 29234246 & 202005 & 1 & 0 & 1 & 61 & 282 & 1716.07 & 12906.70 &   17.09 & ⋯ &       NA & NA & NA & NA & NA & NA & NA &    0.00 &      NA &      NA\\\\\n",
       "\t 29234246 & 202006 & 0 & 0 & 0 & 61 & 283 &    0.00 &     0.00 &    0.00 & ⋯ &       NA & NA & NA & NA & NA & NA & NA &    0.00 &    0.00 &      NA\\\\\n",
       "\t 29234246 & 202007 & 1 & 0 & 1 & 61 & 284 & 1843.89 & 13487.06 &   13.98 & ⋯ &       NA & NA & NA & NA & NA & NA & NA &    0.00 &    0.00 &      NA\\\\\n",
       "\t 29234246 & 202008 & 1 & 0 & 1 & 62 & 285 & 1479.17 & 13404.26 &   13.85 & ⋯ &       NA & NA & NA & NA & NA & NA & NA &    0.00 &    0.00 &      NA\\\\\n",
       "\t 29234246 & 202009 & 1 & 0 & 1 & 62 & 286 & 2121.81 & 14320.19 &   17.29 & ⋯ &       NA & NA & NA & NA & NA & NA & NA &    0.00 &    0.00 &    0.00\\\\\n",
       "\t 29234246 & 202010 & 1 & 0 & 0 & 62 & 287 & 4303.36 & 17865.74 & 2367.26 & ⋯ &       NA & NA & NA & NA & NA & NA & NA &    0.00 &    0.00 &    0.00\\\\\n",
       "\t 29234246 & 202011 & 1 & 0 & 0 & 62 & 288 & 3702.42 & 21318.99 & 2367.27 & ⋯ &       NA & NA & NA & NA & NA & NA & NA &    0.00 &    0.00 &    0.00\\\\\n",
       "\t 29234246 & 202012 & 1 & 0 & 0 & 62 & 289 & 4394.43 & 25032.74 & 2382.39 & ⋯ &       NA & NA & NA & NA & NA & NA & NA &    0.00 &    0.00 &    0.00\\\\\n",
       "\t 29234246 & 202101 & 1 & 0 & 0 & 62 & 290 & 4519.04 & 28757.53 & 2372.25 & ⋯ &       NA & NA & NA & NA & NA & NA & NA &    0.00 &    0.00 &    0.00\\\\\n",
       "\t 29234246 & 202102 & 1 & 0 & 0 & 62 & 291 & 1515.44 & 28934.66 &   22.09 & ⋯ &       NA & NA & NA & NA & NA & NA & NA &    0.00 &    0.00 &    0.00\\\\\n",
       "\t 29235399 & 201901 & 1 & 0 & 1 & 59 & 174 & 1794.53 &  7842.29 &  295.73 & ⋯ &       NA & NA & NA & NA & NA & NA & NA &      NA &      NA &      NA\\\\\n",
       "\t 29235399 & 201902 & 1 & 0 & 1 & 59 & 175 &  765.73 &  8205.41 &  204.86 & ⋯ &       NA &  1 & NA & NA &  0 & NA & NA &  692.07 &      NA &      NA\\\\\n",
       "\t 29235399 & 201903 & 1 & 0 & 1 & 59 & 176 &  927.83 &  8670.28 &  177.54 & ⋯ &       NA &  4 & NA & NA &  0 & NA & NA &  797.64 &      NA &      NA\\\\\n",
       "\t 29235399 & 201904 & 1 & 0 & 1 & 59 & 177 & 2951.32 & 11260.80 & 1337.02 & ⋯ &       NA &  3 &  1 & NA &  0 &  0 & NA &  527.85 &  692.07 &      NA\\\\\n",
       "\t 29235399 & 201905 & 1 & 0 & 1 & 59 & 178 &    0.00 &     0.00 &    0.00 & ⋯ &       NA &  5 &  4 & NA &  0 &  0 & NA & 1055.70 &  797.64 &      NA\\\\\n",
       "\t 29235399 & 201906 & 1 & 0 & 1 & 60 & 179 & 1239.32 & 13242.19 & 1085.64 & ⋯ &       NA &  4 &  3 & NA &  0 &  0 & NA &  914.94 &  527.85 &      NA\\\\\n",
       "\t 29235399 & 201907 & 1 & 0 & 1 & 60 & 180 &  641.43 & 13460.36 & 1763.40 & ⋯ &   809.37 &  6 &  5 &  1 &  0 &  0 &  0 &  434.01 & 1055.70 &  692.07\\\\\n",
       "\t 29235399 & 201908 & 1 & 0 & 1 & 60 & 181 &  336.69 & 13896.07 & 1395.47 & ⋯ &  2772.97 & 15 &  4 &  4 &  0 &  0 &  0 & 2568.87 &  914.94 &  797.64\\\\\n",
       "\t 29235399 & 201909 & 1 & 0 & 1 & 60 & 182 &  398.97 & 13973.28 & 1706.33 & ⋯ &  2046.88 &  4 &  6 &  3 &  0 &  0 &  0 & 2029.29 &  434.01 &  527.85\\\\\n",
       "\t 29235399 & 201910 & 1 & 0 & 1 & 60 & 183 &    0.00 &     0.00 &    0.00 & ⋯ &  6668.90 &  3 & 15 &  5 &  0 &  0 &  0 & 1888.53 & 2568.87 & 1055.70\\\\\n",
       "\t 29235399 & 201911 & 1 & 0 & 1 & 60 & 184 & 1804.94 & 14722.53 & 1442.44 & ⋯ &  4532.47 &  3 &  4 &  4 &  0 &  0 &  0 & 1571.82 & 2029.29 &  914.94\\\\\n",
       "\t 29235399 & 201912 & 1 & 0 & 1 & 60 & 185 & 2993.06 & 16134.60 & 1321.80 & ⋯ &  2421.36 &  3 &  3 &  6 &  0 &  0 &  0 & 1724.31 & 1888.53 &  434.01\\\\\n",
       "\t 29235399 & 202001 & 1 & 0 & 1 & 60 & 186 & 1902.43 & 16242.49 &  390.40 & ⋯ & 22144.77 &  3 &  3 & 15 &  0 &  0 &  0 & 1513.17 & 1571.82 & 2568.87\\\\\n",
       "\t 29235399 & 202002 & 1 & 0 & 1 & 60 & 187 & 2182.74 & 17659.50 &  873.31 & ⋯ &  2967.51 &  3 &  3 &  4 &  0 &  0 &  0 & 1513.17 & 1724.31 & 2029.29\\\\\n",
       "\t 29235399 & 202003 & 1 & 0 & 1 & 60 & 188 & 1810.86 & 18542.53 & 1627.78 & ⋯ &  2604.06 &  5 &  3 &  3 &  0 &  0 &  0 & 2475.03 & 1513.17 & 1888.53\\\\\n",
       "\t 29235399 & 202004 & 1 & 0 & 1 & 60 & 189 & 1552.37 & 17143.58 & 1449.13 & ⋯ &  2604.06 &  4 &  3 &  3 &  0 &  0 &  0 & 2451.57 & 1513.17 & 1571.82\\\\\n",
       "\t 29235399 & 202005 & 1 & 0 & 1 & 60 & 190 & 1849.97 & 17322.94 & 1449.32 & ⋯ &  2709.63 &  3 &  5 &  3 &  0 &  0 &  0 & 2263.89 & 2475.03 & 1724.31\\\\\n",
       "\t 29235399 & 202006 & 0 & 0 & 0 & 60 & 191 &    0.00 &     0.00 &    0.00 & ⋯ &  2709.63 &  3 &  4 &  3 &  0 &  0 &  0 & 2076.21 & 2451.57 & 1513.17\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋱ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t 141405231 & 202010 & 1 & 0 & 0 & 25 & 50 &  740.66 & 11520.93 &  308.00 & ⋯ &  7226.12 &  6 &  8 &  5 &  0 &  0 &  0 & 2815.20 & 2615.79 &  445.74\\\\\n",
       "\t 141405231 & 202011 & 1 & 0 & 0 & 25 & 51 & 1325.57 & 11930.60 &  443.46 & ⋯ & 13824.80 & 10 &  4 &  6 &  0 &  0 &  0 & 3354.78 & 2205.24 & 2275.62\\\\\n",
       "\t 141405231 & 202012 & 1 & 0 & 0 & 25 & 52 & 2002.89 & 12971.81 &  380.15 & ⋯ & 33331.48 &  9 &  6 & 10 &  0 &  0 &  0 & 3214.02 & 2815.20 & 3483.81\\\\\n",
       "\t 141405231 & 202101 & 1 & 0 & 0 & 25 & 53 & 1971.61 & 14487.85 &  180.52 & ⋯ & 14782.72 &  9 & 10 &  8 &  0 &  0 &  0 & 3659.76 & 3354.78 & 2615.79\\\\\n",
       "\t 141405231 & 202102 & 1 & 0 & 0 & 25 & 54 & 2001.47 & 16252.38 & 2012.35 & ⋯ &  5537.36 &  7 &  9 &  4 &  0 &  0 &  0 & 3237.48 & 3214.02 & 2205.24\\\\\n",
       "\t 141405231 & 202103 & 1 & 0 & 0 & 25 & 55 & -288.17 & 15031.81 &  492.15 & ⋯ & 10096.67 &  9 &  9 &  6 &  0 &  0 &  0 & 3730.14 & 3659.76 & 2815.20\\\\\n",
       "\t 141405231 & 202104 & 1 & 0 & 0 & 26 & 56 &  875.16 & 14590.23 &  485.02 & ⋯ & 20109.13 & 12 &  7 & 10 &  0 &  0 &  0 & 3319.59 & 3237.48 & 3354.78\\\\\n",
       "\t 141405231 & 202105 & 1 & 0 & 0 & 26 & 57 & 2135.38 & 14961.69 &  488.85 & ⋯ & 12826.76 &  9 &  9 &  9 &  0 &  0 &  0 & 3155.37 & 3730.14 & 3214.02\\\\\n",
       "\t 141405231 & 202106 & 1 & 0 & 0 & 26 & 58 & -954.82 & 12338.14 &  304.40 & ⋯ & 20146.25 & 11 & 12 &  9 &  0 &  0 &  0 & 3847.44 & 3319.59 & 3659.76\\\\\n",
       "\t 141405231 & 202107 & 1 & 0 & 0 & 26 & 59 & -809.87 & 10681.31 &  476.43 & ⋯ & 12794.20 &  8 &  9 &  7 &  0 &  0 &  0 & 3507.27 & 3155.37 & 3237.48\\\\\n",
       "\t 141405231 & 202108 & 1 & 0 & 0 & 26 & 60 & 2172.81 & 11958.47 &  456.54 & ⋯ & 36043.15 & 11 & 11 &  9 &  0 &  0 &  0 & 4105.50 & 3847.44 & 3730.14\\\\\n",
       "\t 141405231 & 202109 & 1 & 0 & 0 & 26 & 61 &  943.22 & 12115.95 &  324.92 & ⋯ & 30825.51 &  9 &  8 & 12 &  0 &  0 &  0 & 3800.52 & 3507.27 & 3319.59\\\\\n",
       "\t 141457392 & 201901 & 1 & 0 & 1 & 23 & 29 &  729.69 &  7245.19 &  475.27 & ⋯ &       NA & NA & NA & NA & NA & NA & NA &      NA &      NA &      NA\\\\\n",
       "\t 141457392 & 201902 & 1 & 0 & 1 & 23 & 30 &  991.44 &  7881.87 &  479.54 & ⋯ &       NA &  2 & NA & NA &  0 & NA & NA &  175.95 &      NA &      NA\\\\\n",
       "\t 141457392 & 201903 & 1 & 0 & 1 & 23 & 31 &  960.05 &  8674.00 &  439.18 & ⋯ &       NA &  1 & NA & NA &  0 & NA & NA &   11.73 &      NA &      NA\\\\\n",
       "\t 141457392 & 201904 & 1 & 0 & 1 & 23 & 32 & 1268.88 &  9457.20 &  425.23 & ⋯ &       NA &  0 &  2 & NA &  0 &  0 & NA &    0.00 &  175.95 &      NA\\\\\n",
       "\t 141457392 & 201905 & 1 & 0 & 1 & 23 & 33 &    0.00 &     0.00 &    0.00 & ⋯ &       NA &  0 &  1 & NA &  0 &  0 & NA &   58.65 &   11.73 &      NA\\\\\n",
       "\t 141457392 & 201906 & 1 & 0 & 1 & 23 & 34 & 2075.13 & 12656.71 &  458.47 & ⋯ &       NA &  0 &  0 & NA &  0 &  0 & NA &   58.65 &    0.00 &      NA\\\\\n",
       "\t 141457392 & 201907 & 1 & 0 & 1 & 23 & 35 & 2447.24 & 14809.06 &  497.31 & ⋯ &  3988.20 &  1 &  0 &  2 &  0 &  0 &  0 &   58.65 &   58.65 &  175.95\\\\\n",
       "\t 141457392 & 201908 & 1 & 0 & 1 & 24 & 36 & 2530.20 & 17082.96 &  556.45 & ⋯ &   492.66 &  3 &  0 &  1 &  0 &  0 &  0 &  164.22 &   58.65 &   11.73\\\\\n",
       "\t 141457392 & 201909 & 1 & 0 & 1 & 24 & 37 & 2535.08 & 18999.16 & 1062.58 & ⋯ &     0.00 &  3 &  1 &  0 &  0 &  0 &  0 &    0.00 &   58.65 &    0.00\\\\\n",
       "\t 141457392 & 201910 & 1 & 0 & 1 & 24 & 38 &    0.00 &     0.00 &    0.00 & ⋯ &     0.00 &  0 &  3 &  0 &  0 &  0 &  0 &   46.92 &  164.22 &   58.65\\\\\n",
       "\t 141457392 & 201911 & 1 & 0 & 1 & 24 & 39 & 2649.77 & 23222.76 & 1053.79 & ⋯ &     0.00 &  0 &  3 &  0 &  0 &  0 &  0 &  129.03 &    0.00 &   58.65\\\\\n",
       "\t 141457392 & 201912 & 1 & 0 & 1 & 24 & 40 & 2419.20 & 23285.77 & 1021.64 & ⋯ &    50.08 &  0 &  0 &  1 &  0 &  0 &  0 &    0.00 &   46.92 &   58.65\\\\\n",
       "\t 141457392 & 202001 & 1 & 0 & 1 & 24 & 41 & 2614.01 & 25170.09 & 1376.69 & ⋯ &  2656.35 &  0 &  0 &  3 &  0 &  0 &  0 &    0.00 &  129.03 &  164.22\\\\\n",
       "\t 141457392 & 202002 & 1 & 0 & 1 & 24 & 42 & 1818.39 & 25997.04 & 1346.34 & ⋯ &  9723.30 & NA &  0 &  3 & NA &  0 &  0 &    0.00 &    0.00 &    0.00\\\\\n",
       "\t 141523225 & 201910 & 1 & 0 & 1 & 34 & 38 &    0.00 &     0.00 &    0.00 & ⋯ &       NA & NA & NA & NA & NA & NA & NA &      NA &      NA &      NA\\\\\n",
       "\t 141523225 & 201911 & 1 & 0 & 1 & 34 & 39 &  223.93 & 10185.90 &  484.08 & ⋯ &       NA &  6 & NA & NA &  0 & NA & NA &  609.96 &      NA &      NA\\\\\n",
       "\t 141523225 & 201912 & 1 & 0 & 1 & 34 & 40 &  -21.75 &  9239.60 &  213.47 & ⋯ &       NA &  5 & NA & NA &  0 & NA & NA & 1137.81 &      NA &      NA\\\\\n",
       "\t 141523225 & 202001 & 1 & 0 & 1 & 34 & 41 &   46.29 &  8808.30 & 2869.85 & ⋯ &       NA &  5 &  6 & NA &  0 &  0 & NA & 1548.36 &  609.96 &      NA\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 4893028 × 602\n",
       "\n",
       "| numero_de_cliente &lt;int&gt; | foto_mes &lt;int&gt; | active_quarter &lt;int&gt; | cliente_vip &lt;int&gt; | internet &lt;int&gt; | cliente_edad &lt;int&gt; | cliente_antiguedad &lt;int&gt; | mrentabilidad &lt;dbl&gt; | mrentabilidad_annual &lt;dbl&gt; | mcomisiones &lt;dbl&gt; | ⋯ ⋯ | lag_6_Visa_mconsumototal &lt;dbl&gt; | lag_1_Visa_cconsumos &lt;int&gt; | lag_3_Visa_cconsumos &lt;int&gt; | lag_6_Visa_cconsumos &lt;int&gt; | lag_1_Visa_cadelantosefectivo &lt;int&gt; | lag_3_Visa_cadelantosefectivo &lt;int&gt; | lag_6_Visa_cadelantosefectivo &lt;int&gt; | lag_1_Visa_mpagominimo &lt;dbl&gt; | lag_3_Visa_mpagominimo &lt;dbl&gt; | lag_6_Visa_mpagominimo &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 29234246 | 202003 | 1 | 0 | 0 | 61 | 280 |  497.55 | 10740.15 |    9.85 | ⋯ |       NA | NA | NA | NA | NA | NA | NA |      NA |      NA |      NA |\n",
       "| 29234246 | 202004 | 1 | 0 | 1 | 61 | 281 | 1148.00 | 11473.76 |    9.85 | ⋯ |       NA | NA | NA | NA | NA | NA | NA |    0.00 |      NA |      NA |\n",
       "| 29234246 | 202005 | 1 | 0 | 1 | 61 | 282 | 1716.07 | 12906.70 |   17.09 | ⋯ |       NA | NA | NA | NA | NA | NA | NA |    0.00 |      NA |      NA |\n",
       "| 29234246 | 202006 | 0 | 0 | 0 | 61 | 283 |    0.00 |     0.00 |    0.00 | ⋯ |       NA | NA | NA | NA | NA | NA | NA |    0.00 |    0.00 |      NA |\n",
       "| 29234246 | 202007 | 1 | 0 | 1 | 61 | 284 | 1843.89 | 13487.06 |   13.98 | ⋯ |       NA | NA | NA | NA | NA | NA | NA |    0.00 |    0.00 |      NA |\n",
       "| 29234246 | 202008 | 1 | 0 | 1 | 62 | 285 | 1479.17 | 13404.26 |   13.85 | ⋯ |       NA | NA | NA | NA | NA | NA | NA |    0.00 |    0.00 |      NA |\n",
       "| 29234246 | 202009 | 1 | 0 | 1 | 62 | 286 | 2121.81 | 14320.19 |   17.29 | ⋯ |       NA | NA | NA | NA | NA | NA | NA |    0.00 |    0.00 |    0.00 |\n",
       "| 29234246 | 202010 | 1 | 0 | 0 | 62 | 287 | 4303.36 | 17865.74 | 2367.26 | ⋯ |       NA | NA | NA | NA | NA | NA | NA |    0.00 |    0.00 |    0.00 |\n",
       "| 29234246 | 202011 | 1 | 0 | 0 | 62 | 288 | 3702.42 | 21318.99 | 2367.27 | ⋯ |       NA | NA | NA | NA | NA | NA | NA |    0.00 |    0.00 |    0.00 |\n",
       "| 29234246 | 202012 | 1 | 0 | 0 | 62 | 289 | 4394.43 | 25032.74 | 2382.39 | ⋯ |       NA | NA | NA | NA | NA | NA | NA |    0.00 |    0.00 |    0.00 |\n",
       "| 29234246 | 202101 | 1 | 0 | 0 | 62 | 290 | 4519.04 | 28757.53 | 2372.25 | ⋯ |       NA | NA | NA | NA | NA | NA | NA |    0.00 |    0.00 |    0.00 |\n",
       "| 29234246 | 202102 | 1 | 0 | 0 | 62 | 291 | 1515.44 | 28934.66 |   22.09 | ⋯ |       NA | NA | NA | NA | NA | NA | NA |    0.00 |    0.00 |    0.00 |\n",
       "| 29235399 | 201901 | 1 | 0 | 1 | 59 | 174 | 1794.53 |  7842.29 |  295.73 | ⋯ |       NA | NA | NA | NA | NA | NA | NA |      NA |      NA |      NA |\n",
       "| 29235399 | 201902 | 1 | 0 | 1 | 59 | 175 |  765.73 |  8205.41 |  204.86 | ⋯ |       NA |  1 | NA | NA |  0 | NA | NA |  692.07 |      NA |      NA |\n",
       "| 29235399 | 201903 | 1 | 0 | 1 | 59 | 176 |  927.83 |  8670.28 |  177.54 | ⋯ |       NA |  4 | NA | NA |  0 | NA | NA |  797.64 |      NA |      NA |\n",
       "| 29235399 | 201904 | 1 | 0 | 1 | 59 | 177 | 2951.32 | 11260.80 | 1337.02 | ⋯ |       NA |  3 |  1 | NA |  0 |  0 | NA |  527.85 |  692.07 |      NA |\n",
       "| 29235399 | 201905 | 1 | 0 | 1 | 59 | 178 |    0.00 |     0.00 |    0.00 | ⋯ |       NA |  5 |  4 | NA |  0 |  0 | NA | 1055.70 |  797.64 |      NA |\n",
       "| 29235399 | 201906 | 1 | 0 | 1 | 60 | 179 | 1239.32 | 13242.19 | 1085.64 | ⋯ |       NA |  4 |  3 | NA |  0 |  0 | NA |  914.94 |  527.85 |      NA |\n",
       "| 29235399 | 201907 | 1 | 0 | 1 | 60 | 180 |  641.43 | 13460.36 | 1763.40 | ⋯ |   809.37 |  6 |  5 |  1 |  0 |  0 |  0 |  434.01 | 1055.70 |  692.07 |\n",
       "| 29235399 | 201908 | 1 | 0 | 1 | 60 | 181 |  336.69 | 13896.07 | 1395.47 | ⋯ |  2772.97 | 15 |  4 |  4 |  0 |  0 |  0 | 2568.87 |  914.94 |  797.64 |\n",
       "| 29235399 | 201909 | 1 | 0 | 1 | 60 | 182 |  398.97 | 13973.28 | 1706.33 | ⋯ |  2046.88 |  4 |  6 |  3 |  0 |  0 |  0 | 2029.29 |  434.01 |  527.85 |\n",
       "| 29235399 | 201910 | 1 | 0 | 1 | 60 | 183 |    0.00 |     0.00 |    0.00 | ⋯ |  6668.90 |  3 | 15 |  5 |  0 |  0 |  0 | 1888.53 | 2568.87 | 1055.70 |\n",
       "| 29235399 | 201911 | 1 | 0 | 1 | 60 | 184 | 1804.94 | 14722.53 | 1442.44 | ⋯ |  4532.47 |  3 |  4 |  4 |  0 |  0 |  0 | 1571.82 | 2029.29 |  914.94 |\n",
       "| 29235399 | 201912 | 1 | 0 | 1 | 60 | 185 | 2993.06 | 16134.60 | 1321.80 | ⋯ |  2421.36 |  3 |  3 |  6 |  0 |  0 |  0 | 1724.31 | 1888.53 |  434.01 |\n",
       "| 29235399 | 202001 | 1 | 0 | 1 | 60 | 186 | 1902.43 | 16242.49 |  390.40 | ⋯ | 22144.77 |  3 |  3 | 15 |  0 |  0 |  0 | 1513.17 | 1571.82 | 2568.87 |\n",
       "| 29235399 | 202002 | 1 | 0 | 1 | 60 | 187 | 2182.74 | 17659.50 |  873.31 | ⋯ |  2967.51 |  3 |  3 |  4 |  0 |  0 |  0 | 1513.17 | 1724.31 | 2029.29 |\n",
       "| 29235399 | 202003 | 1 | 0 | 1 | 60 | 188 | 1810.86 | 18542.53 | 1627.78 | ⋯ |  2604.06 |  5 |  3 |  3 |  0 |  0 |  0 | 2475.03 | 1513.17 | 1888.53 |\n",
       "| 29235399 | 202004 | 1 | 0 | 1 | 60 | 189 | 1552.37 | 17143.58 | 1449.13 | ⋯ |  2604.06 |  4 |  3 |  3 |  0 |  0 |  0 | 2451.57 | 1513.17 | 1571.82 |\n",
       "| 29235399 | 202005 | 1 | 0 | 1 | 60 | 190 | 1849.97 | 17322.94 | 1449.32 | ⋯ |  2709.63 |  3 |  5 |  3 |  0 |  0 |  0 | 2263.89 | 2475.03 | 1724.31 |\n",
       "| 29235399 | 202006 | 0 | 0 | 0 | 60 | 191 |    0.00 |     0.00 |    0.00 | ⋯ |  2709.63 |  3 |  4 |  3 |  0 |  0 |  0 | 2076.21 | 2451.57 | 1513.17 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋱ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| 141405231 | 202010 | 1 | 0 | 0 | 25 | 50 |  740.66 | 11520.93 |  308.00 | ⋯ |  7226.12 |  6 |  8 |  5 |  0 |  0 |  0 | 2815.20 | 2615.79 |  445.74 |\n",
       "| 141405231 | 202011 | 1 | 0 | 0 | 25 | 51 | 1325.57 | 11930.60 |  443.46 | ⋯ | 13824.80 | 10 |  4 |  6 |  0 |  0 |  0 | 3354.78 | 2205.24 | 2275.62 |\n",
       "| 141405231 | 202012 | 1 | 0 | 0 | 25 | 52 | 2002.89 | 12971.81 |  380.15 | ⋯ | 33331.48 |  9 |  6 | 10 |  0 |  0 |  0 | 3214.02 | 2815.20 | 3483.81 |\n",
       "| 141405231 | 202101 | 1 | 0 | 0 | 25 | 53 | 1971.61 | 14487.85 |  180.52 | ⋯ | 14782.72 |  9 | 10 |  8 |  0 |  0 |  0 | 3659.76 | 3354.78 | 2615.79 |\n",
       "| 141405231 | 202102 | 1 | 0 | 0 | 25 | 54 | 2001.47 | 16252.38 | 2012.35 | ⋯ |  5537.36 |  7 |  9 |  4 |  0 |  0 |  0 | 3237.48 | 3214.02 | 2205.24 |\n",
       "| 141405231 | 202103 | 1 | 0 | 0 | 25 | 55 | -288.17 | 15031.81 |  492.15 | ⋯ | 10096.67 |  9 |  9 |  6 |  0 |  0 |  0 | 3730.14 | 3659.76 | 2815.20 |\n",
       "| 141405231 | 202104 | 1 | 0 | 0 | 26 | 56 |  875.16 | 14590.23 |  485.02 | ⋯ | 20109.13 | 12 |  7 | 10 |  0 |  0 |  0 | 3319.59 | 3237.48 | 3354.78 |\n",
       "| 141405231 | 202105 | 1 | 0 | 0 | 26 | 57 | 2135.38 | 14961.69 |  488.85 | ⋯ | 12826.76 |  9 |  9 |  9 |  0 |  0 |  0 | 3155.37 | 3730.14 | 3214.02 |\n",
       "| 141405231 | 202106 | 1 | 0 | 0 | 26 | 58 | -954.82 | 12338.14 |  304.40 | ⋯ | 20146.25 | 11 | 12 |  9 |  0 |  0 |  0 | 3847.44 | 3319.59 | 3659.76 |\n",
       "| 141405231 | 202107 | 1 | 0 | 0 | 26 | 59 | -809.87 | 10681.31 |  476.43 | ⋯ | 12794.20 |  8 |  9 |  7 |  0 |  0 |  0 | 3507.27 | 3155.37 | 3237.48 |\n",
       "| 141405231 | 202108 | 1 | 0 | 0 | 26 | 60 | 2172.81 | 11958.47 |  456.54 | ⋯ | 36043.15 | 11 | 11 |  9 |  0 |  0 |  0 | 4105.50 | 3847.44 | 3730.14 |\n",
       "| 141405231 | 202109 | 1 | 0 | 0 | 26 | 61 |  943.22 | 12115.95 |  324.92 | ⋯ | 30825.51 |  9 |  8 | 12 |  0 |  0 |  0 | 3800.52 | 3507.27 | 3319.59 |\n",
       "| 141457392 | 201901 | 1 | 0 | 1 | 23 | 29 |  729.69 |  7245.19 |  475.27 | ⋯ |       NA | NA | NA | NA | NA | NA | NA |      NA |      NA |      NA |\n",
       "| 141457392 | 201902 | 1 | 0 | 1 | 23 | 30 |  991.44 |  7881.87 |  479.54 | ⋯ |       NA |  2 | NA | NA |  0 | NA | NA |  175.95 |      NA |      NA |\n",
       "| 141457392 | 201903 | 1 | 0 | 1 | 23 | 31 |  960.05 |  8674.00 |  439.18 | ⋯ |       NA |  1 | NA | NA |  0 | NA | NA |   11.73 |      NA |      NA |\n",
       "| 141457392 | 201904 | 1 | 0 | 1 | 23 | 32 | 1268.88 |  9457.20 |  425.23 | ⋯ |       NA |  0 |  2 | NA |  0 |  0 | NA |    0.00 |  175.95 |      NA |\n",
       "| 141457392 | 201905 | 1 | 0 | 1 | 23 | 33 |    0.00 |     0.00 |    0.00 | ⋯ |       NA |  0 |  1 | NA |  0 |  0 | NA |   58.65 |   11.73 |      NA |\n",
       "| 141457392 | 201906 | 1 | 0 | 1 | 23 | 34 | 2075.13 | 12656.71 |  458.47 | ⋯ |       NA |  0 |  0 | NA |  0 |  0 | NA |   58.65 |    0.00 |      NA |\n",
       "| 141457392 | 201907 | 1 | 0 | 1 | 23 | 35 | 2447.24 | 14809.06 |  497.31 | ⋯ |  3988.20 |  1 |  0 |  2 |  0 |  0 |  0 |   58.65 |   58.65 |  175.95 |\n",
       "| 141457392 | 201908 | 1 | 0 | 1 | 24 | 36 | 2530.20 | 17082.96 |  556.45 | ⋯ |   492.66 |  3 |  0 |  1 |  0 |  0 |  0 |  164.22 |   58.65 |   11.73 |\n",
       "| 141457392 | 201909 | 1 | 0 | 1 | 24 | 37 | 2535.08 | 18999.16 | 1062.58 | ⋯ |     0.00 |  3 |  1 |  0 |  0 |  0 |  0 |    0.00 |   58.65 |    0.00 |\n",
       "| 141457392 | 201910 | 1 | 0 | 1 | 24 | 38 |    0.00 |     0.00 |    0.00 | ⋯ |     0.00 |  0 |  3 |  0 |  0 |  0 |  0 |   46.92 |  164.22 |   58.65 |\n",
       "| 141457392 | 201911 | 1 | 0 | 1 | 24 | 39 | 2649.77 | 23222.76 | 1053.79 | ⋯ |     0.00 |  0 |  3 |  0 |  0 |  0 |  0 |  129.03 |    0.00 |   58.65 |\n",
       "| 141457392 | 201912 | 1 | 0 | 1 | 24 | 40 | 2419.20 | 23285.77 | 1021.64 | ⋯ |    50.08 |  0 |  0 |  1 |  0 |  0 |  0 |    0.00 |   46.92 |   58.65 |\n",
       "| 141457392 | 202001 | 1 | 0 | 1 | 24 | 41 | 2614.01 | 25170.09 | 1376.69 | ⋯ |  2656.35 |  0 |  0 |  3 |  0 |  0 |  0 |    0.00 |  129.03 |  164.22 |\n",
       "| 141457392 | 202002 | 1 | 0 | 1 | 24 | 42 | 1818.39 | 25997.04 | 1346.34 | ⋯ |  9723.30 | NA |  0 |  3 | NA |  0 |  0 |    0.00 |    0.00 |    0.00 |\n",
       "| 141523225 | 201910 | 1 | 0 | 1 | 34 | 38 |    0.00 |     0.00 |    0.00 | ⋯ |       NA | NA | NA | NA | NA | NA | NA |      NA |      NA |      NA |\n",
       "| 141523225 | 201911 | 1 | 0 | 1 | 34 | 39 |  223.93 | 10185.90 |  484.08 | ⋯ |       NA |  6 | NA | NA |  0 | NA | NA |  609.96 |      NA |      NA |\n",
       "| 141523225 | 201912 | 1 | 0 | 1 | 34 | 40 |  -21.75 |  9239.60 |  213.47 | ⋯ |       NA |  5 | NA | NA |  0 | NA | NA | 1137.81 |      NA |      NA |\n",
       "| 141523225 | 202001 | 1 | 0 | 1 | 34 | 41 |   46.29 |  8808.30 | 2869.85 | ⋯ |       NA |  5 |  6 | NA |  0 |  0 | NA | 1548.36 |  609.96 |      NA |\n",
       "\n"
      ],
      "text/plain": [
       "        numero_de_cliente foto_mes active_quarter cliente_vip internet\n",
       "1       29234246          202003   1              0           0       \n",
       "2       29234246          202004   1              0           1       \n",
       "3       29234246          202005   1              0           1       \n",
       "4       29234246          202006   0              0           0       \n",
       "5       29234246          202007   1              0           1       \n",
       "6       29234246          202008   1              0           1       \n",
       "7       29234246          202009   1              0           1       \n",
       "8       29234246          202010   1              0           0       \n",
       "9       29234246          202011   1              0           0       \n",
       "10      29234246          202012   1              0           0       \n",
       "11      29234246          202101   1              0           0       \n",
       "12      29234246          202102   1              0           0       \n",
       "13      29235399          201901   1              0           1       \n",
       "14      29235399          201902   1              0           1       \n",
       "15      29235399          201903   1              0           1       \n",
       "16      29235399          201904   1              0           1       \n",
       "17      29235399          201905   1              0           1       \n",
       "18      29235399          201906   1              0           1       \n",
       "19      29235399          201907   1              0           1       \n",
       "20      29235399          201908   1              0           1       \n",
       "21      29235399          201909   1              0           1       \n",
       "22      29235399          201910   1              0           1       \n",
       "23      29235399          201911   1              0           1       \n",
       "24      29235399          201912   1              0           1       \n",
       "25      29235399          202001   1              0           1       \n",
       "26      29235399          202002   1              0           1       \n",
       "27      29235399          202003   1              0           1       \n",
       "28      29235399          202004   1              0           1       \n",
       "29      29235399          202005   1              0           1       \n",
       "30      29235399          202006   0              0           0       \n",
       "⋮       ⋮                 ⋮        ⋮              ⋮           ⋮       \n",
       "4892999 141405231         202010   1              0           0       \n",
       "4893000 141405231         202011   1              0           0       \n",
       "4893001 141405231         202012   1              0           0       \n",
       "4893002 141405231         202101   1              0           0       \n",
       "4893003 141405231         202102   1              0           0       \n",
       "4893004 141405231         202103   1              0           0       \n",
       "4893005 141405231         202104   1              0           0       \n",
       "4893006 141405231         202105   1              0           0       \n",
       "4893007 141405231         202106   1              0           0       \n",
       "4893008 141405231         202107   1              0           0       \n",
       "4893009 141405231         202108   1              0           0       \n",
       "4893010 141405231         202109   1              0           0       \n",
       "4893011 141457392         201901   1              0           1       \n",
       "4893012 141457392         201902   1              0           1       \n",
       "4893013 141457392         201903   1              0           1       \n",
       "4893014 141457392         201904   1              0           1       \n",
       "4893015 141457392         201905   1              0           1       \n",
       "4893016 141457392         201906   1              0           1       \n",
       "4893017 141457392         201907   1              0           1       \n",
       "4893018 141457392         201908   1              0           1       \n",
       "4893019 141457392         201909   1              0           1       \n",
       "4893020 141457392         201910   1              0           1       \n",
       "4893021 141457392         201911   1              0           1       \n",
       "4893022 141457392         201912   1              0           1       \n",
       "4893023 141457392         202001   1              0           1       \n",
       "4893024 141457392         202002   1              0           1       \n",
       "4893025 141523225         201910   1              0           1       \n",
       "4893026 141523225         201911   1              0           1       \n",
       "4893027 141523225         201912   1              0           1       \n",
       "4893028 141523225         202001   1              0           1       \n",
       "        cliente_edad cliente_antiguedad mrentabilidad mrentabilidad_annual\n",
       "1       61           280                 497.55       10740.15            \n",
       "2       61           281                1148.00       11473.76            \n",
       "3       61           282                1716.07       12906.70            \n",
       "4       61           283                   0.00           0.00            \n",
       "5       61           284                1843.89       13487.06            \n",
       "6       62           285                1479.17       13404.26            \n",
       "7       62           286                2121.81       14320.19            \n",
       "8       62           287                4303.36       17865.74            \n",
       "9       62           288                3702.42       21318.99            \n",
       "10      62           289                4394.43       25032.74            \n",
       "11      62           290                4519.04       28757.53            \n",
       "12      62           291                1515.44       28934.66            \n",
       "13      59           174                1794.53        7842.29            \n",
       "14      59           175                 765.73        8205.41            \n",
       "15      59           176                 927.83        8670.28            \n",
       "16      59           177                2951.32       11260.80            \n",
       "17      59           178                   0.00           0.00            \n",
       "18      60           179                1239.32       13242.19            \n",
       "19      60           180                 641.43       13460.36            \n",
       "20      60           181                 336.69       13896.07            \n",
       "21      60           182                 398.97       13973.28            \n",
       "22      60           183                   0.00           0.00            \n",
       "23      60           184                1804.94       14722.53            \n",
       "24      60           185                2993.06       16134.60            \n",
       "25      60           186                1902.43       16242.49            \n",
       "26      60           187                2182.74       17659.50            \n",
       "27      60           188                1810.86       18542.53            \n",
       "28      60           189                1552.37       17143.58            \n",
       "29      60           190                1849.97       17322.94            \n",
       "30      60           191                   0.00           0.00            \n",
       "⋮       ⋮            ⋮                  ⋮             ⋮                   \n",
       "4892999 25           50                  740.66       11520.93            \n",
       "4893000 25           51                 1325.57       11930.60            \n",
       "4893001 25           52                 2002.89       12971.81            \n",
       "4893002 25           53                 1971.61       14487.85            \n",
       "4893003 25           54                 2001.47       16252.38            \n",
       "4893004 25           55                 -288.17       15031.81            \n",
       "4893005 26           56                  875.16       14590.23            \n",
       "4893006 26           57                 2135.38       14961.69            \n",
       "4893007 26           58                 -954.82       12338.14            \n",
       "4893008 26           59                 -809.87       10681.31            \n",
       "4893009 26           60                 2172.81       11958.47            \n",
       "4893010 26           61                  943.22       12115.95            \n",
       "4893011 23           29                  729.69        7245.19            \n",
       "4893012 23           30                  991.44        7881.87            \n",
       "4893013 23           31                  960.05        8674.00            \n",
       "4893014 23           32                 1268.88        9457.20            \n",
       "4893015 23           33                    0.00           0.00            \n",
       "4893016 23           34                 2075.13       12656.71            \n",
       "4893017 23           35                 2447.24       14809.06            \n",
       "4893018 24           36                 2530.20       17082.96            \n",
       "4893019 24           37                 2535.08       18999.16            \n",
       "4893020 24           38                    0.00           0.00            \n",
       "4893021 24           39                 2649.77       23222.76            \n",
       "4893022 24           40                 2419.20       23285.77            \n",
       "4893023 24           41                 2614.01       25170.09            \n",
       "4893024 24           42                 1818.39       25997.04            \n",
       "4893025 34           38                    0.00           0.00            \n",
       "4893026 34           39                  223.93       10185.90            \n",
       "4893027 34           40                  -21.75        9239.60            \n",
       "4893028 34           41                   46.29        8808.30            \n",
       "        mcomisiones ⋯ lag_6_Visa_mconsumototal lag_1_Visa_cconsumos\n",
       "1          9.85     ⋯       NA                 NA                  \n",
       "2          9.85     ⋯       NA                 NA                  \n",
       "3         17.09     ⋯       NA                 NA                  \n",
       "4          0.00     ⋯       NA                 NA                  \n",
       "5         13.98     ⋯       NA                 NA                  \n",
       "6         13.85     ⋯       NA                 NA                  \n",
       "7         17.29     ⋯       NA                 NA                  \n",
       "8       2367.26     ⋯       NA                 NA                  \n",
       "9       2367.27     ⋯       NA                 NA                  \n",
       "10      2382.39     ⋯       NA                 NA                  \n",
       "11      2372.25     ⋯       NA                 NA                  \n",
       "12        22.09     ⋯       NA                 NA                  \n",
       "13       295.73     ⋯       NA                 NA                  \n",
       "14       204.86     ⋯       NA                  1                  \n",
       "15       177.54     ⋯       NA                  4                  \n",
       "16      1337.02     ⋯       NA                  3                  \n",
       "17         0.00     ⋯       NA                  5                  \n",
       "18      1085.64     ⋯       NA                  4                  \n",
       "19      1763.40     ⋯   809.37                  6                  \n",
       "20      1395.47     ⋯  2772.97                 15                  \n",
       "21      1706.33     ⋯  2046.88                  4                  \n",
       "22         0.00     ⋯  6668.90                  3                  \n",
       "23      1442.44     ⋯  4532.47                  3                  \n",
       "24      1321.80     ⋯  2421.36                  3                  \n",
       "25       390.40     ⋯ 22144.77                  3                  \n",
       "26       873.31     ⋯  2967.51                  3                  \n",
       "27      1627.78     ⋯  2604.06                  5                  \n",
       "28      1449.13     ⋯  2604.06                  4                  \n",
       "29      1449.32     ⋯  2709.63                  3                  \n",
       "30         0.00     ⋯  2709.63                  3                  \n",
       "⋮       ⋮           ⋱ ⋮                        ⋮                   \n",
       "4892999  308.00     ⋯  7226.12                  6                  \n",
       "4893000  443.46     ⋯ 13824.80                 10                  \n",
       "4893001  380.15     ⋯ 33331.48                  9                  \n",
       "4893002  180.52     ⋯ 14782.72                  9                  \n",
       "4893003 2012.35     ⋯  5537.36                  7                  \n",
       "4893004  492.15     ⋯ 10096.67                  9                  \n",
       "4893005  485.02     ⋯ 20109.13                 12                  \n",
       "4893006  488.85     ⋯ 12826.76                  9                  \n",
       "4893007  304.40     ⋯ 20146.25                 11                  \n",
       "4893008  476.43     ⋯ 12794.20                  8                  \n",
       "4893009  456.54     ⋯ 36043.15                 11                  \n",
       "4893010  324.92     ⋯ 30825.51                  9                  \n",
       "4893011  475.27     ⋯       NA                 NA                  \n",
       "4893012  479.54     ⋯       NA                  2                  \n",
       "4893013  439.18     ⋯       NA                  1                  \n",
       "4893014  425.23     ⋯       NA                  0                  \n",
       "4893015    0.00     ⋯       NA                  0                  \n",
       "4893016  458.47     ⋯       NA                  0                  \n",
       "4893017  497.31     ⋯  3988.20                  1                  \n",
       "4893018  556.45     ⋯   492.66                  3                  \n",
       "4893019 1062.58     ⋯     0.00                  3                  \n",
       "4893020    0.00     ⋯     0.00                  0                  \n",
       "4893021 1053.79     ⋯     0.00                  0                  \n",
       "4893022 1021.64     ⋯    50.08                  0                  \n",
       "4893023 1376.69     ⋯  2656.35                  0                  \n",
       "4893024 1346.34     ⋯  9723.30                 NA                  \n",
       "4893025    0.00     ⋯       NA                 NA                  \n",
       "4893026  484.08     ⋯       NA                  6                  \n",
       "4893027  213.47     ⋯       NA                  5                  \n",
       "4893028 2869.85     ⋯       NA                  5                  \n",
       "        lag_3_Visa_cconsumos lag_6_Visa_cconsumos lag_1_Visa_cadelantosefectivo\n",
       "1       NA                   NA                   NA                           \n",
       "2       NA                   NA                   NA                           \n",
       "3       NA                   NA                   NA                           \n",
       "4       NA                   NA                   NA                           \n",
       "5       NA                   NA                   NA                           \n",
       "6       NA                   NA                   NA                           \n",
       "7       NA                   NA                   NA                           \n",
       "8       NA                   NA                   NA                           \n",
       "9       NA                   NA                   NA                           \n",
       "10      NA                   NA                   NA                           \n",
       "11      NA                   NA                   NA                           \n",
       "12      NA                   NA                   NA                           \n",
       "13      NA                   NA                   NA                           \n",
       "14      NA                   NA                    0                           \n",
       "15      NA                   NA                    0                           \n",
       "16       1                   NA                    0                           \n",
       "17       4                   NA                    0                           \n",
       "18       3                   NA                    0                           \n",
       "19       5                    1                    0                           \n",
       "20       4                    4                    0                           \n",
       "21       6                    3                    0                           \n",
       "22      15                    5                    0                           \n",
       "23       4                    4                    0                           \n",
       "24       3                    6                    0                           \n",
       "25       3                   15                    0                           \n",
       "26       3                    4                    0                           \n",
       "27       3                    3                    0                           \n",
       "28       3                    3                    0                           \n",
       "29       5                    3                    0                           \n",
       "30       4                    3                    0                           \n",
       "⋮       ⋮                    ⋮                    ⋮                            \n",
       "4892999  8                    5                    0                           \n",
       "4893000  4                    6                    0                           \n",
       "4893001  6                   10                    0                           \n",
       "4893002 10                    8                    0                           \n",
       "4893003  9                    4                    0                           \n",
       "4893004  9                    6                    0                           \n",
       "4893005  7                   10                    0                           \n",
       "4893006  9                    9                    0                           \n",
       "4893007 12                    9                    0                           \n",
       "4893008  9                    7                    0                           \n",
       "4893009 11                    9                    0                           \n",
       "4893010  8                   12                    0                           \n",
       "4893011 NA                   NA                   NA                           \n",
       "4893012 NA                   NA                    0                           \n",
       "4893013 NA                   NA                    0                           \n",
       "4893014  2                   NA                    0                           \n",
       "4893015  1                   NA                    0                           \n",
       "4893016  0                   NA                    0                           \n",
       "4893017  0                    2                    0                           \n",
       "4893018  0                    1                    0                           \n",
       "4893019  1                    0                    0                           \n",
       "4893020  3                    0                    0                           \n",
       "4893021  3                    0                    0                           \n",
       "4893022  0                    1                    0                           \n",
       "4893023  0                    3                    0                           \n",
       "4893024  0                    3                   NA                           \n",
       "4893025 NA                   NA                   NA                           \n",
       "4893026 NA                   NA                    0                           \n",
       "4893027 NA                   NA                    0                           \n",
       "4893028  6                   NA                    0                           \n",
       "        lag_3_Visa_cadelantosefectivo lag_6_Visa_cadelantosefectivo\n",
       "1       NA                            NA                           \n",
       "2       NA                            NA                           \n",
       "3       NA                            NA                           \n",
       "4       NA                            NA                           \n",
       "5       NA                            NA                           \n",
       "6       NA                            NA                           \n",
       "7       NA                            NA                           \n",
       "8       NA                            NA                           \n",
       "9       NA                            NA                           \n",
       "10      NA                            NA                           \n",
       "11      NA                            NA                           \n",
       "12      NA                            NA                           \n",
       "13      NA                            NA                           \n",
       "14      NA                            NA                           \n",
       "15      NA                            NA                           \n",
       "16       0                            NA                           \n",
       "17       0                            NA                           \n",
       "18       0                            NA                           \n",
       "19       0                             0                           \n",
       "20       0                             0                           \n",
       "21       0                             0                           \n",
       "22       0                             0                           \n",
       "23       0                             0                           \n",
       "24       0                             0                           \n",
       "25       0                             0                           \n",
       "26       0                             0                           \n",
       "27       0                             0                           \n",
       "28       0                             0                           \n",
       "29       0                             0                           \n",
       "30       0                             0                           \n",
       "⋮       ⋮                             ⋮                            \n",
       "4892999  0                             0                           \n",
       "4893000  0                             0                           \n",
       "4893001  0                             0                           \n",
       "4893002  0                             0                           \n",
       "4893003  0                             0                           \n",
       "4893004  0                             0                           \n",
       "4893005  0                             0                           \n",
       "4893006  0                             0                           \n",
       "4893007  0                             0                           \n",
       "4893008  0                             0                           \n",
       "4893009  0                             0                           \n",
       "4893010  0                             0                           \n",
       "4893011 NA                            NA                           \n",
       "4893012 NA                            NA                           \n",
       "4893013 NA                            NA                           \n",
       "4893014  0                            NA                           \n",
       "4893015  0                            NA                           \n",
       "4893016  0                            NA                           \n",
       "4893017  0                             0                           \n",
       "4893018  0                             0                           \n",
       "4893019  0                             0                           \n",
       "4893020  0                             0                           \n",
       "4893021  0                             0                           \n",
       "4893022  0                             0                           \n",
       "4893023  0                             0                           \n",
       "4893024  0                             0                           \n",
       "4893025 NA                            NA                           \n",
       "4893026 NA                            NA                           \n",
       "4893027 NA                            NA                           \n",
       "4893028  0                            NA                           \n",
       "        lag_1_Visa_mpagominimo lag_3_Visa_mpagominimo lag_6_Visa_mpagominimo\n",
       "1            NA                     NA                     NA               \n",
       "2          0.00                     NA                     NA               \n",
       "3          0.00                     NA                     NA               \n",
       "4          0.00                   0.00                     NA               \n",
       "5          0.00                   0.00                     NA               \n",
       "6          0.00                   0.00                     NA               \n",
       "7          0.00                   0.00                   0.00               \n",
       "8          0.00                   0.00                   0.00               \n",
       "9          0.00                   0.00                   0.00               \n",
       "10         0.00                   0.00                   0.00               \n",
       "11         0.00                   0.00                   0.00               \n",
       "12         0.00                   0.00                   0.00               \n",
       "13           NA                     NA                     NA               \n",
       "14       692.07                     NA                     NA               \n",
       "15       797.64                     NA                     NA               \n",
       "16       527.85                 692.07                     NA               \n",
       "17      1055.70                 797.64                     NA               \n",
       "18       914.94                 527.85                     NA               \n",
       "19       434.01                1055.70                 692.07               \n",
       "20      2568.87                 914.94                 797.64               \n",
       "21      2029.29                 434.01                 527.85               \n",
       "22      1888.53                2568.87                1055.70               \n",
       "23      1571.82                2029.29                 914.94               \n",
       "24      1724.31                1888.53                 434.01               \n",
       "25      1513.17                1571.82                2568.87               \n",
       "26      1513.17                1724.31                2029.29               \n",
       "27      2475.03                1513.17                1888.53               \n",
       "28      2451.57                1513.17                1571.82               \n",
       "29      2263.89                2475.03                1724.31               \n",
       "30      2076.21                2451.57                1513.17               \n",
       "⋮       ⋮                      ⋮                      ⋮                     \n",
       "4892999 2815.20                2615.79                 445.74               \n",
       "4893000 3354.78                2205.24                2275.62               \n",
       "4893001 3214.02                2815.20                3483.81               \n",
       "4893002 3659.76                3354.78                2615.79               \n",
       "4893003 3237.48                3214.02                2205.24               \n",
       "4893004 3730.14                3659.76                2815.20               \n",
       "4893005 3319.59                3237.48                3354.78               \n",
       "4893006 3155.37                3730.14                3214.02               \n",
       "4893007 3847.44                3319.59                3659.76               \n",
       "4893008 3507.27                3155.37                3237.48               \n",
       "4893009 4105.50                3847.44                3730.14               \n",
       "4893010 3800.52                3507.27                3319.59               \n",
       "4893011      NA                     NA                     NA               \n",
       "4893012  175.95                     NA                     NA               \n",
       "4893013   11.73                     NA                     NA               \n",
       "4893014    0.00                 175.95                     NA               \n",
       "4893015   58.65                  11.73                     NA               \n",
       "4893016   58.65                   0.00                     NA               \n",
       "4893017   58.65                  58.65                 175.95               \n",
       "4893018  164.22                  58.65                  11.73               \n",
       "4893019    0.00                  58.65                   0.00               \n",
       "4893020   46.92                 164.22                  58.65               \n",
       "4893021  129.03                   0.00                  58.65               \n",
       "4893022    0.00                  46.92                  58.65               \n",
       "4893023    0.00                 129.03                 164.22               \n",
       "4893024    0.00                   0.00                   0.00               \n",
       "4893025      NA                     NA                     NA               \n",
       "4893026  609.96                     NA                     NA               \n",
       "4893027 1137.81                     NA                     NA               \n",
       "4893028 1548.36                 609.96                     NA               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(jsub, SDenv, parent.frame()): object 'clase_ternaria' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(jsub, SDenv, parent.frame()): object 'clase_ternaria' not found\nTraceback:\n",
      "1. dataset[, `:=`(clase01, ifelse(clase_ternaria == \"CONTINUA\", \n .     0L, 1L))]",
      "2. `[.data.table`(dataset, , `:=`(clase01, ifelse(clase_ternaria == \n .     \"CONTINUA\", 0L, 1L)))",
      "3. eval(jsub, SDenv, parent.frame())",
      "4. eval(jsub, SDenv, parent.frame())",
      "5. ifelse(clase_ternaria == \"CONTINUA\", 0L, 1L)"
     ]
    }
   ],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "dataset[, clase01 := ifelse(clase_ternaria == \"CONTINUA\", 0L, 1L)]\n",
    "\n",
    "\n",
    "# los campos que se van a utilizar\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "set.seed(PARAM$trainingstrategy$semilla_azar)\n",
    "dataset[, azar := runif(nrow(dataset))]\n",
    "dataset[, training := 0L]\n",
    "dataset[\n",
    "  foto_mes %in% PARAM$input$training &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "dtrain <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[training == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[training == 1L, clase01],\n",
    "  weight = dataset[training == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forman parte de validation\n",
    "#  no hay undersampling\n",
    "dataset[, validation := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$validation,  validation := 1L]\n",
    "\n",
    "dvalidate <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[validation == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[validation == 1L, clase01],\n",
    "  weight = dataset[validation == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos de testing\n",
    "dataset[, testing := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$testing,  testing := 1L]\n",
    "\n",
    "\n",
    "dataset_test <- dataset[testing == 1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# libero espacio\n",
    "rm(dataset)\n",
    "gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "funcion_optimizar <- EstimarGanancia_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output = FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn = funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize = FALSE, # estoy Maximizando la ganancia\n",
    "  noisy = TRUE,\n",
    "  par.set = PARAM$bo_lgb, # definido al comienzo del programa\n",
    "  has.simple.signature = FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time = 600, # se graba cada 600 segundos\n",
    "  save.file.path = kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters = PARAM$bo_iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())\n",
    "\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type = \"se\",\n",
    "  covtype = \"matern3_2\",\n",
    "  control = list(trace = TRUE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# inicio la optimizacion bayesiana\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  run <- mbo(obj.fun, learner = surr.km, control = ctrl)\n",
    "} else {\n",
    "  run <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}\n",
    "\n",
    "\n",
    "cat(\"\\n\\nLa optimizacion Bayesiana ha terminado\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semilla 2, base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# limpio la memoria\n",
    "rm(list = ls()) # remove all objects\n",
    "gc() # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "require(\"data.table\")\n",
    "require(\"rlist\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paquetes necesarios para la Bayesian Optimization\n",
    "require(\"DiceKriging\")\n",
    "require(\"mlrMBO\")\n",
    "\n",
    "# para que se detenga ante el primer error\n",
    "# y muestre el stack de funciones invocadas\n",
    "options(error = function() {\n",
    "  traceback(20)\n",
    "  options(error = NULL)\n",
    "  stop(\"exiting after script error\")\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los parametros de la corrida, en una lista, la variable global  PARAM\n",
    "#  muy pronto esto se leera desde un archivo formato .yaml\n",
    "PARAM <- list()\n",
    "\n",
    "PARAM$experimento <- \"HT8230 (Clase 12, Base Sem2)\"\n",
    "\n",
    "PARAM$input$dataset <- \"datasets/competencia_03_base_lags.csv.gz\"\n",
    "\n",
    "# los meses en los que vamos a entrenar\n",
    "#  mucha magia emerger de esta eleccion\n",
    "PARAM$input$testing <- c(202107) # Último mes, lo más cercano al 202109 de kaggle\n",
    "PARAM$input$validation <- c(202106)\n",
    "PARAM$input$training <- c(202105, 202104, 202103, 202102, 202101,202012) # 6 meses de entrenamiento\t\n",
    "\n",
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "PARAM$trainingstrategy$undersampling <- 1.0\n",
    "PARAM$trainingstrategy$semilla_azar <- c(279511, 279523, 279541, 279551, 279571)  # Aqui poner su  primer  semilla/ pongo todas mis semillas\n",
    "\n",
    "PARAM$hyperparametertuning$POS_ganancia <- 273000\n",
    "PARAM$hyperparametertuning$NEG_ganancia <- -7000\n",
    "\n",
    "# Aqui va semilla\n",
    "PARAM$lgb_semilla <- 279523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Hiperparametros FIJOS de  lightgbm\n",
    "PARAM$lgb_basicos <- list(\n",
    "  boosting = \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
    "  objective = \"binary\",\n",
    "  metric = \"custom\",\n",
    "  first_metric_only = TRUE,\n",
    "  boost_from_average = TRUE,\n",
    "  feature_pre_filter = FALSE,\n",
    "  force_row_wise = TRUE, # para reducir warnings\n",
    "  verbosity = -100,\n",
    "  max_depth = -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split = 0.0, # min_gain_to_split >= 0.0\n",
    "  min_sum_hessian_in_leaf = 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1 = 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2 = 0.0, # lambda_l2 >= 0.0\n",
    "  max_bin = 31L, # lo debo dejar fijo, no participa de la BO\n",
    "  num_iterations = 9999, # un numero muy grande, lo limita early_stopping_rounds\n",
    "\n",
    "  bagging_fraction = 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction = 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction = 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance = FALSE, #\n",
    "  scale_pos_weight = 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate = 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop = 50, # <=0 means no limit\n",
    "  skip_drop = 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  extra_trees = TRUE, # Magic Sauce\n",
    "\n",
    "  seed = PARAM$lgb_semilla\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui se cargan los hiperparametros que se optimizan\n",
    "#  en la Bayesian Optimization\n",
    "PARAM$bo_lgb <- makeParamSet(\n",
    "  makeNumericParam(\"learning_rate\", lower = 0.02, upper = 0.3),\n",
    "  makeNumericParam(\"feature_fraction\", lower = 0.01, upper = 1.0),\n",
    "  makeIntegerParam(\"num_leaves\", lower = 8L, upper = 1024L),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower = 100L, upper = 50000L)\n",
    ")\n",
    "\n",
    "# si usted es ambicioso, y tiene paciencia, podria subir este valor a 100\n",
    "PARAM$bo_iteraciones <- 50 # iteraciones de la Optimizacion Bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# graba a un archivo los componentes de lista\n",
    "# para el primer registro, escribe antes los titulos\n",
    "\n",
    "loguear <- function(\n",
    "    reg, arch = NA, folder = \"./exp/\",\n",
    "    ext = \".txt\", verbose = TRUE) {\n",
    "  archivo <- arch\n",
    "  if (is.na(arch)) archivo <- paste0(folder, substitute(reg), ext)\n",
    "\n",
    "  if (!file.exists(archivo)) # Escribo los titulos\n",
    "    {\n",
    "      linea <- paste0(\n",
    "        \"fecha\\t\",\n",
    "        paste(list.names(reg), collapse = \"\\t\"), \"\\n\"\n",
    "      )\n",
    "\n",
    "      cat(linea, file = archivo)\n",
    "    }\n",
    "\n",
    "  linea <- paste0(\n",
    "    format(Sys.time(), \"%Y%m%d %H%M%S\"), \"\\t\", # la fecha y hora\n",
    "    gsub(\", \", \"\\t\", toString(reg)), \"\\n\"\n",
    "  )\n",
    "\n",
    "  cat(linea, file = archivo, append = TRUE) # grabo al archivo\n",
    "\n",
    "  if (verbose) cat(linea) # imprimo por pantalla\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "GLOBAL_arbol <- 0L\n",
    "GLOBAL_gan_max <- -Inf\n",
    "vcant_optima <- c()\n",
    "\n",
    "fganancia_lgbm_meseta <- function(probs, datos) {\n",
    "  vlabels <- get_field(datos, \"label\")\n",
    "  vpesos <- get_field(datos, \"weight\")\n",
    "\n",
    "\n",
    "  GLOBAL_arbol <<- GLOBAL_arbol + 1\n",
    "  tbl <- as.data.table(list(\n",
    "    \"prob\" = probs,\n",
    "    \"gan\" = ifelse(vlabels == 1 & vpesos > 1,\n",
    "      PARAM$hyperparametertuning$POS_ganancia,\n",
    "      PARAM$hyperparametertuning$NEG_ganancia  )\n",
    "  ))\n",
    "\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, posicion := .I]\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "\n",
    "  tbl[, gan_suavizada :=\n",
    "    frollmean(\n",
    "      x = gan_acum, n = 2001, align = \"center\",\n",
    "      na.rm = TRUE, hasNA = TRUE\n",
    "    )]\n",
    "\n",
    "  gan <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "\n",
    "  pos <- which.max(tbl[, gan_suavizada])\n",
    "  vcant_optima <<- c(vcant_optima, pos)\n",
    "\n",
    "  if (GLOBAL_arbol %% 10 == 0) {\n",
    "    if (gan > GLOBAL_gan_max) GLOBAL_gan_max <<- gan\n",
    "\n",
    "    cat(\"\\r\")\n",
    "    cat(\n",
    "      \"Validate \", GLOBAL_iteracion, \" \", \" \",\n",
    "      GLOBAL_arbol, \"  \", gan, \"   \", GLOBAL_gan_max, \"   \"\n",
    "    )\n",
    "  }\n",
    "\n",
    "\n",
    "  return(list(\n",
    "    \"name\" = \"ganancia\",\n",
    "    \"value\" = gan,\n",
    "    \"higher_better\" = TRUE\n",
    "  ))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "\n",
    "EstimarGanancia_lightgbm <- function(x) {\n",
    "  gc()\n",
    "  GLOBAL_iteracion <<- GLOBAL_iteracion + 1L\n",
    "\n",
    "  # hago la union de los parametros basicos y los moviles que vienen en x\n",
    "  param_completo <- c(PARAM$lgb_basicos, x)\n",
    "\n",
    "  param_completo$early_stopping_rounds <-\n",
    "    as.integer(400 + 4 / param_completo$learning_rate)\n",
    "\n",
    "  GLOBAL_arbol <<- 0L\n",
    "  GLOBAL_gan_max <<- -Inf\n",
    "  vcant_optima <<- c()\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  modelo_train <- lgb.train(\n",
    "    data = dtrain,\n",
    "    valids = list(valid = dvalidate),\n",
    "    eval = fganancia_lgbm_meseta,\n",
    "    param = param_completo,\n",
    "    verbose = -100\n",
    "  )\n",
    "\n",
    "  cat(\"\\n\")\n",
    "\n",
    "  cant_corte <- vcant_optima[modelo_train$best_iter]\n",
    "\n",
    "  # aplico el modelo a testing y calculo la ganancia\n",
    "  prediccion <- predict(\n",
    "    modelo_train,\n",
    "    data.matrix(dataset_test[, campos_buenos, with = FALSE])\n",
    "  )\n",
    "\n",
    "  tbl <- copy(dataset_test[, list(\"gan\" = ifelse(clase_ternaria == \"BAJA+2\",\n",
    "    PARAM$hyperparametertuning$POS_ganancia, \n",
    "    PARAM$hyperparametertuning$NEG_ganancia))])\n",
    "\n",
    "  tbl[, prob := prediccion]\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "  tbl[, gan_suavizada := frollmean(\n",
    "    x = gan_acum, n = 2001,\n",
    "    align = \"center\", na.rm = TRUE, hasNA = TRUE\n",
    "  )]\n",
    "\n",
    "\n",
    "  ganancia_test <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "  cantidad_test_normalizada <- which.max(tbl[, gan_suavizada])\n",
    "\n",
    "  rm(tbl)\n",
    "  gc()\n",
    "\n",
    "  ganancia_test_normalizada <- ganancia_test\n",
    "\n",
    "\n",
    "  # voy grabando las mejores column importance\n",
    "  if (ganancia_test_normalizada > GLOBAL_gananciamax) {\n",
    "    GLOBAL_gananciamax <<- ganancia_test_normalizada\n",
    "    tb_importancia <- as.data.table(lgb.importance(modelo_train))\n",
    "\n",
    "    fwrite(tb_importancia,\n",
    "      file = paste0(\"impo_\", sprintf(\"%03d\", GLOBAL_iteracion), \".txt\"),\n",
    "      sep = \"\\t\"\n",
    "    )\n",
    "\n",
    "    rm(tb_importancia)\n",
    "  }\n",
    "\n",
    "\n",
    "  # logueo final\n",
    "  ds <- list(\"cols\" = ncol(dtrain), \"rows\" = nrow(dtrain))\n",
    "  xx <- c(ds, copy(param_completo))\n",
    "\n",
    "  xx$early_stopping_rounds <- NULL\n",
    "  xx$num_iterations <- modelo_train$best_iter\n",
    "  xx$estimulos <- cantidad_test_normalizada\n",
    "  xx$ganancia <- ganancia_test_normalizada\n",
    "  xx$iteracion_bayesiana <- GLOBAL_iteracion\n",
    "\n",
    "  loguear(xx, arch = \"BO_log.txt\")\n",
    "\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  return(ganancia_test_normalizada)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aquí empieza el programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui empieza el programa\n",
    "\n",
    "# Aqui se debe poner la carpeta de la computadora local\n",
    "setwd(\"~/buckets/b1/\") # Establezco el Working Directory\n",
    "\n",
    "# cargo el dataset donde voy a entrenar el modelo\n",
    "dataset <- fread(PARAM$input$dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# creo la carpeta donde va el experimento\n",
    "dir.create(\"./exp/\", showWarnings = FALSE)\n",
    "dir.create(paste0(\"./exp/\", PARAM$experimento, \"/\"), showWarnings = FALSE)\n",
    "\n",
    "# Establezco el Working Directory DEL EXPERIMENTO\n",
    "setwd(paste0(\"./exp/\", PARAM$experimento, \"/\"))\n",
    "\n",
    "# en estos archivos quedan los resultados\n",
    "kbayesiana <- paste0(PARAM$experimento, \".RDATA\")\n",
    "klog <- paste0(PARAM$experimento, \".txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Catastrophe Analysis  -------------------------------------------------------\n",
    "# deben ir cosas de este estilo\n",
    "#   dataset[foto_mes == 202006, active_quarter := NA]\n",
    "\n",
    "# Data Drifting\n",
    "# por ahora, no hago nada\n",
    "\n",
    "\n",
    "# Feature Engineering Historico  ----------------------------------------------\n",
    "#   aqui deben calcularse los  lags y  lag_delta\n",
    "#   Sin lags no hay paraiso !  corta la bocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ahora SI comienza la optimizacion Bayesiana\n",
    "\n",
    "GLOBAL_iteracion <- 0 # inicializo la variable global\n",
    "GLOBAL_gananciamax <- -1 # inicializo la variable global\n",
    "\n",
    "# si ya existe el archivo log, traigo hasta donde llegue\n",
    "if (file.exists(klog)) {\n",
    "  tabla_log <- fread(klog)\n",
    "  GLOBAL_iteracion <- nrow(tabla_log)\n",
    "  GLOBAL_gananciamax <- tabla_log[, max(ganancia)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "dataset[, clase01 := ifelse(clase_ternaria == \"CONTINUA\", 0L, 1L)]\n",
    "\n",
    "\n",
    "# los campos que se van a utilizar\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "set.seed(PARAM$trainingstrategy$semilla_azar)\n",
    "dataset[, azar := runif(nrow(dataset))]\n",
    "dataset[, training := 0L]\n",
    "dataset[\n",
    "  foto_mes %in% PARAM$input$training &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "dtrain <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[training == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[training == 1L, clase01],\n",
    "  weight = dataset[training == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forman parte de validation\n",
    "#  no hay undersampling\n",
    "dataset[, validation := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$validation,  validation := 1L]\n",
    "\n",
    "dvalidate <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[validation == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[validation == 1L, clase01],\n",
    "  weight = dataset[validation == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos de testing\n",
    "dataset[, testing := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$testing,  testing := 1L]\n",
    "\n",
    "\n",
    "dataset_test <- dataset[testing == 1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# libero espacio\n",
    "rm(dataset)\n",
    "gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "funcion_optimizar <- EstimarGanancia_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output = FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn = funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize = FALSE, # estoy Maximizando la ganancia\n",
    "  noisy = TRUE,\n",
    "  par.set = PARAM$bo_lgb, # definido al comienzo del programa\n",
    "  has.simple.signature = FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time = 600, # se graba cada 600 segundos\n",
    "  save.file.path = kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters = PARAM$bo_iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())\n",
    "\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type = \"se\",\n",
    "  covtype = \"matern3_2\",\n",
    "  control = list(trace = TRUE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# inicio la optimizacion bayesiana\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  run <- mbo(obj.fun, learner = surr.km, control = ctrl)\n",
    "} else {\n",
    "  run <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}\n",
    "\n",
    "\n",
    "cat(\"\\n\\nLa optimizacion Bayesiana ha terminado\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semilla 3, base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# limpio la memoria\n",
    "rm(list = ls()) # remove all objects\n",
    "gc() # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "require(\"data.table\")\n",
    "require(\"rlist\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paquetes necesarios para la Bayesian Optimization\n",
    "require(\"DiceKriging\")\n",
    "require(\"mlrMBO\")\n",
    "\n",
    "# para que se detenga ante el primer error\n",
    "# y muestre el stack de funciones invocadas\n",
    "options(error = function() {\n",
    "  traceback(20)\n",
    "  options(error = NULL)\n",
    "  stop(\"exiting after script error\")\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los parametros de la corrida, en una lista, la variable global  PARAM\n",
    "#  muy pronto esto se leera desde un archivo formato .yaml\n",
    "PARAM <- list()\n",
    "\n",
    "PARAM$experimento <- \"HT8230 (Clase 12, Base Sem3)\"\n",
    "\n",
    "PARAM$input$dataset <- \"datasets/competencia_03_base_lags.csv.gz\"\n",
    "\n",
    "# los meses en los que vamos a entrenar\n",
    "#  mucha magia emerger de esta eleccion\n",
    "PARAM$input$testing <- c(202107) # Último mes, lo más cercano al 202109 de kaggle\n",
    "PARAM$input$validation <- c(202106)\n",
    "PARAM$input$training <- c(202105, 202104, 202103, 202102, 202101,202012) # 6 meses de entrenamiento\t\n",
    "\n",
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "PARAM$trainingstrategy$undersampling <- 1.0\n",
    "PARAM$trainingstrategy$semilla_azar <- c(279511, 279523, 279541, 279551, 279571)  # Aqui poner su  primer  semilla/ pongo todas mis semillas\n",
    "\n",
    "PARAM$hyperparametertuning$POS_ganancia <- 273000\n",
    "PARAM$hyperparametertuning$NEG_ganancia <- -7000\n",
    "\n",
    "# Aqui va semilla\n",
    "PARAM$lgb_semilla <- 279541"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Hiperparametros FIJOS de  lightgbm\n",
    "PARAM$lgb_basicos <- list(\n",
    "  boosting = \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
    "  objective = \"binary\",\n",
    "  metric = \"custom\",\n",
    "  first_metric_only = TRUE,\n",
    "  boost_from_average = TRUE,\n",
    "  feature_pre_filter = FALSE,\n",
    "  force_row_wise = TRUE, # para reducir warnings\n",
    "  verbosity = -100,\n",
    "  max_depth = -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split = 0.0, # min_gain_to_split >= 0.0\n",
    "  min_sum_hessian_in_leaf = 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1 = 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2 = 0.0, # lambda_l2 >= 0.0\n",
    "  max_bin = 31L, # lo debo dejar fijo, no participa de la BO\n",
    "  num_iterations = 9999, # un numero muy grande, lo limita early_stopping_rounds\n",
    "\n",
    "  bagging_fraction = 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction = 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction = 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance = FALSE, #\n",
    "  scale_pos_weight = 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate = 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop = 50, # <=0 means no limit\n",
    "  skip_drop = 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  extra_trees = TRUE, # Magic Sauce\n",
    "\n",
    "  seed = PARAM$lgb_semilla\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui se cargan los hiperparametros que se optimizan\n",
    "#  en la Bayesian Optimization\n",
    "PARAM$bo_lgb <- makeParamSet(\n",
    "  makeNumericParam(\"learning_rate\", lower = 0.02, upper = 0.3),\n",
    "  makeNumericParam(\"feature_fraction\", lower = 0.01, upper = 1.0),\n",
    "  makeIntegerParam(\"num_leaves\", lower = 8L, upper = 1024L),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower = 100L, upper = 50000L)\n",
    ")\n",
    "\n",
    "# si usted es ambicioso, y tiene paciencia, podria subir este valor a 100\n",
    "PARAM$bo_iteraciones <- 50 # iteraciones de la Optimizacion Bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# graba a un archivo los componentes de lista\n",
    "# para el primer registro, escribe antes los titulos\n",
    "\n",
    "loguear <- function(\n",
    "    reg, arch = NA, folder = \"./exp/\",\n",
    "    ext = \".txt\", verbose = TRUE) {\n",
    "  archivo <- arch\n",
    "  if (is.na(arch)) archivo <- paste0(folder, substitute(reg), ext)\n",
    "\n",
    "  if (!file.exists(archivo)) # Escribo los titulos\n",
    "    {\n",
    "      linea <- paste0(\n",
    "        \"fecha\\t\",\n",
    "        paste(list.names(reg), collapse = \"\\t\"), \"\\n\"\n",
    "      )\n",
    "\n",
    "      cat(linea, file = archivo)\n",
    "    }\n",
    "\n",
    "  linea <- paste0(\n",
    "    format(Sys.time(), \"%Y%m%d %H%M%S\"), \"\\t\", # la fecha y hora\n",
    "    gsub(\", \", \"\\t\", toString(reg)), \"\\n\"\n",
    "  )\n",
    "\n",
    "  cat(linea, file = archivo, append = TRUE) # grabo al archivo\n",
    "\n",
    "  if (verbose) cat(linea) # imprimo por pantalla\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "GLOBAL_arbol <- 0L\n",
    "GLOBAL_gan_max <- -Inf\n",
    "vcant_optima <- c()\n",
    "\n",
    "fganancia_lgbm_meseta <- function(probs, datos) {\n",
    "  vlabels <- get_field(datos, \"label\")\n",
    "  vpesos <- get_field(datos, \"weight\")\n",
    "\n",
    "\n",
    "  GLOBAL_arbol <<- GLOBAL_arbol + 1\n",
    "  tbl <- as.data.table(list(\n",
    "    \"prob\" = probs,\n",
    "    \"gan\" = ifelse(vlabels == 1 & vpesos > 1,\n",
    "      PARAM$hyperparametertuning$POS_ganancia,\n",
    "      PARAM$hyperparametertuning$NEG_ganancia  )\n",
    "  ))\n",
    "\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, posicion := .I]\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "\n",
    "  tbl[, gan_suavizada :=\n",
    "    frollmean(\n",
    "      x = gan_acum, n = 2001, align = \"center\",\n",
    "      na.rm = TRUE, hasNA = TRUE\n",
    "    )]\n",
    "\n",
    "  gan <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "\n",
    "  pos <- which.max(tbl[, gan_suavizada])\n",
    "  vcant_optima <<- c(vcant_optima, pos)\n",
    "\n",
    "  if (GLOBAL_arbol %% 10 == 0) {\n",
    "    if (gan > GLOBAL_gan_max) GLOBAL_gan_max <<- gan\n",
    "\n",
    "    cat(\"\\r\")\n",
    "    cat(\n",
    "      \"Validate \", GLOBAL_iteracion, \" \", \" \",\n",
    "      GLOBAL_arbol, \"  \", gan, \"   \", GLOBAL_gan_max, \"   \"\n",
    "    )\n",
    "  }\n",
    "\n",
    "\n",
    "  return(list(\n",
    "    \"name\" = \"ganancia\",\n",
    "    \"value\" = gan,\n",
    "    \"higher_better\" = TRUE\n",
    "  ))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "\n",
    "EstimarGanancia_lightgbm <- function(x) {\n",
    "  gc()\n",
    "  GLOBAL_iteracion <<- GLOBAL_iteracion + 1L\n",
    "\n",
    "  # hago la union de los parametros basicos y los moviles que vienen en x\n",
    "  param_completo <- c(PARAM$lgb_basicos, x)\n",
    "\n",
    "  param_completo$early_stopping_rounds <-\n",
    "    as.integer(400 + 4 / param_completo$learning_rate)\n",
    "\n",
    "  GLOBAL_arbol <<- 0L\n",
    "  GLOBAL_gan_max <<- -Inf\n",
    "  vcant_optima <<- c()\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  modelo_train <- lgb.train(\n",
    "    data = dtrain,\n",
    "    valids = list(valid = dvalidate),\n",
    "    eval = fganancia_lgbm_meseta,\n",
    "    param = param_completo,\n",
    "    verbose = -100\n",
    "  )\n",
    "\n",
    "  cat(\"\\n\")\n",
    "\n",
    "  cant_corte <- vcant_optima[modelo_train$best_iter]\n",
    "\n",
    "  # aplico el modelo a testing y calculo la ganancia\n",
    "  prediccion <- predict(\n",
    "    modelo_train,\n",
    "    data.matrix(dataset_test[, campos_buenos, with = FALSE])\n",
    "  )\n",
    "\n",
    "  tbl <- copy(dataset_test[, list(\"gan\" = ifelse(clase_ternaria == \"BAJA+2\",\n",
    "    PARAM$hyperparametertuning$POS_ganancia, \n",
    "    PARAM$hyperparametertuning$NEG_ganancia))])\n",
    "\n",
    "  tbl[, prob := prediccion]\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "  tbl[, gan_suavizada := frollmean(\n",
    "    x = gan_acum, n = 2001,\n",
    "    align = \"center\", na.rm = TRUE, hasNA = TRUE\n",
    "  )]\n",
    "\n",
    "\n",
    "  ganancia_test <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "  cantidad_test_normalizada <- which.max(tbl[, gan_suavizada])\n",
    "\n",
    "  rm(tbl)\n",
    "  gc()\n",
    "\n",
    "  ganancia_test_normalizada <- ganancia_test\n",
    "\n",
    "\n",
    "  # voy grabando las mejores column importance\n",
    "  if (ganancia_test_normalizada > GLOBAL_gananciamax) {\n",
    "    GLOBAL_gananciamax <<- ganancia_test_normalizada\n",
    "    tb_importancia <- as.data.table(lgb.importance(modelo_train))\n",
    "\n",
    "    fwrite(tb_importancia,\n",
    "      file = paste0(\"impo_\", sprintf(\"%03d\", GLOBAL_iteracion), \".txt\"),\n",
    "      sep = \"\\t\"\n",
    "    )\n",
    "\n",
    "    rm(tb_importancia)\n",
    "  }\n",
    "\n",
    "\n",
    "  # logueo final\n",
    "  ds <- list(\"cols\" = ncol(dtrain), \"rows\" = nrow(dtrain))\n",
    "  xx <- c(ds, copy(param_completo))\n",
    "\n",
    "  xx$early_stopping_rounds <- NULL\n",
    "  xx$num_iterations <- modelo_train$best_iter\n",
    "  xx$estimulos <- cantidad_test_normalizada\n",
    "  xx$ganancia <- ganancia_test_normalizada\n",
    "  xx$iteracion_bayesiana <- GLOBAL_iteracion\n",
    "\n",
    "  loguear(xx, arch = \"BO_log.txt\")\n",
    "\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  return(ganancia_test_normalizada)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aquí empieza el programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui empieza el programa\n",
    "\n",
    "# Aqui se debe poner la carpeta de la computadora local\n",
    "setwd(\"~/buckets/b1/\") # Establezco el Working Directory\n",
    "\n",
    "# cargo el dataset donde voy a entrenar el modelo\n",
    "dataset <- fread(PARAM$input$dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# creo la carpeta donde va el experimento\n",
    "dir.create(\"./exp/\", showWarnings = FALSE)\n",
    "dir.create(paste0(\"./exp/\", PARAM$experimento, \"/\"), showWarnings = FALSE)\n",
    "\n",
    "# Establezco el Working Directory DEL EXPERIMENTO\n",
    "setwd(paste0(\"./exp/\", PARAM$experimento, \"/\"))\n",
    "\n",
    "# en estos archivos quedan los resultados\n",
    "kbayesiana <- paste0(PARAM$experimento, \".RDATA\")\n",
    "klog <- paste0(PARAM$experimento, \".txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Catastrophe Analysis  -------------------------------------------------------\n",
    "# deben ir cosas de este estilo\n",
    "#   dataset[foto_mes == 202006, active_quarter := NA]\n",
    "\n",
    "# Data Drifting\n",
    "# por ahora, no hago nada\n",
    "\n",
    "\n",
    "# Feature Engineering Historico  ----------------------------------------------\n",
    "#   aqui deben calcularse los  lags y  lag_delta\n",
    "#   Sin lags no hay paraiso !  corta la bocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ahora SI comienza la optimizacion Bayesiana\n",
    "\n",
    "GLOBAL_iteracion <- 0 # inicializo la variable global\n",
    "GLOBAL_gananciamax <- -1 # inicializo la variable global\n",
    "\n",
    "# si ya existe el archivo log, traigo hasta donde llegue\n",
    "if (file.exists(klog)) {\n",
    "  tabla_log <- fread(klog)\n",
    "  GLOBAL_iteracion <- nrow(tabla_log)\n",
    "  GLOBAL_gananciamax <- tabla_log[, max(ganancia)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "dataset[, clase01 := ifelse(clase_ternaria == \"CONTINUA\", 0L, 1L)]\n",
    "\n",
    "\n",
    "# los campos que se van a utilizar\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "set.seed(PARAM$trainingstrategy$semilla_azar)\n",
    "dataset[, azar := runif(nrow(dataset))]\n",
    "dataset[, training := 0L]\n",
    "dataset[\n",
    "  foto_mes %in% PARAM$input$training &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "dtrain <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[training == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[training == 1L, clase01],\n",
    "  weight = dataset[training == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forman parte de validation\n",
    "#  no hay undersampling\n",
    "dataset[, validation := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$validation,  validation := 1L]\n",
    "\n",
    "dvalidate <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[validation == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[validation == 1L, clase01],\n",
    "  weight = dataset[validation == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos de testing\n",
    "dataset[, testing := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$testing,  testing := 1L]\n",
    "\n",
    "\n",
    "dataset_test <- dataset[testing == 1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# libero espacio\n",
    "rm(dataset)\n",
    "gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "funcion_optimizar <- EstimarGanancia_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output = FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn = funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize = FALSE, # estoy Maximizando la ganancia\n",
    "  noisy = TRUE,\n",
    "  par.set = PARAM$bo_lgb, # definido al comienzo del programa\n",
    "  has.simple.signature = FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time = 600, # se graba cada 600 segundos\n",
    "  save.file.path = kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters = PARAM$bo_iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())\n",
    "\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type = \"se\",\n",
    "  covtype = \"matern3_2\",\n",
    "  control = list(trace = TRUE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# inicio la optimizacion bayesiana\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  run <- mbo(obj.fun, learner = surr.km, control = ctrl)\n",
    "} else {\n",
    "  run <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}\n",
    "\n",
    "\n",
    "cat(\"\\n\\nLa optimizacion Bayesiana ha terminado\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semilla 4, base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# limpio la memoria\n",
    "rm(list = ls()) # remove all objects\n",
    "gc() # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "require(\"data.table\")\n",
    "require(\"rlist\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paquetes necesarios para la Bayesian Optimization\n",
    "require(\"DiceKriging\")\n",
    "require(\"mlrMBO\")\n",
    "\n",
    "# para que se detenga ante el primer error\n",
    "# y muestre el stack de funciones invocadas\n",
    "options(error = function() {\n",
    "  traceback(20)\n",
    "  options(error = NULL)\n",
    "  stop(\"exiting after script error\")\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los parametros de la corrida, en una lista, la variable global  PARAM\n",
    "#  muy pronto esto se leera desde un archivo formato .yaml\n",
    "PARAM <- list()\n",
    "\n",
    "PARAM$experimento <- \"HT8230 (Clase 12, Base Sem4)\"\n",
    "\n",
    "PARAM$input$dataset <- \"datasets/competencia_03_base_lags.csv.gz\"\n",
    "\n",
    "# los meses en los que vamos a entrenar\n",
    "#  mucha magia emerger de esta eleccion\n",
    "PARAM$input$testing <- c(202107) # Último mes, lo más cercano al 202109 de kaggle\n",
    "PARAM$input$validation <- c(202106)\n",
    "PARAM$input$training <- c(202105, 202104, 202103, 202102, 202101,202012) # 6 meses de entrenamiento\t\n",
    "\n",
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "PARAM$trainingstrategy$undersampling <- 1.0\n",
    "PARAM$trainingstrategy$semilla_azar <- c(279511, 279523, 279541, 279551, 279571)  # Aqui poner su  primer  semilla/ pongo todas mis semillas\n",
    "\n",
    "PARAM$hyperparametertuning$POS_ganancia <- 273000\n",
    "PARAM$hyperparametertuning$NEG_ganancia <- -7000\n",
    "\n",
    "# Aqui va semilla\n",
    "PARAM$lgb_semilla <- 279551"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Hiperparametros FIJOS de  lightgbm\n",
    "PARAM$lgb_basicos <- list(\n",
    "  boosting = \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
    "  objective = \"binary\",\n",
    "  metric = \"custom\",\n",
    "  first_metric_only = TRUE,\n",
    "  boost_from_average = TRUE,\n",
    "  feature_pre_filter = FALSE,\n",
    "  force_row_wise = TRUE, # para reducir warnings\n",
    "  verbosity = -100,\n",
    "  max_depth = -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split = 0.0, # min_gain_to_split >= 0.0\n",
    "  min_sum_hessian_in_leaf = 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1 = 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2 = 0.0, # lambda_l2 >= 0.0\n",
    "  max_bin = 31L, # lo debo dejar fijo, no participa de la BO\n",
    "  num_iterations = 9999, # un numero muy grande, lo limita early_stopping_rounds\n",
    "\n",
    "  bagging_fraction = 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction = 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction = 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance = FALSE, #\n",
    "  scale_pos_weight = 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate = 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop = 50, # <=0 means no limit\n",
    "  skip_drop = 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  extra_trees = TRUE, # Magic Sauce\n",
    "\n",
    "  seed = PARAM$lgb_semilla\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui se cargan los hiperparametros que se optimizan\n",
    "#  en la Bayesian Optimization\n",
    "PARAM$bo_lgb <- makeParamSet(\n",
    "  makeNumericParam(\"learning_rate\", lower = 0.02, upper = 0.3),\n",
    "  makeNumericParam(\"feature_fraction\", lower = 0.01, upper = 1.0),\n",
    "  makeIntegerParam(\"num_leaves\", lower = 8L, upper = 1024L),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower = 100L, upper = 50000L)\n",
    ")\n",
    "\n",
    "# si usted es ambicioso, y tiene paciencia, podria subir este valor a 100\n",
    "PARAM$bo_iteraciones <- 50 # iteraciones de la Optimizacion Bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# graba a un archivo los componentes de lista\n",
    "# para el primer registro, escribe antes los titulos\n",
    "\n",
    "loguear <- function(\n",
    "    reg, arch = NA, folder = \"./exp/\",\n",
    "    ext = \".txt\", verbose = TRUE) {\n",
    "  archivo <- arch\n",
    "  if (is.na(arch)) archivo <- paste0(folder, substitute(reg), ext)\n",
    "\n",
    "  if (!file.exists(archivo)) # Escribo los titulos\n",
    "    {\n",
    "      linea <- paste0(\n",
    "        \"fecha\\t\",\n",
    "        paste(list.names(reg), collapse = \"\\t\"), \"\\n\"\n",
    "      )\n",
    "\n",
    "      cat(linea, file = archivo)\n",
    "    }\n",
    "\n",
    "  linea <- paste0(\n",
    "    format(Sys.time(), \"%Y%m%d %H%M%S\"), \"\\t\", # la fecha y hora\n",
    "    gsub(\", \", \"\\t\", toString(reg)), \"\\n\"\n",
    "  )\n",
    "\n",
    "  cat(linea, file = archivo, append = TRUE) # grabo al archivo\n",
    "\n",
    "  if (verbose) cat(linea) # imprimo por pantalla\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "GLOBAL_arbol <- 0L\n",
    "GLOBAL_gan_max <- -Inf\n",
    "vcant_optima <- c()\n",
    "\n",
    "fganancia_lgbm_meseta <- function(probs, datos) {\n",
    "  vlabels <- get_field(datos, \"label\")\n",
    "  vpesos <- get_field(datos, \"weight\")\n",
    "\n",
    "\n",
    "  GLOBAL_arbol <<- GLOBAL_arbol + 1\n",
    "  tbl <- as.data.table(list(\n",
    "    \"prob\" = probs,\n",
    "    \"gan\" = ifelse(vlabels == 1 & vpesos > 1,\n",
    "      PARAM$hyperparametertuning$POS_ganancia,\n",
    "      PARAM$hyperparametertuning$NEG_ganancia  )\n",
    "  ))\n",
    "\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, posicion := .I]\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "\n",
    "  tbl[, gan_suavizada :=\n",
    "    frollmean(\n",
    "      x = gan_acum, n = 2001, align = \"center\",\n",
    "      na.rm = TRUE, hasNA = TRUE\n",
    "    )]\n",
    "\n",
    "  gan <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "\n",
    "  pos <- which.max(tbl[, gan_suavizada])\n",
    "  vcant_optima <<- c(vcant_optima, pos)\n",
    "\n",
    "  if (GLOBAL_arbol %% 10 == 0) {\n",
    "    if (gan > GLOBAL_gan_max) GLOBAL_gan_max <<- gan\n",
    "\n",
    "    cat(\"\\r\")\n",
    "    cat(\n",
    "      \"Validate \", GLOBAL_iteracion, \" \", \" \",\n",
    "      GLOBAL_arbol, \"  \", gan, \"   \", GLOBAL_gan_max, \"   \"\n",
    "    )\n",
    "  }\n",
    "\n",
    "\n",
    "  return(list(\n",
    "    \"name\" = \"ganancia\",\n",
    "    \"value\" = gan,\n",
    "    \"higher_better\" = TRUE\n",
    "  ))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "\n",
    "EstimarGanancia_lightgbm <- function(x) {\n",
    "  gc()\n",
    "  GLOBAL_iteracion <<- GLOBAL_iteracion + 1L\n",
    "\n",
    "  # hago la union de los parametros basicos y los moviles que vienen en x\n",
    "  param_completo <- c(PARAM$lgb_basicos, x)\n",
    "\n",
    "  param_completo$early_stopping_rounds <-\n",
    "    as.integer(400 + 4 / param_completo$learning_rate)\n",
    "\n",
    "  GLOBAL_arbol <<- 0L\n",
    "  GLOBAL_gan_max <<- -Inf\n",
    "  vcant_optima <<- c()\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  modelo_train <- lgb.train(\n",
    "    data = dtrain,\n",
    "    valids = list(valid = dvalidate),\n",
    "    eval = fganancia_lgbm_meseta,\n",
    "    param = param_completo,\n",
    "    verbose = -100\n",
    "  )\n",
    "\n",
    "  cat(\"\\n\")\n",
    "\n",
    "  cant_corte <- vcant_optima[modelo_train$best_iter]\n",
    "\n",
    "  # aplico el modelo a testing y calculo la ganancia\n",
    "  prediccion <- predict(\n",
    "    modelo_train,\n",
    "    data.matrix(dataset_test[, campos_buenos, with = FALSE])\n",
    "  )\n",
    "\n",
    "  tbl <- copy(dataset_test[, list(\"gan\" = ifelse(clase_ternaria == \"BAJA+2\",\n",
    "    PARAM$hyperparametertuning$POS_ganancia, \n",
    "    PARAM$hyperparametertuning$NEG_ganancia))])\n",
    "\n",
    "  tbl[, prob := prediccion]\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "  tbl[, gan_suavizada := frollmean(\n",
    "    x = gan_acum, n = 2001,\n",
    "    align = \"center\", na.rm = TRUE, hasNA = TRUE\n",
    "  )]\n",
    "\n",
    "\n",
    "  ganancia_test <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "  cantidad_test_normalizada <- which.max(tbl[, gan_suavizada])\n",
    "\n",
    "  rm(tbl)\n",
    "  gc()\n",
    "\n",
    "  ganancia_test_normalizada <- ganancia_test\n",
    "\n",
    "\n",
    "  # voy grabando las mejores column importance\n",
    "  if (ganancia_test_normalizada > GLOBAL_gananciamax) {\n",
    "    GLOBAL_gananciamax <<- ganancia_test_normalizada\n",
    "    tb_importancia <- as.data.table(lgb.importance(modelo_train))\n",
    "\n",
    "    fwrite(tb_importancia,\n",
    "      file = paste0(\"impo_\", sprintf(\"%03d\", GLOBAL_iteracion), \".txt\"),\n",
    "      sep = \"\\t\"\n",
    "    )\n",
    "\n",
    "    rm(tb_importancia)\n",
    "  }\n",
    "\n",
    "\n",
    "  # logueo final\n",
    "  ds <- list(\"cols\" = ncol(dtrain), \"rows\" = nrow(dtrain))\n",
    "  xx <- c(ds, copy(param_completo))\n",
    "\n",
    "  xx$early_stopping_rounds <- NULL\n",
    "  xx$num_iterations <- modelo_train$best_iter\n",
    "  xx$estimulos <- cantidad_test_normalizada\n",
    "  xx$ganancia <- ganancia_test_normalizada\n",
    "  xx$iteracion_bayesiana <- GLOBAL_iteracion\n",
    "\n",
    "  loguear(xx, arch = \"BO_log.txt\")\n",
    "\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  return(ganancia_test_normalizada)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aquí empieza el programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui empieza el programa\n",
    "\n",
    "# Aqui se debe poner la carpeta de la computadora local\n",
    "setwd(\"~/buckets/b1/\") # Establezco el Working Directory\n",
    "\n",
    "# cargo el dataset donde voy a entrenar el modelo\n",
    "dataset <- fread(PARAM$input$dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# creo la carpeta donde va el experimento\n",
    "dir.create(\"./exp/\", showWarnings = FALSE)\n",
    "dir.create(paste0(\"./exp/\", PARAM$experimento, \"/\"), showWarnings = FALSE)\n",
    "\n",
    "# Establezco el Working Directory DEL EXPERIMENTO\n",
    "setwd(paste0(\"./exp/\", PARAM$experimento, \"/\"))\n",
    "\n",
    "# en estos archivos quedan los resultados\n",
    "kbayesiana <- paste0(PARAM$experimento, \".RDATA\")\n",
    "klog <- paste0(PARAM$experimento, \".txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Catastrophe Analysis  -------------------------------------------------------\n",
    "# deben ir cosas de este estilo\n",
    "#   dataset[foto_mes == 202006, active_quarter := NA]\n",
    "\n",
    "# Data Drifting\n",
    "# por ahora, no hago nada\n",
    "\n",
    "\n",
    "# Feature Engineering Historico  ----------------------------------------------\n",
    "#   aqui deben calcularse los  lags y  lag_delta\n",
    "#   Sin lags no hay paraiso !  corta la bocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ahora SI comienza la optimizacion Bayesiana\n",
    "\n",
    "GLOBAL_iteracion <- 0 # inicializo la variable global\n",
    "GLOBAL_gananciamax <- -1 # inicializo la variable global\n",
    "\n",
    "# si ya existe el archivo log, traigo hasta donde llegue\n",
    "if (file.exists(klog)) {\n",
    "  tabla_log <- fread(klog)\n",
    "  GLOBAL_iteracion <- nrow(tabla_log)\n",
    "  GLOBAL_gananciamax <- tabla_log[, max(ganancia)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "dataset[, clase01 := ifelse(clase_ternaria == \"CONTINUA\", 0L, 1L)]\n",
    "\n",
    "\n",
    "# los campos que se van a utilizar\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "set.seed(PARAM$trainingstrategy$semilla_azar)\n",
    "dataset[, azar := runif(nrow(dataset))]\n",
    "dataset[, training := 0L]\n",
    "dataset[\n",
    "  foto_mes %in% PARAM$input$training &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "dtrain <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[training == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[training == 1L, clase01],\n",
    "  weight = dataset[training == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forman parte de validation\n",
    "#  no hay undersampling\n",
    "dataset[, validation := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$validation,  validation := 1L]\n",
    "\n",
    "dvalidate <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[validation == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[validation == 1L, clase01],\n",
    "  weight = dataset[validation == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos de testing\n",
    "dataset[, testing := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$testing,  testing := 1L]\n",
    "\n",
    "\n",
    "dataset_test <- dataset[testing == 1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# libero espacio\n",
    "rm(dataset)\n",
    "gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "funcion_optimizar <- EstimarGanancia_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output = FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn = funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize = FALSE, # estoy Maximizando la ganancia\n",
    "  noisy = TRUE,\n",
    "  par.set = PARAM$bo_lgb, # definido al comienzo del programa\n",
    "  has.simple.signature = FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time = 600, # se graba cada 600 segundos\n",
    "  save.file.path = kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters = PARAM$bo_iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())\n",
    "\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type = \"se\",\n",
    "  covtype = \"matern3_2\",\n",
    "  control = list(trace = TRUE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# inicio la optimizacion bayesiana\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  run <- mbo(obj.fun, learner = surr.km, control = ctrl)\n",
    "} else {\n",
    "  run <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}\n",
    "\n",
    "\n",
    "cat(\"\\n\\nLa optimizacion Bayesiana ha terminado\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semilla 5, base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# limpio la memoria\n",
    "rm(list = ls()) # remove all objects\n",
    "gc() # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "require(\"data.table\")\n",
    "require(\"rlist\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paquetes necesarios para la Bayesian Optimization\n",
    "require(\"DiceKriging\")\n",
    "require(\"mlrMBO\")\n",
    "\n",
    "# para que se detenga ante el primer error\n",
    "# y muestre el stack de funciones invocadas\n",
    "options(error = function() {\n",
    "  traceback(20)\n",
    "  options(error = NULL)\n",
    "  stop(\"exiting after script error\")\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los parametros de la corrida, en una lista, la variable global  PARAM\n",
    "#  muy pronto esto se leera desde un archivo formato .yaml\n",
    "PARAM <- list()\n",
    "\n",
    "PARAM$experimento <- \"HT8230 (Clase 12, Base Sem5)\"\n",
    "\n",
    "PARAM$input$dataset <- \"datasets/competencia_03_base_lags.csv.gz\"\n",
    "\n",
    "# los meses en los que vamos a entrenar\n",
    "#  mucha magia emerger de esta eleccion\n",
    "PARAM$input$testing <- c(202107) # Último mes, lo más cercano al 202109 de kaggle\n",
    "PARAM$input$validation <- c(202106)\n",
    "PARAM$input$training <- c(202105, 202104, 202103, 202102, 202101,202012) # 6 meses de entrenamiento\t\n",
    "\n",
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "PARAM$trainingstrategy$undersampling <- 1.0\n",
    "PARAM$trainingstrategy$semilla_azar <- c(279511, 279523, 279541, 279551, 279571)  # Aqui poner su  primer  semilla/ pongo todas mis semillas\n",
    "\n",
    "PARAM$hyperparametertuning$POS_ganancia <- 273000\n",
    "PARAM$hyperparametertuning$NEG_ganancia <- -7000\n",
    "\n",
    "# Aqui va semilla\n",
    "PARAM$lgb_semilla <- 279571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Hiperparametros FIJOS de  lightgbm\n",
    "PARAM$lgb_basicos <- list(\n",
    "  boosting = \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
    "  objective = \"binary\",\n",
    "  metric = \"custom\",\n",
    "  first_metric_only = TRUE,\n",
    "  boost_from_average = TRUE,\n",
    "  feature_pre_filter = FALSE,\n",
    "  force_row_wise = TRUE, # para reducir warnings\n",
    "  verbosity = -100,\n",
    "  max_depth = -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split = 0.0, # min_gain_to_split >= 0.0\n",
    "  min_sum_hessian_in_leaf = 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1 = 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2 = 0.0, # lambda_l2 >= 0.0\n",
    "  max_bin = 31L, # lo debo dejar fijo, no participa de la BO\n",
    "  num_iterations = 9999, # un numero muy grande, lo limita early_stopping_rounds\n",
    "\n",
    "  bagging_fraction = 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction = 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction = 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance = FALSE, #\n",
    "  scale_pos_weight = 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate = 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop = 50, # <=0 means no limit\n",
    "  skip_drop = 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  extra_trees = TRUE, # Magic Sauce\n",
    "\n",
    "  seed = PARAM$lgb_semilla\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui se cargan los hiperparametros que se optimizan\n",
    "#  en la Bayesian Optimization\n",
    "PARAM$bo_lgb <- makeParamSet(\n",
    "  makeNumericParam(\"learning_rate\", lower = 0.02, upper = 0.3),\n",
    "  makeNumericParam(\"feature_fraction\", lower = 0.01, upper = 1.0),\n",
    "  makeIntegerParam(\"num_leaves\", lower = 8L, upper = 1024L),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower = 100L, upper = 50000L)\n",
    ")\n",
    "\n",
    "# si usted es ambicioso, y tiene paciencia, podria subir este valor a 100\n",
    "PARAM$bo_iteraciones <- 50 # iteraciones de la Optimizacion Bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# graba a un archivo los componentes de lista\n",
    "# para el primer registro, escribe antes los titulos\n",
    "\n",
    "loguear <- function(\n",
    "    reg, arch = NA, folder = \"./exp/\",\n",
    "    ext = \".txt\", verbose = TRUE) {\n",
    "  archivo <- arch\n",
    "  if (is.na(arch)) archivo <- paste0(folder, substitute(reg), ext)\n",
    "\n",
    "  if (!file.exists(archivo)) # Escribo los titulos\n",
    "    {\n",
    "      linea <- paste0(\n",
    "        \"fecha\\t\",\n",
    "        paste(list.names(reg), collapse = \"\\t\"), \"\\n\"\n",
    "      )\n",
    "\n",
    "      cat(linea, file = archivo)\n",
    "    }\n",
    "\n",
    "  linea <- paste0(\n",
    "    format(Sys.time(), \"%Y%m%d %H%M%S\"), \"\\t\", # la fecha y hora\n",
    "    gsub(\", \", \"\\t\", toString(reg)), \"\\n\"\n",
    "  )\n",
    "\n",
    "  cat(linea, file = archivo, append = TRUE) # grabo al archivo\n",
    "\n",
    "  if (verbose) cat(linea) # imprimo por pantalla\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "GLOBAL_arbol <- 0L\n",
    "GLOBAL_gan_max <- -Inf\n",
    "vcant_optima <- c()\n",
    "\n",
    "fganancia_lgbm_meseta <- function(probs, datos) {\n",
    "  vlabels <- get_field(datos, \"label\")\n",
    "  vpesos <- get_field(datos, \"weight\")\n",
    "\n",
    "\n",
    "  GLOBAL_arbol <<- GLOBAL_arbol + 1\n",
    "  tbl <- as.data.table(list(\n",
    "    \"prob\" = probs,\n",
    "    \"gan\" = ifelse(vlabels == 1 & vpesos > 1,\n",
    "      PARAM$hyperparametertuning$POS_ganancia,\n",
    "      PARAM$hyperparametertuning$NEG_ganancia  )\n",
    "  ))\n",
    "\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, posicion := .I]\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "\n",
    "  tbl[, gan_suavizada :=\n",
    "    frollmean(\n",
    "      x = gan_acum, n = 2001, align = \"center\",\n",
    "      na.rm = TRUE, hasNA = TRUE\n",
    "    )]\n",
    "\n",
    "  gan <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "\n",
    "  pos <- which.max(tbl[, gan_suavizada])\n",
    "  vcant_optima <<- c(vcant_optima, pos)\n",
    "\n",
    "  if (GLOBAL_arbol %% 10 == 0) {\n",
    "    if (gan > GLOBAL_gan_max) GLOBAL_gan_max <<- gan\n",
    "\n",
    "    cat(\"\\r\")\n",
    "    cat(\n",
    "      \"Validate \", GLOBAL_iteracion, \" \", \" \",\n",
    "      GLOBAL_arbol, \"  \", gan, \"   \", GLOBAL_gan_max, \"   \"\n",
    "    )\n",
    "  }\n",
    "\n",
    "\n",
    "  return(list(\n",
    "    \"name\" = \"ganancia\",\n",
    "    \"value\" = gan,\n",
    "    \"higher_better\" = TRUE\n",
    "  ))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "\n",
    "EstimarGanancia_lightgbm <- function(x) {\n",
    "  gc()\n",
    "  GLOBAL_iteracion <<- GLOBAL_iteracion + 1L\n",
    "\n",
    "  # hago la union de los parametros basicos y los moviles que vienen en x\n",
    "  param_completo <- c(PARAM$lgb_basicos, x)\n",
    "\n",
    "  param_completo$early_stopping_rounds <-\n",
    "    as.integer(400 + 4 / param_completo$learning_rate)\n",
    "\n",
    "  GLOBAL_arbol <<- 0L\n",
    "  GLOBAL_gan_max <<- -Inf\n",
    "  vcant_optima <<- c()\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  modelo_train <- lgb.train(\n",
    "    data = dtrain,\n",
    "    valids = list(valid = dvalidate),\n",
    "    eval = fganancia_lgbm_meseta,\n",
    "    param = param_completo,\n",
    "    verbose = -100\n",
    "  )\n",
    "\n",
    "  cat(\"\\n\")\n",
    "\n",
    "  cant_corte <- vcant_optima[modelo_train$best_iter]\n",
    "\n",
    "  # aplico el modelo a testing y calculo la ganancia\n",
    "  prediccion <- predict(\n",
    "    modelo_train,\n",
    "    data.matrix(dataset_test[, campos_buenos, with = FALSE])\n",
    "  )\n",
    "\n",
    "  tbl <- copy(dataset_test[, list(\"gan\" = ifelse(clase_ternaria == \"BAJA+2\",\n",
    "    PARAM$hyperparametertuning$POS_ganancia, \n",
    "    PARAM$hyperparametertuning$NEG_ganancia))])\n",
    "\n",
    "  tbl[, prob := prediccion]\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "  tbl[, gan_suavizada := frollmean(\n",
    "    x = gan_acum, n = 2001,\n",
    "    align = \"center\", na.rm = TRUE, hasNA = TRUE\n",
    "  )]\n",
    "\n",
    "\n",
    "  ganancia_test <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "  cantidad_test_normalizada <- which.max(tbl[, gan_suavizada])\n",
    "\n",
    "  rm(tbl)\n",
    "  gc()\n",
    "\n",
    "  ganancia_test_normalizada <- ganancia_test\n",
    "\n",
    "\n",
    "  # voy grabando las mejores column importance\n",
    "  if (ganancia_test_normalizada > GLOBAL_gananciamax) {\n",
    "    GLOBAL_gananciamax <<- ganancia_test_normalizada\n",
    "    tb_importancia <- as.data.table(lgb.importance(modelo_train))\n",
    "\n",
    "    fwrite(tb_importancia,\n",
    "      file = paste0(\"impo_\", sprintf(\"%03d\", GLOBAL_iteracion), \".txt\"),\n",
    "      sep = \"\\t\"\n",
    "    )\n",
    "\n",
    "    rm(tb_importancia)\n",
    "  }\n",
    "\n",
    "\n",
    "  # logueo final\n",
    "  ds <- list(\"cols\" = ncol(dtrain), \"rows\" = nrow(dtrain))\n",
    "  xx <- c(ds, copy(param_completo))\n",
    "\n",
    "  xx$early_stopping_rounds <- NULL\n",
    "  xx$num_iterations <- modelo_train$best_iter\n",
    "  xx$estimulos <- cantidad_test_normalizada\n",
    "  xx$ganancia <- ganancia_test_normalizada\n",
    "  xx$iteracion_bayesiana <- GLOBAL_iteracion\n",
    "\n",
    "  loguear(xx, arch = \"BO_log.txt\")\n",
    "\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  return(ganancia_test_normalizada)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aquí empieza el programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui empieza el programa\n",
    "\n",
    "# Aqui se debe poner la carpeta de la computadora local\n",
    "setwd(\"~/buckets/b1/\") # Establezco el Working Directory\n",
    "\n",
    "# cargo el dataset donde voy a entrenar el modelo\n",
    "dataset <- fread(PARAM$input$dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# creo la carpeta donde va el experimento\n",
    "dir.create(\"./exp/\", showWarnings = FALSE)\n",
    "dir.create(paste0(\"./exp/\", PARAM$experimento, \"/\"), showWarnings = FALSE)\n",
    "\n",
    "# Establezco el Working Directory DEL EXPERIMENTO\n",
    "setwd(paste0(\"./exp/\", PARAM$experimento, \"/\"))\n",
    "\n",
    "# en estos archivos quedan los resultados\n",
    "kbayesiana <- paste0(PARAM$experimento, \".RDATA\")\n",
    "klog <- paste0(PARAM$experimento, \".txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Catastrophe Analysis  -------------------------------------------------------\n",
    "# deben ir cosas de este estilo\n",
    "#   dataset[foto_mes == 202006, active_quarter := NA]\n",
    "\n",
    "# Data Drifting\n",
    "# por ahora, no hago nada\n",
    "\n",
    "\n",
    "# Feature Engineering Historico  ----------------------------------------------\n",
    "#   aqui deben calcularse los  lags y  lag_delta\n",
    "#   Sin lags no hay paraiso !  corta la bocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ahora SI comienza la optimizacion Bayesiana\n",
    "\n",
    "GLOBAL_iteracion <- 0 # inicializo la variable global\n",
    "GLOBAL_gananciamax <- -1 # inicializo la variable global\n",
    "\n",
    "# si ya existe el archivo log, traigo hasta donde llegue\n",
    "if (file.exists(klog)) {\n",
    "  tabla_log <- fread(klog)\n",
    "  GLOBAL_iteracion <- nrow(tabla_log)\n",
    "  GLOBAL_gananciamax <- tabla_log[, max(ganancia)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "dataset[, clase01 := ifelse(clase_ternaria == \"CONTINUA\", 0L, 1L)]\n",
    "\n",
    "\n",
    "# los campos que se van a utilizar\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "set.seed(PARAM$trainingstrategy$semilla_azar)\n",
    "dataset[, azar := runif(nrow(dataset))]\n",
    "dataset[, training := 0L]\n",
    "dataset[\n",
    "  foto_mes %in% PARAM$input$training &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "dtrain <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[training == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[training == 1L, clase01],\n",
    "  weight = dataset[training == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forman parte de validation\n",
    "#  no hay undersampling\n",
    "dataset[, validation := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$validation,  validation := 1L]\n",
    "\n",
    "dvalidate <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[validation == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[validation == 1L, clase01],\n",
    "  weight = dataset[validation == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos de testing\n",
    "dataset[, testing := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$testing,  testing := 1L]\n",
    "\n",
    "\n",
    "dataset_test <- dataset[testing == 1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# libero espacio\n",
    "rm(dataset)\n",
    "gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "funcion_optimizar <- EstimarGanancia_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output = FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn = funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize = FALSE, # estoy Maximizando la ganancia\n",
    "  noisy = TRUE,\n",
    "  par.set = PARAM$bo_lgb, # definido al comienzo del programa\n",
    "  has.simple.signature = FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time = 600, # se graba cada 600 segundos\n",
    "  save.file.path = kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters = PARAM$bo_iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())\n",
    "\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type = \"se\",\n",
    "  covtype = \"matern3_2\",\n",
    "  control = list(trace = TRUE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# inicio la optimizacion bayesiana\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  run <- mbo(obj.fun, learner = surr.km, control = ctrl)\n",
    "} else {\n",
    "  run <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}\n",
    "\n",
    "\n",
    "cat(\"\\n\\nLa optimizacion Bayesiana ha terminado\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semilla 1, ajustado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# limpio la memoria\n",
    "rm(list = ls()) # remove all objects\n",
    "gc() # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "require(\"data.table\")\n",
    "require(\"rlist\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paquetes necesarios para la Bayesian Optimization\n",
    "require(\"DiceKriging\")\n",
    "require(\"mlrMBO\")\n",
    "\n",
    "# para que se detenga ante el primer error\n",
    "# y muestre el stack de funciones invocadas\n",
    "options(error = function() {\n",
    "  traceback(20)\n",
    "  options(error = NULL)\n",
    "  stop(\"exiting after script error\")\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los parametros de la corrida, en una lista, la variable global  PARAM\n",
    "#  muy pronto esto se leera desde un archivo formato .yaml\n",
    "PARAM <- list()\n",
    "\n",
    "PARAM$experimento <- \"HT8230 (Clase 12, Ajustado Sem1)\"\n",
    "\n",
    "PARAM$input$dataset <- \"datasets/competencia_03_infla_ajustado_lags.csv.gz\"\n",
    "\n",
    "# los meses en los que vamos a entrenar\n",
    "#  mucha magia emerger de esta eleccion\n",
    "PARAM$input$testing <- c(202107) # Último mes, lo más cercano al 202109 de kaggle\n",
    "PARAM$input$validation <- c(202106)\n",
    "PARAM$input$training <- c(202105, 202104, 202103, 202102, 202101,202012) # 6 meses de entrenamiento\t\n",
    "\n",
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "PARAM$trainingstrategy$undersampling <- 1.0\n",
    "PARAM$trainingstrategy$semilla_azar <- c(279511, 279523, 279541, 279551, 279571)  # Aqui poner su  primer  semilla/ pongo todas mis semillas\n",
    "\n",
    "PARAM$hyperparametertuning$POS_ganancia <- 273000\n",
    "PARAM$hyperparametertuning$NEG_ganancia <- -7000\n",
    "\n",
    "# Aqui va semilla\n",
    "PARAM$lgb_semilla <- 279511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Hiperparametros FIJOS de  lightgbm\n",
    "PARAM$lgb_basicos <- list(\n",
    "  boosting = \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
    "  objective = \"binary\",\n",
    "  metric = \"custom\",\n",
    "  first_metric_only = TRUE,\n",
    "  boost_from_average = TRUE,\n",
    "  feature_pre_filter = FALSE,\n",
    "  force_row_wise = TRUE, # para reducir warnings\n",
    "  verbosity = -100,\n",
    "  max_depth = -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split = 0.0, # min_gain_to_split >= 0.0\n",
    "  min_sum_hessian_in_leaf = 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1 = 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2 = 0.0, # lambda_l2 >= 0.0\n",
    "  max_bin = 31L, # lo debo dejar fijo, no participa de la BO\n",
    "  num_iterations = 9999, # un numero muy grande, lo limita early_stopping_rounds\n",
    "\n",
    "  bagging_fraction = 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction = 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction = 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance = FALSE, #\n",
    "  scale_pos_weight = 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate = 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop = 50, # <=0 means no limit\n",
    "  skip_drop = 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  extra_trees = TRUE, # Magic Sauce\n",
    "\n",
    "  seed = PARAM$lgb_semilla\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui se cargan los hiperparametros que se optimizan\n",
    "#  en la Bayesian Optimization\n",
    "PARAM$bo_lgb <- makeParamSet(\n",
    "  makeNumericParam(\"learning_rate\", lower = 0.02, upper = 0.3),\n",
    "  makeNumericParam(\"feature_fraction\", lower = 0.01, upper = 1.0),\n",
    "  makeIntegerParam(\"num_leaves\", lower = 8L, upper = 1024L),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower = 100L, upper = 50000L)\n",
    ")\n",
    "\n",
    "# si usted es ambicioso, y tiene paciencia, podria subir este valor a 100\n",
    "PARAM$bo_iteraciones <- 50 # iteraciones de la Optimizacion Bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# graba a un archivo los componentes de lista\n",
    "# para el primer registro, escribe antes los titulos\n",
    "\n",
    "loguear <- function(\n",
    "    reg, arch = NA, folder = \"./exp/\",\n",
    "    ext = \".txt\", verbose = TRUE) {\n",
    "  archivo <- arch\n",
    "  if (is.na(arch)) archivo <- paste0(folder, substitute(reg), ext)\n",
    "\n",
    "  if (!file.exists(archivo)) # Escribo los titulos\n",
    "    {\n",
    "      linea <- paste0(\n",
    "        \"fecha\\t\",\n",
    "        paste(list.names(reg), collapse = \"\\t\"), \"\\n\"\n",
    "      )\n",
    "\n",
    "      cat(linea, file = archivo)\n",
    "    }\n",
    "\n",
    "  linea <- paste0(\n",
    "    format(Sys.time(), \"%Y%m%d %H%M%S\"), \"\\t\", # la fecha y hora\n",
    "    gsub(\", \", \"\\t\", toString(reg)), \"\\n\"\n",
    "  )\n",
    "\n",
    "  cat(linea, file = archivo, append = TRUE) # grabo al archivo\n",
    "\n",
    "  if (verbose) cat(linea) # imprimo por pantalla\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "GLOBAL_arbol <- 0L\n",
    "GLOBAL_gan_max <- -Inf\n",
    "vcant_optima <- c()\n",
    "\n",
    "fganancia_lgbm_meseta <- function(probs, datos) {\n",
    "  vlabels <- get_field(datos, \"label\")\n",
    "  vpesos <- get_field(datos, \"weight\")\n",
    "\n",
    "\n",
    "  GLOBAL_arbol <<- GLOBAL_arbol + 1\n",
    "  tbl <- as.data.table(list(\n",
    "    \"prob\" = probs,\n",
    "    \"gan\" = ifelse(vlabels == 1 & vpesos > 1,\n",
    "      PARAM$hyperparametertuning$POS_ganancia,\n",
    "      PARAM$hyperparametertuning$NEG_ganancia  )\n",
    "  ))\n",
    "\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, posicion := .I]\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "\n",
    "  tbl[, gan_suavizada :=\n",
    "    frollmean(\n",
    "      x = gan_acum, n = 2001, align = \"center\",\n",
    "      na.rm = TRUE, hasNA = TRUE\n",
    "    )]\n",
    "\n",
    "  gan <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "\n",
    "  pos <- which.max(tbl[, gan_suavizada])\n",
    "  vcant_optima <<- c(vcant_optima, pos)\n",
    "\n",
    "  if (GLOBAL_arbol %% 10 == 0) {\n",
    "    if (gan > GLOBAL_gan_max) GLOBAL_gan_max <<- gan\n",
    "\n",
    "    cat(\"\\r\")\n",
    "    cat(\n",
    "      \"Validate \", GLOBAL_iteracion, \" \", \" \",\n",
    "      GLOBAL_arbol, \"  \", gan, \"   \", GLOBAL_gan_max, \"   \"\n",
    "    )\n",
    "  }\n",
    "\n",
    "\n",
    "  return(list(\n",
    "    \"name\" = \"ganancia\",\n",
    "    \"value\" = gan,\n",
    "    \"higher_better\" = TRUE\n",
    "  ))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "\n",
    "EstimarGanancia_lightgbm <- function(x) {\n",
    "  gc()\n",
    "  GLOBAL_iteracion <<- GLOBAL_iteracion + 1L\n",
    "\n",
    "  # hago la union de los parametros basicos y los moviles que vienen en x\n",
    "  param_completo <- c(PARAM$lgb_basicos, x)\n",
    "\n",
    "  param_completo$early_stopping_rounds <-\n",
    "    as.integer(400 + 4 / param_completo$learning_rate)\n",
    "\n",
    "  GLOBAL_arbol <<- 0L\n",
    "  GLOBAL_gan_max <<- -Inf\n",
    "  vcant_optima <<- c()\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  modelo_train <- lgb.train(\n",
    "    data = dtrain,\n",
    "    valids = list(valid = dvalidate),\n",
    "    eval = fganancia_lgbm_meseta,\n",
    "    param = param_completo,\n",
    "    verbose = -100\n",
    "  )\n",
    "\n",
    "  cat(\"\\n\")\n",
    "\n",
    "  cant_corte <- vcant_optima[modelo_train$best_iter]\n",
    "\n",
    "  # aplico el modelo a testing y calculo la ganancia\n",
    "  prediccion <- predict(\n",
    "    modelo_train,\n",
    "    data.matrix(dataset_test[, campos_buenos, with = FALSE])\n",
    "  )\n",
    "\n",
    "  tbl <- copy(dataset_test[, list(\"gan\" = ifelse(clase_ternaria == \"BAJA+2\",\n",
    "    PARAM$hyperparametertuning$POS_ganancia, \n",
    "    PARAM$hyperparametertuning$NEG_ganancia))])\n",
    "\n",
    "  tbl[, prob := prediccion]\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "  tbl[, gan_suavizada := frollmean(\n",
    "    x = gan_acum, n = 2001,\n",
    "    align = \"center\", na.rm = TRUE, hasNA = TRUE\n",
    "  )]\n",
    "\n",
    "\n",
    "  ganancia_test <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "  cantidad_test_normalizada <- which.max(tbl[, gan_suavizada])\n",
    "\n",
    "  rm(tbl)\n",
    "  gc()\n",
    "\n",
    "  ganancia_test_normalizada <- ganancia_test\n",
    "\n",
    "\n",
    "  # voy grabando las mejores column importance\n",
    "  if (ganancia_test_normalizada > GLOBAL_gananciamax) {\n",
    "    GLOBAL_gananciamax <<- ganancia_test_normalizada\n",
    "    tb_importancia <- as.data.table(lgb.importance(modelo_train))\n",
    "\n",
    "    fwrite(tb_importancia,\n",
    "      file = paste0(\"impo_\", sprintf(\"%03d\", GLOBAL_iteracion), \".txt\"),\n",
    "      sep = \"\\t\"\n",
    "    )\n",
    "\n",
    "    rm(tb_importancia)\n",
    "  }\n",
    "\n",
    "\n",
    "  # logueo final\n",
    "  ds <- list(\"cols\" = ncol(dtrain), \"rows\" = nrow(dtrain))\n",
    "  xx <- c(ds, copy(param_completo))\n",
    "\n",
    "  xx$early_stopping_rounds <- NULL\n",
    "  xx$num_iterations <- modelo_train$best_iter\n",
    "  xx$estimulos <- cantidad_test_normalizada\n",
    "  xx$ganancia <- ganancia_test_normalizada\n",
    "  xx$iteracion_bayesiana <- GLOBAL_iteracion\n",
    "\n",
    "  loguear(xx, arch = \"BO_log.txt\")\n",
    "\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  return(ganancia_test_normalizada)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aquí empieza el programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui empieza el programa\n",
    "\n",
    "# Aqui se debe poner la carpeta de la computadora local\n",
    "setwd(\"~/buckets/b1/\") # Establezco el Working Directory\n",
    "\n",
    "# cargo el dataset donde voy a entrenar el modelo\n",
    "dataset <- fread(PARAM$input$dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# creo la carpeta donde va el experimento\n",
    "dir.create(\"./exp/\", showWarnings = FALSE)\n",
    "dir.create(paste0(\"./exp/\", PARAM$experimento, \"/\"), showWarnings = FALSE)\n",
    "\n",
    "# Establezco el Working Directory DEL EXPERIMENTO\n",
    "setwd(paste0(\"./exp/\", PARAM$experimento, \"/\"))\n",
    "\n",
    "# en estos archivos quedan los resultados\n",
    "kbayesiana <- paste0(PARAM$experimento, \".RDATA\")\n",
    "klog <- paste0(PARAM$experimento, \".txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Catastrophe Analysis  -------------------------------------------------------\n",
    "# deben ir cosas de este estilo\n",
    "#   dataset[foto_mes == 202006, active_quarter := NA]\n",
    "\n",
    "# Data Drifting\n",
    "# por ahora, no hago nada\n",
    "\n",
    "\n",
    "# Feature Engineering Historico  ----------------------------------------------\n",
    "#   aqui deben calcularse los  lags y  lag_delta\n",
    "#   Sin lags no hay paraiso !  corta la bocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ahora SI comienza la optimizacion Bayesiana\n",
    "\n",
    "GLOBAL_iteracion <- 0 # inicializo la variable global\n",
    "GLOBAL_gananciamax <- -1 # inicializo la variable global\n",
    "\n",
    "# si ya existe el archivo log, traigo hasta donde llegue\n",
    "if (file.exists(klog)) {\n",
    "  tabla_log <- fread(klog)\n",
    "  GLOBAL_iteracion <- nrow(tabla_log)\n",
    "  GLOBAL_gananciamax <- tabla_log[, max(ganancia)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "dataset[, clase01 := ifelse(clase_ternaria == \"CONTINUA\", 0L, 1L)]\n",
    "\n",
    "\n",
    "# los campos que se van a utilizar\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "set.seed(PARAM$trainingstrategy$semilla_azar)\n",
    "dataset[, azar := runif(nrow(dataset))]\n",
    "dataset[, training := 0L]\n",
    "dataset[\n",
    "  foto_mes %in% PARAM$input$training &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "dtrain <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[training == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[training == 1L, clase01],\n",
    "  weight = dataset[training == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forman parte de validation\n",
    "#  no hay undersampling\n",
    "dataset[, validation := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$validation,  validation := 1L]\n",
    "\n",
    "dvalidate <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[validation == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[validation == 1L, clase01],\n",
    "  weight = dataset[validation == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos de testing\n",
    "dataset[, testing := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$testing,  testing := 1L]\n",
    "\n",
    "\n",
    "dataset_test <- dataset[testing == 1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# libero espacio\n",
    "rm(dataset)\n",
    "gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "funcion_optimizar <- EstimarGanancia_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output = FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn = funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize = FALSE, # estoy Maximizando la ganancia\n",
    "  noisy = TRUE,\n",
    "  par.set = PARAM$bo_lgb, # definido al comienzo del programa\n",
    "  has.simple.signature = FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time = 600, # se graba cada 600 segundos\n",
    "  save.file.path = kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters = PARAM$bo_iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())\n",
    "\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type = \"se\",\n",
    "  covtype = \"matern3_2\",\n",
    "  control = list(trace = TRUE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# inicio la optimizacion bayesiana\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  run <- mbo(obj.fun, learner = surr.km, control = ctrl)\n",
    "} else {\n",
    "  run <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}\n",
    "\n",
    "\n",
    "cat(\"\\n\\nLa optimizacion Bayesiana ha terminado\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semilla 2, ajustado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# limpio la memoria\n",
    "rm(list = ls()) # remove all objects\n",
    "gc() # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "require(\"data.table\")\n",
    "require(\"rlist\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paquetes necesarios para la Bayesian Optimization\n",
    "require(\"DiceKriging\")\n",
    "require(\"mlrMBO\")\n",
    "\n",
    "# para que se detenga ante el primer error\n",
    "# y muestre el stack de funciones invocadas\n",
    "options(error = function() {\n",
    "  traceback(20)\n",
    "  options(error = NULL)\n",
    "  stop(\"exiting after script error\")\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los parametros de la corrida, en una lista, la variable global  PARAM\n",
    "#  muy pronto esto se leera desde un archivo formato .yaml\n",
    "PARAM <- list()\n",
    "\n",
    "PARAM$experimento <- \"HT8230 (Clase 12, Ajustado Sem2)\"\n",
    "\n",
    "PARAM$input$dataset <- \"datasets/competencia_03_infla_ajustado_lags.csv.gz\"\n",
    "\n",
    "# los meses en los que vamos a entrenar\n",
    "#  mucha magia emerger de esta eleccion\n",
    "PARAM$input$testing <- c(202107) # Último mes, lo más cercano al 202109 de kaggle\n",
    "PARAM$input$validation <- c(202106)\n",
    "PARAM$input$training <- c(202105, 202104, 202103, 202102, 202101,202012) # 6 meses de entrenamiento\t\n",
    "\n",
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "PARAM$trainingstrategy$undersampling <- 1.0\n",
    "PARAM$trainingstrategy$semilla_azar <- c(279511, 279523, 279541, 279551, 279571)  # Aqui poner su  primer  semilla/ pongo todas mis semillas\n",
    "\n",
    "PARAM$hyperparametertuning$POS_ganancia <- 273000\n",
    "PARAM$hyperparametertuning$NEG_ganancia <- -7000\n",
    "\n",
    "# Aqui va semilla\n",
    "PARAM$lgb_semilla <- 279523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Hiperparametros FIJOS de  lightgbm\n",
    "PARAM$lgb_basicos <- list(\n",
    "  boosting = \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
    "  objective = \"binary\",\n",
    "  metric = \"custom\",\n",
    "  first_metric_only = TRUE,\n",
    "  boost_from_average = TRUE,\n",
    "  feature_pre_filter = FALSE,\n",
    "  force_row_wise = TRUE, # para reducir warnings\n",
    "  verbosity = -100,\n",
    "  max_depth = -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split = 0.0, # min_gain_to_split >= 0.0\n",
    "  min_sum_hessian_in_leaf = 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1 = 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2 = 0.0, # lambda_l2 >= 0.0\n",
    "  max_bin = 31L, # lo debo dejar fijo, no participa de la BO\n",
    "  num_iterations = 9999, # un numero muy grande, lo limita early_stopping_rounds\n",
    "\n",
    "  bagging_fraction = 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction = 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction = 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance = FALSE, #\n",
    "  scale_pos_weight = 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate = 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop = 50, # <=0 means no limit\n",
    "  skip_drop = 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  extra_trees = TRUE, # Magic Sauce\n",
    "\n",
    "  seed = PARAM$lgb_semilla\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui se cargan los hiperparametros que se optimizan\n",
    "#  en la Bayesian Optimization\n",
    "PARAM$bo_lgb <- makeParamSet(\n",
    "  makeNumericParam(\"learning_rate\", lower = 0.02, upper = 0.3),\n",
    "  makeNumericParam(\"feature_fraction\", lower = 0.01, upper = 1.0),\n",
    "  makeIntegerParam(\"num_leaves\", lower = 8L, upper = 1024L),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower = 100L, upper = 50000L)\n",
    ")\n",
    "\n",
    "# si usted es ambicioso, y tiene paciencia, podria subir este valor a 100\n",
    "PARAM$bo_iteraciones <- 50 # iteraciones de la Optimizacion Bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# graba a un archivo los componentes de lista\n",
    "# para el primer registro, escribe antes los titulos\n",
    "\n",
    "loguear <- function(\n",
    "    reg, arch = NA, folder = \"./exp/\",\n",
    "    ext = \".txt\", verbose = TRUE) {\n",
    "  archivo <- arch\n",
    "  if (is.na(arch)) archivo <- paste0(folder, substitute(reg), ext)\n",
    "\n",
    "  if (!file.exists(archivo)) # Escribo los titulos\n",
    "    {\n",
    "      linea <- paste0(\n",
    "        \"fecha\\t\",\n",
    "        paste(list.names(reg), collapse = \"\\t\"), \"\\n\"\n",
    "      )\n",
    "\n",
    "      cat(linea, file = archivo)\n",
    "    }\n",
    "\n",
    "  linea <- paste0(\n",
    "    format(Sys.time(), \"%Y%m%d %H%M%S\"), \"\\t\", # la fecha y hora\n",
    "    gsub(\", \", \"\\t\", toString(reg)), \"\\n\"\n",
    "  )\n",
    "\n",
    "  cat(linea, file = archivo, append = TRUE) # grabo al archivo\n",
    "\n",
    "  if (verbose) cat(linea) # imprimo por pantalla\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "GLOBAL_arbol <- 0L\n",
    "GLOBAL_gan_max <- -Inf\n",
    "vcant_optima <- c()\n",
    "\n",
    "fganancia_lgbm_meseta <- function(probs, datos) {\n",
    "  vlabels <- get_field(datos, \"label\")\n",
    "  vpesos <- get_field(datos, \"weight\")\n",
    "\n",
    "\n",
    "  GLOBAL_arbol <<- GLOBAL_arbol + 1\n",
    "  tbl <- as.data.table(list(\n",
    "    \"prob\" = probs,\n",
    "    \"gan\" = ifelse(vlabels == 1 & vpesos > 1,\n",
    "      PARAM$hyperparametertuning$POS_ganancia,\n",
    "      PARAM$hyperparametertuning$NEG_ganancia  )\n",
    "  ))\n",
    "\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, posicion := .I]\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "\n",
    "  tbl[, gan_suavizada :=\n",
    "    frollmean(\n",
    "      x = gan_acum, n = 2001, align = \"center\",\n",
    "      na.rm = TRUE, hasNA = TRUE\n",
    "    )]\n",
    "\n",
    "  gan <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "\n",
    "  pos <- which.max(tbl[, gan_suavizada])\n",
    "  vcant_optima <<- c(vcant_optima, pos)\n",
    "\n",
    "  if (GLOBAL_arbol %% 10 == 0) {\n",
    "    if (gan > GLOBAL_gan_max) GLOBAL_gan_max <<- gan\n",
    "\n",
    "    cat(\"\\r\")\n",
    "    cat(\n",
    "      \"Validate \", GLOBAL_iteracion, \" \", \" \",\n",
    "      GLOBAL_arbol, \"  \", gan, \"   \", GLOBAL_gan_max, \"   \"\n",
    "    )\n",
    "  }\n",
    "\n",
    "\n",
    "  return(list(\n",
    "    \"name\" = \"ganancia\",\n",
    "    \"value\" = gan,\n",
    "    \"higher_better\" = TRUE\n",
    "  ))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "\n",
    "EstimarGanancia_lightgbm <- function(x) {\n",
    "  gc()\n",
    "  GLOBAL_iteracion <<- GLOBAL_iteracion + 1L\n",
    "\n",
    "  # hago la union de los parametros basicos y los moviles que vienen en x\n",
    "  param_completo <- c(PARAM$lgb_basicos, x)\n",
    "\n",
    "  param_completo$early_stopping_rounds <-\n",
    "    as.integer(400 + 4 / param_completo$learning_rate)\n",
    "\n",
    "  GLOBAL_arbol <<- 0L\n",
    "  GLOBAL_gan_max <<- -Inf\n",
    "  vcant_optima <<- c()\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  modelo_train <- lgb.train(\n",
    "    data = dtrain,\n",
    "    valids = list(valid = dvalidate),\n",
    "    eval = fganancia_lgbm_meseta,\n",
    "    param = param_completo,\n",
    "    verbose = -100\n",
    "  )\n",
    "\n",
    "  cat(\"\\n\")\n",
    "\n",
    "  cant_corte <- vcant_optima[modelo_train$best_iter]\n",
    "\n",
    "  # aplico el modelo a testing y calculo la ganancia\n",
    "  prediccion <- predict(\n",
    "    modelo_train,\n",
    "    data.matrix(dataset_test[, campos_buenos, with = FALSE])\n",
    "  )\n",
    "\n",
    "  tbl <- copy(dataset_test[, list(\"gan\" = ifelse(clase_ternaria == \"BAJA+2\",\n",
    "    PARAM$hyperparametertuning$POS_ganancia, \n",
    "    PARAM$hyperparametertuning$NEG_ganancia))])\n",
    "\n",
    "  tbl[, prob := prediccion]\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "  tbl[, gan_suavizada := frollmean(\n",
    "    x = gan_acum, n = 2001,\n",
    "    align = \"center\", na.rm = TRUE, hasNA = TRUE\n",
    "  )]\n",
    "\n",
    "\n",
    "  ganancia_test <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "  cantidad_test_normalizada <- which.max(tbl[, gan_suavizada])\n",
    "\n",
    "  rm(tbl)\n",
    "  gc()\n",
    "\n",
    "  ganancia_test_normalizada <- ganancia_test\n",
    "\n",
    "\n",
    "  # voy grabando las mejores column importance\n",
    "  if (ganancia_test_normalizada > GLOBAL_gananciamax) {\n",
    "    GLOBAL_gananciamax <<- ganancia_test_normalizada\n",
    "    tb_importancia <- as.data.table(lgb.importance(modelo_train))\n",
    "\n",
    "    fwrite(tb_importancia,\n",
    "      file = paste0(\"impo_\", sprintf(\"%03d\", GLOBAL_iteracion), \".txt\"),\n",
    "      sep = \"\\t\"\n",
    "    )\n",
    "\n",
    "    rm(tb_importancia)\n",
    "  }\n",
    "\n",
    "\n",
    "  # logueo final\n",
    "  ds <- list(\"cols\" = ncol(dtrain), \"rows\" = nrow(dtrain))\n",
    "  xx <- c(ds, copy(param_completo))\n",
    "\n",
    "  xx$early_stopping_rounds <- NULL\n",
    "  xx$num_iterations <- modelo_train$best_iter\n",
    "  xx$estimulos <- cantidad_test_normalizada\n",
    "  xx$ganancia <- ganancia_test_normalizada\n",
    "  xx$iteracion_bayesiana <- GLOBAL_iteracion\n",
    "\n",
    "  loguear(xx, arch = \"BO_log.txt\")\n",
    "\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  return(ganancia_test_normalizada)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aquí empieza el programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui empieza el programa\n",
    "\n",
    "# Aqui se debe poner la carpeta de la computadora local\n",
    "setwd(\"~/buckets/b1/\") # Establezco el Working Directory\n",
    "\n",
    "# cargo el dataset donde voy a entrenar el modelo\n",
    "dataset <- fread(PARAM$input$dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# creo la carpeta donde va el experimento\n",
    "dir.create(\"./exp/\", showWarnings = FALSE)\n",
    "dir.create(paste0(\"./exp/\", PARAM$experimento, \"/\"), showWarnings = FALSE)\n",
    "\n",
    "# Establezco el Working Directory DEL EXPERIMENTO\n",
    "setwd(paste0(\"./exp/\", PARAM$experimento, \"/\"))\n",
    "\n",
    "# en estos archivos quedan los resultados\n",
    "kbayesiana <- paste0(PARAM$experimento, \".RDATA\")\n",
    "klog <- paste0(PARAM$experimento, \".txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Catastrophe Analysis  -------------------------------------------------------\n",
    "# deben ir cosas de este estilo\n",
    "#   dataset[foto_mes == 202006, active_quarter := NA]\n",
    "\n",
    "# Data Drifting\n",
    "# por ahora, no hago nada\n",
    "\n",
    "\n",
    "# Feature Engineering Historico  ----------------------------------------------\n",
    "#   aqui deben calcularse los  lags y  lag_delta\n",
    "#   Sin lags no hay paraiso !  corta la bocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ahora SI comienza la optimizacion Bayesiana\n",
    "\n",
    "GLOBAL_iteracion <- 0 # inicializo la variable global\n",
    "GLOBAL_gananciamax <- -1 # inicializo la variable global\n",
    "\n",
    "# si ya existe el archivo log, traigo hasta donde llegue\n",
    "if (file.exists(klog)) {\n",
    "  tabla_log <- fread(klog)\n",
    "  GLOBAL_iteracion <- nrow(tabla_log)\n",
    "  GLOBAL_gananciamax <- tabla_log[, max(ganancia)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "dataset[, clase01 := ifelse(clase_ternaria == \"CONTINUA\", 0L, 1L)]\n",
    "\n",
    "\n",
    "# los campos que se van a utilizar\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "set.seed(PARAM$trainingstrategy$semilla_azar)\n",
    "dataset[, azar := runif(nrow(dataset))]\n",
    "dataset[, training := 0L]\n",
    "dataset[\n",
    "  foto_mes %in% PARAM$input$training &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "dtrain <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[training == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[training == 1L, clase01],\n",
    "  weight = dataset[training == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forman parte de validation\n",
    "#  no hay undersampling\n",
    "dataset[, validation := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$validation,  validation := 1L]\n",
    "\n",
    "dvalidate <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[validation == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[validation == 1L, clase01],\n",
    "  weight = dataset[validation == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos de testing\n",
    "dataset[, testing := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$testing,  testing := 1L]\n",
    "\n",
    "\n",
    "dataset_test <- dataset[testing == 1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# libero espacio\n",
    "rm(dataset)\n",
    "gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "funcion_optimizar <- EstimarGanancia_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output = FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn = funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize = FALSE, # estoy Maximizando la ganancia\n",
    "  noisy = TRUE,\n",
    "  par.set = PARAM$bo_lgb, # definido al comienzo del programa\n",
    "  has.simple.signature = FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time = 600, # se graba cada 600 segundos\n",
    "  save.file.path = kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters = PARAM$bo_iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())\n",
    "\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type = \"se\",\n",
    "  covtype = \"matern3_2\",\n",
    "  control = list(trace = TRUE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# inicio la optimizacion bayesiana\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  run <- mbo(obj.fun, learner = surr.km, control = ctrl)\n",
    "} else {\n",
    "  run <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}\n",
    "\n",
    "\n",
    "cat(\"\\n\\nLa optimizacion Bayesiana ha terminado\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semilla 3, ajustado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# limpio la memoria\n",
    "rm(list = ls()) # remove all objects\n",
    "gc() # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "require(\"data.table\")\n",
    "require(\"rlist\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paquetes necesarios para la Bayesian Optimization\n",
    "require(\"DiceKriging\")\n",
    "require(\"mlrMBO\")\n",
    "\n",
    "# para que se detenga ante el primer error\n",
    "# y muestre el stack de funciones invocadas\n",
    "options(error = function() {\n",
    "  traceback(20)\n",
    "  options(error = NULL)\n",
    "  stop(\"exiting after script error\")\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los parametros de la corrida, en una lista, la variable global  PARAM\n",
    "#  muy pronto esto se leera desde un archivo formato .yaml\n",
    "PARAM <- list()\n",
    "\n",
    "PARAM$experimento <- \"HT8230 (Clase 12, Ajustado Sem3)\"\n",
    "\n",
    "PARAM$input$dataset <- \"datasets/competencia_03_infla_ajustado_lags.csv.gz\"\n",
    "\n",
    "# los meses en los que vamos a entrenar\n",
    "#  mucha magia emerger de esta eleccion\n",
    "PARAM$input$testing <- c(202107) # Último mes, lo más cercano al 202109 de kaggle\n",
    "PARAM$input$validation <- c(202106)\n",
    "PARAM$input$training <- c(202105, 202104, 202103, 202102, 202101,202012) # 6 meses de entrenamiento\t\n",
    "\n",
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "PARAM$trainingstrategy$undersampling <- 1.0\n",
    "PARAM$trainingstrategy$semilla_azar <- c(279511, 279523, 279541, 279551, 279571)  # Aqui poner su  primer  semilla/ pongo todas mis semillas\n",
    "\n",
    "PARAM$hyperparametertuning$POS_ganancia <- 273000\n",
    "PARAM$hyperparametertuning$NEG_ganancia <- -7000\n",
    "\n",
    "# Aqui va semilla\n",
    "PARAM$lgb_semilla <- 279541"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Hiperparametros FIJOS de  lightgbm\n",
    "PARAM$lgb_basicos <- list(\n",
    "  boosting = \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
    "  objective = \"binary\",\n",
    "  metric = \"custom\",\n",
    "  first_metric_only = TRUE,\n",
    "  boost_from_average = TRUE,\n",
    "  feature_pre_filter = FALSE,\n",
    "  force_row_wise = TRUE, # para reducir warnings\n",
    "  verbosity = -100,\n",
    "  max_depth = -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split = 0.0, # min_gain_to_split >= 0.0\n",
    "  min_sum_hessian_in_leaf = 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1 = 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2 = 0.0, # lambda_l2 >= 0.0\n",
    "  max_bin = 31L, # lo debo dejar fijo, no participa de la BO\n",
    "  num_iterations = 9999, # un numero muy grande, lo limita early_stopping_rounds\n",
    "\n",
    "  bagging_fraction = 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction = 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction = 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance = FALSE, #\n",
    "  scale_pos_weight = 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate = 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop = 50, # <=0 means no limit\n",
    "  skip_drop = 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  extra_trees = TRUE, # Magic Sauce\n",
    "\n",
    "  seed = PARAM$lgb_semilla\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui se cargan los hiperparametros que se optimizan\n",
    "#  en la Bayesian Optimization\n",
    "PARAM$bo_lgb <- makeParamSet(\n",
    "  makeNumericParam(\"learning_rate\", lower = 0.02, upper = 0.3),\n",
    "  makeNumericParam(\"feature_fraction\", lower = 0.01, upper = 1.0),\n",
    "  makeIntegerParam(\"num_leaves\", lower = 8L, upper = 1024L),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower = 100L, upper = 50000L)\n",
    ")\n",
    "\n",
    "# si usted es ambicioso, y tiene paciencia, podria subir este valor a 100\n",
    "PARAM$bo_iteraciones <- 50 # iteraciones de la Optimizacion Bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# graba a un archivo los componentes de lista\n",
    "# para el primer registro, escribe antes los titulos\n",
    "\n",
    "loguear <- function(\n",
    "    reg, arch = NA, folder = \"./exp/\",\n",
    "    ext = \".txt\", verbose = TRUE) {\n",
    "  archivo <- arch\n",
    "  if (is.na(arch)) archivo <- paste0(folder, substitute(reg), ext)\n",
    "\n",
    "  if (!file.exists(archivo)) # Escribo los titulos\n",
    "    {\n",
    "      linea <- paste0(\n",
    "        \"fecha\\t\",\n",
    "        paste(list.names(reg), collapse = \"\\t\"), \"\\n\"\n",
    "      )\n",
    "\n",
    "      cat(linea, file = archivo)\n",
    "    }\n",
    "\n",
    "  linea <- paste0(\n",
    "    format(Sys.time(), \"%Y%m%d %H%M%S\"), \"\\t\", # la fecha y hora\n",
    "    gsub(\", \", \"\\t\", toString(reg)), \"\\n\"\n",
    "  )\n",
    "\n",
    "  cat(linea, file = archivo, append = TRUE) # grabo al archivo\n",
    "\n",
    "  if (verbose) cat(linea) # imprimo por pantalla\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "GLOBAL_arbol <- 0L\n",
    "GLOBAL_gan_max <- -Inf\n",
    "vcant_optima <- c()\n",
    "\n",
    "fganancia_lgbm_meseta <- function(probs, datos) {\n",
    "  vlabels <- get_field(datos, \"label\")\n",
    "  vpesos <- get_field(datos, \"weight\")\n",
    "\n",
    "\n",
    "  GLOBAL_arbol <<- GLOBAL_arbol + 1\n",
    "  tbl <- as.data.table(list(\n",
    "    \"prob\" = probs,\n",
    "    \"gan\" = ifelse(vlabels == 1 & vpesos > 1,\n",
    "      PARAM$hyperparametertuning$POS_ganancia,\n",
    "      PARAM$hyperparametertuning$NEG_ganancia  )\n",
    "  ))\n",
    "\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, posicion := .I]\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "\n",
    "  tbl[, gan_suavizada :=\n",
    "    frollmean(\n",
    "      x = gan_acum, n = 2001, align = \"center\",\n",
    "      na.rm = TRUE, hasNA = TRUE\n",
    "    )]\n",
    "\n",
    "  gan <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "\n",
    "  pos <- which.max(tbl[, gan_suavizada])\n",
    "  vcant_optima <<- c(vcant_optima, pos)\n",
    "\n",
    "  if (GLOBAL_arbol %% 10 == 0) {\n",
    "    if (gan > GLOBAL_gan_max) GLOBAL_gan_max <<- gan\n",
    "\n",
    "    cat(\"\\r\")\n",
    "    cat(\n",
    "      \"Validate \", GLOBAL_iteracion, \" \", \" \",\n",
    "      GLOBAL_arbol, \"  \", gan, \"   \", GLOBAL_gan_max, \"   \"\n",
    "    )\n",
    "  }\n",
    "\n",
    "\n",
    "  return(list(\n",
    "    \"name\" = \"ganancia\",\n",
    "    \"value\" = gan,\n",
    "    \"higher_better\" = TRUE\n",
    "  ))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "\n",
    "EstimarGanancia_lightgbm <- function(x) {\n",
    "  gc()\n",
    "  GLOBAL_iteracion <<- GLOBAL_iteracion + 1L\n",
    "\n",
    "  # hago la union de los parametros basicos y los moviles que vienen en x\n",
    "  param_completo <- c(PARAM$lgb_basicos, x)\n",
    "\n",
    "  param_completo$early_stopping_rounds <-\n",
    "    as.integer(400 + 4 / param_completo$learning_rate)\n",
    "\n",
    "  GLOBAL_arbol <<- 0L\n",
    "  GLOBAL_gan_max <<- -Inf\n",
    "  vcant_optima <<- c()\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  modelo_train <- lgb.train(\n",
    "    data = dtrain,\n",
    "    valids = list(valid = dvalidate),\n",
    "    eval = fganancia_lgbm_meseta,\n",
    "    param = param_completo,\n",
    "    verbose = -100\n",
    "  )\n",
    "\n",
    "  cat(\"\\n\")\n",
    "\n",
    "  cant_corte <- vcant_optima[modelo_train$best_iter]\n",
    "\n",
    "  # aplico el modelo a testing y calculo la ganancia\n",
    "  prediccion <- predict(\n",
    "    modelo_train,\n",
    "    data.matrix(dataset_test[, campos_buenos, with = FALSE])\n",
    "  )\n",
    "\n",
    "  tbl <- copy(dataset_test[, list(\"gan\" = ifelse(clase_ternaria == \"BAJA+2\",\n",
    "    PARAM$hyperparametertuning$POS_ganancia, \n",
    "    PARAM$hyperparametertuning$NEG_ganancia))])\n",
    "\n",
    "  tbl[, prob := prediccion]\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "  tbl[, gan_suavizada := frollmean(\n",
    "    x = gan_acum, n = 2001,\n",
    "    align = \"center\", na.rm = TRUE, hasNA = TRUE\n",
    "  )]\n",
    "\n",
    "\n",
    "  ganancia_test <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "  cantidad_test_normalizada <- which.max(tbl[, gan_suavizada])\n",
    "\n",
    "  rm(tbl)\n",
    "  gc()\n",
    "\n",
    "  ganancia_test_normalizada <- ganancia_test\n",
    "\n",
    "\n",
    "  # voy grabando las mejores column importance\n",
    "  if (ganancia_test_normalizada > GLOBAL_gananciamax) {\n",
    "    GLOBAL_gananciamax <<- ganancia_test_normalizada\n",
    "    tb_importancia <- as.data.table(lgb.importance(modelo_train))\n",
    "\n",
    "    fwrite(tb_importancia,\n",
    "      file = paste0(\"impo_\", sprintf(\"%03d\", GLOBAL_iteracion), \".txt\"),\n",
    "      sep = \"\\t\"\n",
    "    )\n",
    "\n",
    "    rm(tb_importancia)\n",
    "  }\n",
    "\n",
    "\n",
    "  # logueo final\n",
    "  ds <- list(\"cols\" = ncol(dtrain), \"rows\" = nrow(dtrain))\n",
    "  xx <- c(ds, copy(param_completo))\n",
    "\n",
    "  xx$early_stopping_rounds <- NULL\n",
    "  xx$num_iterations <- modelo_train$best_iter\n",
    "  xx$estimulos <- cantidad_test_normalizada\n",
    "  xx$ganancia <- ganancia_test_normalizada\n",
    "  xx$iteracion_bayesiana <- GLOBAL_iteracion\n",
    "\n",
    "  loguear(xx, arch = \"BO_log.txt\")\n",
    "\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  return(ganancia_test_normalizada)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aquí empieza el programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui empieza el programa\n",
    "\n",
    "# Aqui se debe poner la carpeta de la computadora local\n",
    "setwd(\"~/buckets/b1/\") # Establezco el Working Directory\n",
    "\n",
    "# cargo el dataset donde voy a entrenar el modelo\n",
    "dataset <- fread(PARAM$input$dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# creo la carpeta donde va el experimento\n",
    "dir.create(\"./exp/\", showWarnings = FALSE)\n",
    "dir.create(paste0(\"./exp/\", PARAM$experimento, \"/\"), showWarnings = FALSE)\n",
    "\n",
    "# Establezco el Working Directory DEL EXPERIMENTO\n",
    "setwd(paste0(\"./exp/\", PARAM$experimento, \"/\"))\n",
    "\n",
    "# en estos archivos quedan los resultados\n",
    "kbayesiana <- paste0(PARAM$experimento, \".RDATA\")\n",
    "klog <- paste0(PARAM$experimento, \".txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Catastrophe Analysis  -------------------------------------------------------\n",
    "# deben ir cosas de este estilo\n",
    "#   dataset[foto_mes == 202006, active_quarter := NA]\n",
    "\n",
    "# Data Drifting\n",
    "# por ahora, no hago nada\n",
    "\n",
    "\n",
    "# Feature Engineering Historico  ----------------------------------------------\n",
    "#   aqui deben calcularse los  lags y  lag_delta\n",
    "#   Sin lags no hay paraiso !  corta la bocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ahora SI comienza la optimizacion Bayesiana\n",
    "\n",
    "GLOBAL_iteracion <- 0 # inicializo la variable global\n",
    "GLOBAL_gananciamax <- -1 # inicializo la variable global\n",
    "\n",
    "# si ya existe el archivo log, traigo hasta donde llegue\n",
    "if (file.exists(klog)) {\n",
    "  tabla_log <- fread(klog)\n",
    "  GLOBAL_iteracion <- nrow(tabla_log)\n",
    "  GLOBAL_gananciamax <- tabla_log[, max(ganancia)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "dataset[, clase01 := ifelse(clase_ternaria == \"CONTINUA\", 0L, 1L)]\n",
    "\n",
    "\n",
    "# los campos que se van a utilizar\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "set.seed(PARAM$trainingstrategy$semilla_azar)\n",
    "dataset[, azar := runif(nrow(dataset))]\n",
    "dataset[, training := 0L]\n",
    "dataset[\n",
    "  foto_mes %in% PARAM$input$training &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "dtrain <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[training == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[training == 1L, clase01],\n",
    "  weight = dataset[training == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forman parte de validation\n",
    "#  no hay undersampling\n",
    "dataset[, validation := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$validation,  validation := 1L]\n",
    "\n",
    "dvalidate <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[validation == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[validation == 1L, clase01],\n",
    "  weight = dataset[validation == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos de testing\n",
    "dataset[, testing := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$testing,  testing := 1L]\n",
    "\n",
    "\n",
    "dataset_test <- dataset[testing == 1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# libero espacio\n",
    "rm(dataset)\n",
    "gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "funcion_optimizar <- EstimarGanancia_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output = FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn = funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize = FALSE, # estoy Maximizando la ganancia\n",
    "  noisy = TRUE,\n",
    "  par.set = PARAM$bo_lgb, # definido al comienzo del programa\n",
    "  has.simple.signature = FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time = 600, # se graba cada 600 segundos\n",
    "  save.file.path = kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters = PARAM$bo_iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())\n",
    "\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type = \"se\",\n",
    "  covtype = \"matern3_2\",\n",
    "  control = list(trace = TRUE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# inicio la optimizacion bayesiana\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  run <- mbo(obj.fun, learner = surr.km, control = ctrl)\n",
    "} else {\n",
    "  run <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}\n",
    "\n",
    "\n",
    "cat(\"\\n\\nLa optimizacion Bayesiana ha terminado\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semilla 4, ajustado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# limpio la memoria\n",
    "rm(list = ls()) # remove all objects\n",
    "gc() # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "require(\"data.table\")\n",
    "require(\"rlist\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paquetes necesarios para la Bayesian Optimization\n",
    "require(\"DiceKriging\")\n",
    "require(\"mlrMBO\")\n",
    "\n",
    "# para que se detenga ante el primer error\n",
    "# y muestre el stack de funciones invocadas\n",
    "options(error = function() {\n",
    "  traceback(20)\n",
    "  options(error = NULL)\n",
    "  stop(\"exiting after script error\")\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los parametros de la corrida, en una lista, la variable global  PARAM\n",
    "#  muy pronto esto se leera desde un archivo formato .yaml\n",
    "PARAM <- list()\n",
    "\n",
    "PARAM$experimento <- \"HT8230 (Clase 12, Ajustado Sem4)\"\n",
    "\n",
    "PARAM$input$dataset <- \"datasets/competencia_03_infla_ajustado_lags.csv.gz\"\n",
    "\n",
    "# los meses en los que vamos a entrenar\n",
    "#  mucha magia emerger de esta eleccion\n",
    "PARAM$input$testing <- c(202107) # Último mes, lo más cercano al 202109 de kaggle\n",
    "PARAM$input$validation <- c(202106)\n",
    "PARAM$input$training <- c(202105, 202104, 202103, 202102, 202101,202012) # 6 meses de entrenamiento\t\n",
    "\n",
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "PARAM$trainingstrategy$undersampling <- 1.0\n",
    "PARAM$trainingstrategy$semilla_azar <- c(279511, 279523, 279541, 279551, 279571)  # Aqui poner su  primer  semilla/ pongo todas mis semillas\n",
    "\n",
    "PARAM$hyperparametertuning$POS_ganancia <- 273000\n",
    "PARAM$hyperparametertuning$NEG_ganancia <- -7000\n",
    "\n",
    "# Aqui va semilla\n",
    "PARAM$lgb_semilla <- 279551"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Hiperparametros FIJOS de  lightgbm\n",
    "PARAM$lgb_basicos <- list(\n",
    "  boosting = \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
    "  objective = \"binary\",\n",
    "  metric = \"custom\",\n",
    "  first_metric_only = TRUE,\n",
    "  boost_from_average = TRUE,\n",
    "  feature_pre_filter = FALSE,\n",
    "  force_row_wise = TRUE, # para reducir warnings\n",
    "  verbosity = -100,\n",
    "  max_depth = -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split = 0.0, # min_gain_to_split >= 0.0\n",
    "  min_sum_hessian_in_leaf = 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1 = 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2 = 0.0, # lambda_l2 >= 0.0\n",
    "  max_bin = 31L, # lo debo dejar fijo, no participa de la BO\n",
    "  num_iterations = 9999, # un numero muy grande, lo limita early_stopping_rounds\n",
    "\n",
    "  bagging_fraction = 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction = 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction = 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance = FALSE, #\n",
    "  scale_pos_weight = 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate = 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop = 50, # <=0 means no limit\n",
    "  skip_drop = 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  extra_trees = TRUE, # Magic Sauce\n",
    "\n",
    "  seed = PARAM$lgb_semilla\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui se cargan los hiperparametros que se optimizan\n",
    "#  en la Bayesian Optimization\n",
    "PARAM$bo_lgb <- makeParamSet(\n",
    "  makeNumericParam(\"learning_rate\", lower = 0.02, upper = 0.3),\n",
    "  makeNumericParam(\"feature_fraction\", lower = 0.01, upper = 1.0),\n",
    "  makeIntegerParam(\"num_leaves\", lower = 8L, upper = 1024L),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower = 100L, upper = 50000L)\n",
    ")\n",
    "\n",
    "# si usted es ambicioso, y tiene paciencia, podria subir este valor a 100\n",
    "PARAM$bo_iteraciones <- 50 # iteraciones de la Optimizacion Bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# graba a un archivo los componentes de lista\n",
    "# para el primer registro, escribe antes los titulos\n",
    "\n",
    "loguear <- function(\n",
    "    reg, arch = NA, folder = \"./exp/\",\n",
    "    ext = \".txt\", verbose = TRUE) {\n",
    "  archivo <- arch\n",
    "  if (is.na(arch)) archivo <- paste0(folder, substitute(reg), ext)\n",
    "\n",
    "  if (!file.exists(archivo)) # Escribo los titulos\n",
    "    {\n",
    "      linea <- paste0(\n",
    "        \"fecha\\t\",\n",
    "        paste(list.names(reg), collapse = \"\\t\"), \"\\n\"\n",
    "      )\n",
    "\n",
    "      cat(linea, file = archivo)\n",
    "    }\n",
    "\n",
    "  linea <- paste0(\n",
    "    format(Sys.time(), \"%Y%m%d %H%M%S\"), \"\\t\", # la fecha y hora\n",
    "    gsub(\", \", \"\\t\", toString(reg)), \"\\n\"\n",
    "  )\n",
    "\n",
    "  cat(linea, file = archivo, append = TRUE) # grabo al archivo\n",
    "\n",
    "  if (verbose) cat(linea) # imprimo por pantalla\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "GLOBAL_arbol <- 0L\n",
    "GLOBAL_gan_max <- -Inf\n",
    "vcant_optima <- c()\n",
    "\n",
    "fganancia_lgbm_meseta <- function(probs, datos) {\n",
    "  vlabels <- get_field(datos, \"label\")\n",
    "  vpesos <- get_field(datos, \"weight\")\n",
    "\n",
    "\n",
    "  GLOBAL_arbol <<- GLOBAL_arbol + 1\n",
    "  tbl <- as.data.table(list(\n",
    "    \"prob\" = probs,\n",
    "    \"gan\" = ifelse(vlabels == 1 & vpesos > 1,\n",
    "      PARAM$hyperparametertuning$POS_ganancia,\n",
    "      PARAM$hyperparametertuning$NEG_ganancia  )\n",
    "  ))\n",
    "\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, posicion := .I]\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "\n",
    "  tbl[, gan_suavizada :=\n",
    "    frollmean(\n",
    "      x = gan_acum, n = 2001, align = \"center\",\n",
    "      na.rm = TRUE, hasNA = TRUE\n",
    "    )]\n",
    "\n",
    "  gan <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "\n",
    "  pos <- which.max(tbl[, gan_suavizada])\n",
    "  vcant_optima <<- c(vcant_optima, pos)\n",
    "\n",
    "  if (GLOBAL_arbol %% 10 == 0) {\n",
    "    if (gan > GLOBAL_gan_max) GLOBAL_gan_max <<- gan\n",
    "\n",
    "    cat(\"\\r\")\n",
    "    cat(\n",
    "      \"Validate \", GLOBAL_iteracion, \" \", \" \",\n",
    "      GLOBAL_arbol, \"  \", gan, \"   \", GLOBAL_gan_max, \"   \"\n",
    "    )\n",
    "  }\n",
    "\n",
    "\n",
    "  return(list(\n",
    "    \"name\" = \"ganancia\",\n",
    "    \"value\" = gan,\n",
    "    \"higher_better\" = TRUE\n",
    "  ))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "\n",
    "EstimarGanancia_lightgbm <- function(x) {\n",
    "  gc()\n",
    "  GLOBAL_iteracion <<- GLOBAL_iteracion + 1L\n",
    "\n",
    "  # hago la union de los parametros basicos y los moviles que vienen en x\n",
    "  param_completo <- c(PARAM$lgb_basicos, x)\n",
    "\n",
    "  param_completo$early_stopping_rounds <-\n",
    "    as.integer(400 + 4 / param_completo$learning_rate)\n",
    "\n",
    "  GLOBAL_arbol <<- 0L\n",
    "  GLOBAL_gan_max <<- -Inf\n",
    "  vcant_optima <<- c()\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  modelo_train <- lgb.train(\n",
    "    data = dtrain,\n",
    "    valids = list(valid = dvalidate),\n",
    "    eval = fganancia_lgbm_meseta,\n",
    "    param = param_completo,\n",
    "    verbose = -100\n",
    "  )\n",
    "\n",
    "  cat(\"\\n\")\n",
    "\n",
    "  cant_corte <- vcant_optima[modelo_train$best_iter]\n",
    "\n",
    "  # aplico el modelo a testing y calculo la ganancia\n",
    "  prediccion <- predict(\n",
    "    modelo_train,\n",
    "    data.matrix(dataset_test[, campos_buenos, with = FALSE])\n",
    "  )\n",
    "\n",
    "  tbl <- copy(dataset_test[, list(\"gan\" = ifelse(clase_ternaria == \"BAJA+2\",\n",
    "    PARAM$hyperparametertuning$POS_ganancia, \n",
    "    PARAM$hyperparametertuning$NEG_ganancia))])\n",
    "\n",
    "  tbl[, prob := prediccion]\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "  tbl[, gan_suavizada := frollmean(\n",
    "    x = gan_acum, n = 2001,\n",
    "    align = \"center\", na.rm = TRUE, hasNA = TRUE\n",
    "  )]\n",
    "\n",
    "\n",
    "  ganancia_test <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "  cantidad_test_normalizada <- which.max(tbl[, gan_suavizada])\n",
    "\n",
    "  rm(tbl)\n",
    "  gc()\n",
    "\n",
    "  ganancia_test_normalizada <- ganancia_test\n",
    "\n",
    "\n",
    "  # voy grabando las mejores column importance\n",
    "  if (ganancia_test_normalizada > GLOBAL_gananciamax) {\n",
    "    GLOBAL_gananciamax <<- ganancia_test_normalizada\n",
    "    tb_importancia <- as.data.table(lgb.importance(modelo_train))\n",
    "\n",
    "    fwrite(tb_importancia,\n",
    "      file = paste0(\"impo_\", sprintf(\"%03d\", GLOBAL_iteracion), \".txt\"),\n",
    "      sep = \"\\t\"\n",
    "    )\n",
    "\n",
    "    rm(tb_importancia)\n",
    "  }\n",
    "\n",
    "\n",
    "  # logueo final\n",
    "  ds <- list(\"cols\" = ncol(dtrain), \"rows\" = nrow(dtrain))\n",
    "  xx <- c(ds, copy(param_completo))\n",
    "\n",
    "  xx$early_stopping_rounds <- NULL\n",
    "  xx$num_iterations <- modelo_train$best_iter\n",
    "  xx$estimulos <- cantidad_test_normalizada\n",
    "  xx$ganancia <- ganancia_test_normalizada\n",
    "  xx$iteracion_bayesiana <- GLOBAL_iteracion\n",
    "\n",
    "  loguear(xx, arch = \"BO_log.txt\")\n",
    "\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  return(ganancia_test_normalizada)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aquí empieza el programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui empieza el programa\n",
    "\n",
    "# Aqui se debe poner la carpeta de la computadora local\n",
    "setwd(\"~/buckets/b1/\") # Establezco el Working Directory\n",
    "\n",
    "# cargo el dataset donde voy a entrenar el modelo\n",
    "dataset <- fread(PARAM$input$dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# creo la carpeta donde va el experimento\n",
    "dir.create(\"./exp/\", showWarnings = FALSE)\n",
    "dir.create(paste0(\"./exp/\", PARAM$experimento, \"/\"), showWarnings = FALSE)\n",
    "\n",
    "# Establezco el Working Directory DEL EXPERIMENTO\n",
    "setwd(paste0(\"./exp/\", PARAM$experimento, \"/\"))\n",
    "\n",
    "# en estos archivos quedan los resultados\n",
    "kbayesiana <- paste0(PARAM$experimento, \".RDATA\")\n",
    "klog <- paste0(PARAM$experimento, \".txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Catastrophe Analysis  -------------------------------------------------------\n",
    "# deben ir cosas de este estilo\n",
    "#   dataset[foto_mes == 202006, active_quarter := NA]\n",
    "\n",
    "# Data Drifting\n",
    "# por ahora, no hago nada\n",
    "\n",
    "\n",
    "# Feature Engineering Historico  ----------------------------------------------\n",
    "#   aqui deben calcularse los  lags y  lag_delta\n",
    "#   Sin lags no hay paraiso !  corta la bocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ahora SI comienza la optimizacion Bayesiana\n",
    "\n",
    "GLOBAL_iteracion <- 0 # inicializo la variable global\n",
    "GLOBAL_gananciamax <- -1 # inicializo la variable global\n",
    "\n",
    "# si ya existe el archivo log, traigo hasta donde llegue\n",
    "if (file.exists(klog)) {\n",
    "  tabla_log <- fread(klog)\n",
    "  GLOBAL_iteracion <- nrow(tabla_log)\n",
    "  GLOBAL_gananciamax <- tabla_log[, max(ganancia)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "dataset[, clase01 := ifelse(clase_ternaria == \"CONTINUA\", 0L, 1L)]\n",
    "\n",
    "\n",
    "# los campos que se van a utilizar\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "set.seed(PARAM$trainingstrategy$semilla_azar)\n",
    "dataset[, azar := runif(nrow(dataset))]\n",
    "dataset[, training := 0L]\n",
    "dataset[\n",
    "  foto_mes %in% PARAM$input$training &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "dtrain <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[training == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[training == 1L, clase01],\n",
    "  weight = dataset[training == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forman parte de validation\n",
    "#  no hay undersampling\n",
    "dataset[, validation := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$validation,  validation := 1L]\n",
    "\n",
    "dvalidate <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[validation == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[validation == 1L, clase01],\n",
    "  weight = dataset[validation == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos de testing\n",
    "dataset[, testing := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$testing,  testing := 1L]\n",
    "\n",
    "\n",
    "dataset_test <- dataset[testing == 1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# libero espacio\n",
    "rm(dataset)\n",
    "gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "funcion_optimizar <- EstimarGanancia_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output = FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn = funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize = FALSE, # estoy Maximizando la ganancia\n",
    "  noisy = TRUE,\n",
    "  par.set = PARAM$bo_lgb, # definido al comienzo del programa\n",
    "  has.simple.signature = FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time = 600, # se graba cada 600 segundos\n",
    "  save.file.path = kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters = PARAM$bo_iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())\n",
    "\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type = \"se\",\n",
    "  covtype = \"matern3_2\",\n",
    "  control = list(trace = TRUE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# inicio la optimizacion bayesiana\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  run <- mbo(obj.fun, learner = surr.km, control = ctrl)\n",
    "} else {\n",
    "  run <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}\n",
    "\n",
    "\n",
    "cat(\"\\n\\nLa optimizacion Bayesiana ha terminado\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semilla 5, ajustado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# limpio la memoria\n",
    "rm(list = ls()) # remove all objects\n",
    "gc() # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "require(\"data.table\")\n",
    "require(\"rlist\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paquetes necesarios para la Bayesian Optimization\n",
    "require(\"DiceKriging\")\n",
    "require(\"mlrMBO\")\n",
    "\n",
    "# para que se detenga ante el primer error\n",
    "# y muestre el stack de funciones invocadas\n",
    "options(error = function() {\n",
    "  traceback(20)\n",
    "  options(error = NULL)\n",
    "  stop(\"exiting after script error\")\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los parametros de la corrida, en una lista, la variable global  PARAM\n",
    "#  muy pronto esto se leera desde un archivo formato .yaml\n",
    "PARAM <- list()\n",
    "\n",
    "PARAM$experimento <- \"HT8230 (Clase 12, Ajustado Sem5)\"\n",
    "\n",
    "PARAM$input$dataset <- \"datasets/competencia_03_infla_ajustado_lags.csv.gz\"\n",
    "\n",
    "# los meses en los que vamos a entrenar\n",
    "#  mucha magia emerger de esta eleccion\n",
    "PARAM$input$testing <- c(202107) # Último mes, lo más cercano al 202109 de kaggle\n",
    "PARAM$input$validation <- c(202106)\n",
    "PARAM$input$training <- c(202105, 202104, 202103, 202102, 202101,202012) # 6 meses de entrenamiento\t\n",
    "\n",
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "PARAM$trainingstrategy$undersampling <- 1.0\n",
    "PARAM$trainingstrategy$semilla_azar <- c(279511, 279523, 279541, 279551, 279571)  # Aqui poner su  primer  semilla/ pongo todas mis semillas\n",
    "\n",
    "PARAM$hyperparametertuning$POS_ganancia <- 273000\n",
    "PARAM$hyperparametertuning$NEG_ganancia <- -7000\n",
    "\n",
    "# Aqui va semilla\n",
    "PARAM$lgb_semilla <- 279571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Hiperparametros FIJOS de  lightgbm\n",
    "PARAM$lgb_basicos <- list(\n",
    "  boosting = \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
    "  objective = \"binary\",\n",
    "  metric = \"custom\",\n",
    "  first_metric_only = TRUE,\n",
    "  boost_from_average = TRUE,\n",
    "  feature_pre_filter = FALSE,\n",
    "  force_row_wise = TRUE, # para reducir warnings\n",
    "  verbosity = -100,\n",
    "  max_depth = -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split = 0.0, # min_gain_to_split >= 0.0\n",
    "  min_sum_hessian_in_leaf = 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1 = 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2 = 0.0, # lambda_l2 >= 0.0\n",
    "  max_bin = 31L, # lo debo dejar fijo, no participa de la BO\n",
    "  num_iterations = 9999, # un numero muy grande, lo limita early_stopping_rounds\n",
    "\n",
    "  bagging_fraction = 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction = 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction = 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance = FALSE, #\n",
    "  scale_pos_weight = 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate = 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop = 50, # <=0 means no limit\n",
    "  skip_drop = 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  extra_trees = TRUE, # Magic Sauce\n",
    "\n",
    "  seed = PARAM$lgb_semilla\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui se cargan los hiperparametros que se optimizan\n",
    "#  en la Bayesian Optimization\n",
    "PARAM$bo_lgb <- makeParamSet(\n",
    "  makeNumericParam(\"learning_rate\", lower = 0.02, upper = 0.3),\n",
    "  makeNumericParam(\"feature_fraction\", lower = 0.01, upper = 1.0),\n",
    "  makeIntegerParam(\"num_leaves\", lower = 8L, upper = 1024L),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower = 100L, upper = 50000L)\n",
    ")\n",
    "\n",
    "# si usted es ambicioso, y tiene paciencia, podria subir este valor a 100\n",
    "PARAM$bo_iteraciones <- 50 # iteraciones de la Optimizacion Bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# graba a un archivo los componentes de lista\n",
    "# para el primer registro, escribe antes los titulos\n",
    "\n",
    "loguear <- function(\n",
    "    reg, arch = NA, folder = \"./exp/\",\n",
    "    ext = \".txt\", verbose = TRUE) {\n",
    "  archivo <- arch\n",
    "  if (is.na(arch)) archivo <- paste0(folder, substitute(reg), ext)\n",
    "\n",
    "  if (!file.exists(archivo)) # Escribo los titulos\n",
    "    {\n",
    "      linea <- paste0(\n",
    "        \"fecha\\t\",\n",
    "        paste(list.names(reg), collapse = \"\\t\"), \"\\n\"\n",
    "      )\n",
    "\n",
    "      cat(linea, file = archivo)\n",
    "    }\n",
    "\n",
    "  linea <- paste0(\n",
    "    format(Sys.time(), \"%Y%m%d %H%M%S\"), \"\\t\", # la fecha y hora\n",
    "    gsub(\", \", \"\\t\", toString(reg)), \"\\n\"\n",
    "  )\n",
    "\n",
    "  cat(linea, file = archivo, append = TRUE) # grabo al archivo\n",
    "\n",
    "  if (verbose) cat(linea) # imprimo por pantalla\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "GLOBAL_arbol <- 0L\n",
    "GLOBAL_gan_max <- -Inf\n",
    "vcant_optima <- c()\n",
    "\n",
    "fganancia_lgbm_meseta <- function(probs, datos) {\n",
    "  vlabels <- get_field(datos, \"label\")\n",
    "  vpesos <- get_field(datos, \"weight\")\n",
    "\n",
    "\n",
    "  GLOBAL_arbol <<- GLOBAL_arbol + 1\n",
    "  tbl <- as.data.table(list(\n",
    "    \"prob\" = probs,\n",
    "    \"gan\" = ifelse(vlabels == 1 & vpesos > 1,\n",
    "      PARAM$hyperparametertuning$POS_ganancia,\n",
    "      PARAM$hyperparametertuning$NEG_ganancia  )\n",
    "  ))\n",
    "\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, posicion := .I]\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "\n",
    "  tbl[, gan_suavizada :=\n",
    "    frollmean(\n",
    "      x = gan_acum, n = 2001, align = \"center\",\n",
    "      na.rm = TRUE, hasNA = TRUE\n",
    "    )]\n",
    "\n",
    "  gan <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "\n",
    "  pos <- which.max(tbl[, gan_suavizada])\n",
    "  vcant_optima <<- c(vcant_optima, pos)\n",
    "\n",
    "  if (GLOBAL_arbol %% 10 == 0) {\n",
    "    if (gan > GLOBAL_gan_max) GLOBAL_gan_max <<- gan\n",
    "\n",
    "    cat(\"\\r\")\n",
    "    cat(\n",
    "      \"Validate \", GLOBAL_iteracion, \" \", \" \",\n",
    "      GLOBAL_arbol, \"  \", gan, \"   \", GLOBAL_gan_max, \"   \"\n",
    "    )\n",
    "  }\n",
    "\n",
    "\n",
    "  return(list(\n",
    "    \"name\" = \"ganancia\",\n",
    "    \"value\" = gan,\n",
    "    \"higher_better\" = TRUE\n",
    "  ))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "\n",
    "EstimarGanancia_lightgbm <- function(x) {\n",
    "  gc()\n",
    "  GLOBAL_iteracion <<- GLOBAL_iteracion + 1L\n",
    "\n",
    "  # hago la union de los parametros basicos y los moviles que vienen en x\n",
    "  param_completo <- c(PARAM$lgb_basicos, x)\n",
    "\n",
    "  param_completo$early_stopping_rounds <-\n",
    "    as.integer(400 + 4 / param_completo$learning_rate)\n",
    "\n",
    "  GLOBAL_arbol <<- 0L\n",
    "  GLOBAL_gan_max <<- -Inf\n",
    "  vcant_optima <<- c()\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  modelo_train <- lgb.train(\n",
    "    data = dtrain,\n",
    "    valids = list(valid = dvalidate),\n",
    "    eval = fganancia_lgbm_meseta,\n",
    "    param = param_completo,\n",
    "    verbose = -100\n",
    "  )\n",
    "\n",
    "  cat(\"\\n\")\n",
    "\n",
    "  cant_corte <- vcant_optima[modelo_train$best_iter]\n",
    "\n",
    "  # aplico el modelo a testing y calculo la ganancia\n",
    "  prediccion <- predict(\n",
    "    modelo_train,\n",
    "    data.matrix(dataset_test[, campos_buenos, with = FALSE])\n",
    "  )\n",
    "\n",
    "  tbl <- copy(dataset_test[, list(\"gan\" = ifelse(clase_ternaria == \"BAJA+2\",\n",
    "    PARAM$hyperparametertuning$POS_ganancia, \n",
    "    PARAM$hyperparametertuning$NEG_ganancia))])\n",
    "\n",
    "  tbl[, prob := prediccion]\n",
    "  setorder(tbl, -prob)\n",
    "  tbl[, gan_acum := cumsum(gan)]\n",
    "  tbl[, gan_suavizada := frollmean(\n",
    "    x = gan_acum, n = 2001,\n",
    "    align = \"center\", na.rm = TRUE, hasNA = TRUE\n",
    "  )]\n",
    "\n",
    "\n",
    "  ganancia_test <- tbl[, max(gan_suavizada, na.rm = TRUE)]\n",
    "\n",
    "  cantidad_test_normalizada <- which.max(tbl[, gan_suavizada])\n",
    "\n",
    "  rm(tbl)\n",
    "  gc()\n",
    "\n",
    "  ganancia_test_normalizada <- ganancia_test\n",
    "\n",
    "\n",
    "  # voy grabando las mejores column importance\n",
    "  if (ganancia_test_normalizada > GLOBAL_gananciamax) {\n",
    "    GLOBAL_gananciamax <<- ganancia_test_normalizada\n",
    "    tb_importancia <- as.data.table(lgb.importance(modelo_train))\n",
    "\n",
    "    fwrite(tb_importancia,\n",
    "      file = paste0(\"impo_\", sprintf(\"%03d\", GLOBAL_iteracion), \".txt\"),\n",
    "      sep = \"\\t\"\n",
    "    )\n",
    "\n",
    "    rm(tb_importancia)\n",
    "  }\n",
    "\n",
    "\n",
    "  # logueo final\n",
    "  ds <- list(\"cols\" = ncol(dtrain), \"rows\" = nrow(dtrain))\n",
    "  xx <- c(ds, copy(param_completo))\n",
    "\n",
    "  xx$early_stopping_rounds <- NULL\n",
    "  xx$num_iterations <- modelo_train$best_iter\n",
    "  xx$estimulos <- cantidad_test_normalizada\n",
    "  xx$ganancia <- ganancia_test_normalizada\n",
    "  xx$iteracion_bayesiana <- GLOBAL_iteracion\n",
    "\n",
    "  loguear(xx, arch = \"BO_log.txt\")\n",
    "\n",
    "  set.seed(PARAM$lgb_semilla, kind = \"L'Ecuyer-CMRG\")\n",
    "  return(ganancia_test_normalizada)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aquí empieza el programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui empieza el programa\n",
    "\n",
    "# Aqui se debe poner la carpeta de la computadora local\n",
    "setwd(\"~/buckets/b1/\") # Establezco el Working Directory\n",
    "\n",
    "# cargo el dataset donde voy a entrenar el modelo\n",
    "dataset <- fread(PARAM$input$dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# creo la carpeta donde va el experimento\n",
    "dir.create(\"./exp/\", showWarnings = FALSE)\n",
    "dir.create(paste0(\"./exp/\", PARAM$experimento, \"/\"), showWarnings = FALSE)\n",
    "\n",
    "# Establezco el Working Directory DEL EXPERIMENTO\n",
    "setwd(paste0(\"./exp/\", PARAM$experimento, \"/\"))\n",
    "\n",
    "# en estos archivos quedan los resultados\n",
    "kbayesiana <- paste0(PARAM$experimento, \".RDATA\")\n",
    "klog <- paste0(PARAM$experimento, \".txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Catastrophe Analysis  -------------------------------------------------------\n",
    "# deben ir cosas de este estilo\n",
    "#   dataset[foto_mes == 202006, active_quarter := NA]\n",
    "\n",
    "# Data Drifting\n",
    "# por ahora, no hago nada\n",
    "\n",
    "\n",
    "# Feature Engineering Historico  ----------------------------------------------\n",
    "#   aqui deben calcularse los  lags y  lag_delta\n",
    "#   Sin lags no hay paraiso !  corta la bocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ahora SI comienza la optimizacion Bayesiana\n",
    "\n",
    "GLOBAL_iteracion <- 0 # inicializo la variable global\n",
    "GLOBAL_gananciamax <- -1 # inicializo la variable global\n",
    "\n",
    "# si ya existe el archivo log, traigo hasta donde llegue\n",
    "if (file.exists(klog)) {\n",
    "  tabla_log <- fread(klog)\n",
    "  GLOBAL_iteracion <- nrow(tabla_log)\n",
    "  GLOBAL_gananciamax <- tabla_log[, max(ganancia)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "dataset[, clase01 := ifelse(clase_ternaria == \"CONTINUA\", 0L, 1L)]\n",
    "\n",
    "\n",
    "# los campos que se van a utilizar\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "set.seed(PARAM$trainingstrategy$semilla_azar)\n",
    "dataset[, azar := runif(nrow(dataset))]\n",
    "dataset[, training := 0L]\n",
    "dataset[\n",
    "  foto_mes %in% PARAM$input$training &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "dtrain <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[training == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[training == 1L, clase01],\n",
    "  weight = dataset[training == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forman parte de validation\n",
    "#  no hay undersampling\n",
    "dataset[, validation := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$validation,  validation := 1L]\n",
    "\n",
    "dvalidate <- lgb.Dataset(\n",
    "  data = data.matrix(dataset[validation == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset[validation == 1L, clase01],\n",
    "  weight = dataset[validation == 1L, \n",
    "    ifelse(clase_ternaria == \"BAJA+2\", 1.0000001, \n",
    "      ifelse(clase_ternaria == \"BAJA+1\", 1.0, 1.0))],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos de testing\n",
    "dataset[, testing := 0L]\n",
    "dataset[ foto_mes %in% PARAM$input$testing,  testing := 1L]\n",
    "\n",
    "\n",
    "dataset_test <- dataset[testing == 1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# libero espacio\n",
    "rm(dataset)\n",
    "gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "funcion_optimizar <- EstimarGanancia_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output = FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn = funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize = FALSE, # estoy Maximizando la ganancia\n",
    "  noisy = TRUE,\n",
    "  par.set = PARAM$bo_lgb, # definido al comienzo del programa\n",
    "  has.simple.signature = FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time = 600, # se graba cada 600 segundos\n",
    "  save.file.path = kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters = PARAM$bo_iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())\n",
    "\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type = \"se\",\n",
    "  covtype = \"matern3_2\",\n",
    "  control = list(trace = TRUE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# inicio la optimizacion bayesiana\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  run <- mbo(obj.fun, learner = surr.km, control = ctrl)\n",
    "} else {\n",
    "  run <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}\n",
    "\n",
    "\n",
    "cat(\"\\n\\nLa optimizacion Bayesiana ha terminado\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
